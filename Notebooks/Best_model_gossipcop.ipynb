{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0NGBxXcVj4Z"
      },
      "source": [
        "# Installlations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcSe3ryFVgv3",
        "outputId": "4784851a-85a8-40db-a140-7a14241f3480"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping torch-scatter as it is not installed.\u001b[0m\n",
            "\u001b[33mWARNING: Skipping torch-sparse as it is not installed.\u001b[0m\n",
            "\u001b[33mWARNING: Skipping torch-geometric as it is not installed.\u001b[0m\n",
            "\u001b[33mWARNING: Skipping torch-cluster as it is not installed.\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-+.html\n",
            "Collecting torch-scatter\n",
            "  Downloading torch_scatter-2.0.9.tar.gz (21 kB)\n",
            "Building wheels for collected packages: torch-scatter\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl size=2657108 sha256=026cf249e122f4c8aa38065fdabe9750cb7874a4cfb6cede1fb99c34f09a2a0d\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/57/a3/42ea193b77378ce634eb9454c9bc1e3163f3b482a35cdee4d1\n",
            "Successfully built torch-scatter\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.9\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-+.html\n",
            "Collecting torch-sparse\n",
            "  Downloading torch_sparse-0.6.15.tar.gz (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 33.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Building wheels for collected packages: torch-sparse\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.15-cp37-cp37m-linux_x86_64.whl size=1577337 sha256=7656d0f3850953546ed49496b2e52f18921d13f46306fb7dc98d0a8668d23608\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/68/4d/1414be5c2c622bad35364e13213180797717b6d4b8923936dc\n",
            "Successfully built torch-sparse\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.15\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.1.0.post1.tar.gz (467 kB)\n",
            "\u001b[K     |████████████████████████████████| 467 kB 31.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2022.9.24)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.2.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.1.0.post1-py3-none-any.whl size=689859 sha256=2efbb834ef79baa8735c1ba859232baf1f4ec646ae103a7eb7e72779ca5f6c4f\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/cb/43/f7f2e472de4d7cff31bceddadc36d634e1e545fbc17961c282\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.1.0.post1\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  \n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}+${CUDA}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}+${CUDA}.html\n",
        "!pip install torch-geometric\n",
        "#!pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ep-VMvdQVnZM",
        "outputId": "f54c82d9-7a95-4b1e-9a1a-0e1608ce426c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.0.3-py3-none-any.whl (348 kB)\n",
            "\u001b[K     |████████████████████████████████| 348 kB 19.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.6)\n",
            "Requirement already satisfied: scipy<1.9.0,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.7.3)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.41)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 5.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Collecting alembic>=1.5.0\n",
            "  Downloading alembic-1.8.1-py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 59.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (6.0)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting importlib-metadata<5.0.0\n",
            "  Downloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.3-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic>=1.5.0->optuna) (5.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5.0.0->optuna) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5.0.0->optuna) (3.9.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.3.0->optuna) (1.1.3.post0)\n",
            "Collecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.1-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 5.7 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.4.1)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.10.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 68.0 MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.2-py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 63.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (22.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=43b77773b4dab96c1e816e9c54fd02c42c0c282c1cb7fff1ede45dbfe3e68b29\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, importlib-metadata, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 5.0.0\n",
            "    Uninstalling importlib-metadata-5.0.0:\n",
            "      Successfully uninstalled importlib-metadata-5.0.0\n",
            "Successfully installed Mako-1.2.3 alembic-1.8.1 autopage-0.5.1 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.2 colorlog-6.7.0 importlib-metadata-4.13.0 optuna-3.0.3 pbr-5.10.0 pyperclip-1.8.2 stevedore-3.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlNCSrUqVq9_"
      },
      "source": [
        "# Model definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmUK6R5FVpah"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch_geometric.datasets import UPFD\n",
        "import numpy as np\n",
        "from torch_geometric.loader import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AyeWEOJAWKnW"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "from torch.nn import ReLU, LeakyReLU, Softmax, Linear, SELU, GELU, ELU\n",
        "from torch_geometric.nn import SAGEConv, global_max_pool, TopKPooling,GCNConv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZ3ZOPO7ZQg6"
      },
      "outputs": [],
      "source": [
        "from torch.autograd import Variable\n",
        "from sklearn.metrics import accuracy_score, f1_score "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFNw7_rmV4ec"
      },
      "outputs": [],
      "source": [
        "test_data_gos = UPFD(root=\".\", name=\"gossipcop\", feature=\"bert\",split=\"test\")\n",
        "train_data_gos = UPFD(root=\".\", name=\"gossipcop\", feature=\"bert\", split=\"train\")\n",
        "val_data_gos = UPFD(root=\".\", name=\"gossipcop\", feature=\"bert\", split=\"val\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAaqMY3rV8E7"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_data_gos, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(train_data_gos, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_data_gos, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bi29BEZXYD-Q"
      },
      "outputs": [],
      "source": [
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels[0])\n",
        "        self.leaky1 = LeakyReLU()\n",
        "        self.conv2 = SAGEConv(hidden_channels[0], hidden_channels[1])\n",
        "        self.leaky2 = LeakyReLU()\n",
        "        self.conv3 = SAGEConv(hidden_channels[1], hidden_channels[2])\n",
        "        self.leaky3 = LeakyReLU() \n",
        "        \n",
        "        self.full1 = Linear(hidden_channels[2],hidden_channels[3])\n",
        "        self.ge1 = GELU()\n",
        "        self.full2 = Linear(hidden_channels[3],hidden_channels[4])\n",
        "        self.ge2 = GELU()\n",
        "        self.full3 = Linear(hidden_channels[4],out_channels)\n",
        "\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        h = self.leaky1(self.conv1(x, edge_index))\n",
        "        h = self.leaky2(self.conv2(h, edge_index))\n",
        "        h = self.leaky3(self.conv3(h, edge_index))\n",
        "\n",
        "        h = global_max_pool(h,batch)\n",
        "\n",
        "        h = self.ge1(self.full1(h))\n",
        "        h = self.ge2(self.full2(h))\n",
        "        h = self.full3(h)\n",
        "\n",
        "        return torch.sigmoid(h)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XI5gL3-_edt-"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hyper Parameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1v_ZxrlHZZMF"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "  \n",
        "  model = Net(768,[trial.suggest_int(name=\"layer_size1\",low=256,high=512,step=128),\n",
        "                   trial.suggest_int(name=\"layer_size2\",low=256,high=512,step=128),\n",
        "                   trial.suggest_int(name=\"layer_size3\",low=256,high=512,step=128),\n",
        "                   trial.suggest_int(name=\"layer_size4\",low=64,high=256,step=64),\n",
        "                   trial.suggest_int(name=\"layer_size5\",low=64,high=256,step=64),\n",
        "  \n",
        "  ],1).to(device)\n",
        "  optimizer = torch.optim.Adam(model.parameters(),lr=trial.suggest_loguniform('learning_rate', 1e-6, 1e-3),betas=(trial.suggest_loguniform('b1', 1-1e-1,1-1e-3),0.99))\n",
        "  lossff = torch.nn.BCELoss()\n",
        "\n",
        "  total_loss = 0\n",
        "  weighted_loss = 0\n",
        "  exp_param = 0.8\n",
        "\n",
        "  wloss = []\n",
        "\n",
        "  for i in range(400):\n",
        "    print(\"Epoch:\", i)\n",
        "    model.train()\n",
        "    for data in train_loader:\n",
        "          data = data.to(device)\n",
        "          optimizer.zero_grad()\n",
        "          out = model(data.x, data.edge_index, data.batch)\n",
        "          loss = lossff(torch.reshape(out,(-1,)), data.y.float())\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          total_loss += float(loss) * data.num_graphs\n",
        "    print(\"Train: \",total_loss / len(train_loader.dataset))\n",
        "\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    for data in val_loader:\n",
        "          data = data.to(device)\n",
        "          out = model(data.x, data.edge_index, data.batch)\n",
        "          loss = lossff(torch.reshape(out,(-1,)), data.y.float())\n",
        "          total_loss += float(loss) * data.num_graphs\n",
        "          \n",
        "    print(\"Test\", total_loss / len(val_loader.dataset))\n",
        "\n",
        "    weighted_loss = exp_param*(weighted_loss) + (1-exp_param)*(total_loss/ len(val_loader.dataset))\n",
        "    print(weighted_loss/(1-exp_param**(i+1)))\n",
        "    wloss.append(weighted_loss/(1-exp_param**(i+1)))\n",
        "\n",
        "    if(i-30>=0 and wloss[i-20]-weighted_loss<0.01):\n",
        "      break\n",
        "\n",
        "  return weighted_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKKZ-PZTi3Q8",
        "outputId": "68f1d880-16cc-4319-83ab-dae12b8ad3de"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-10-15 12:18:05,824]\u001b[0m A new study created in memory with name: no-name-f44bd841-3251-4e67-a81c-665ab8c6cedc\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Train:  0.6734409181626289\n",
            "Test 0.5883285658700126\n",
            "0.5883285658700126\n",
            "Epoch: 1\n",
            "Train:  0.7410202604947073\n",
            "Test 0.2711249816985357\n",
            "0.4121043524414144\n",
            "Epoch: 2\n",
            "Train:  0.4425303549556942\n",
            "Test 0.2491557567820444\n",
            "0.34532214110560705\n",
            "Epoch: 3\n",
            "Train:  0.3476556937445651\n",
            "Test 0.17865540948270003\n",
            "0.28886322117914803\n",
            "Epoch: 4\n",
            "Train:  0.26342853388643306\n",
            "Test 0.15664322930814584\n",
            "0.2495307628643568\n",
            "Epoch: 5\n",
            "Train:  0.25067862810314573\n",
            "Test 0.15549390199815943\n",
            "0.22404154522129438\n",
            "Epoch: 6\n",
            "Train:  0.21862659711329327\n",
            "Test 0.13647594966076232\n",
            "0.2018810290224425\n",
            "Epoch: 7\n",
            "Train:  0.19661503752195464\n",
            "Test 0.15832880553499465\n",
            "0.19141461071866459\n",
            "Epoch: 8\n",
            "Train:  0.20783235950415935\n",
            "Test 0.14639594572367687\n",
            "0.18101507576607373\n",
            "Epoch: 9\n",
            "Train:  0.1809123311423775\n",
            "Test 0.14106498194019218\n",
            "0.1720639356493123\n",
            "Epoch: 10\n",
            "Train:  0.1753456720795769\n",
            "Test 0.16153149421398455\n",
            "0.16975949764495968\n",
            "Epoch: 11\n",
            "Train:  0.16975126131659463\n",
            "Test 0.17073512066414942\n",
            "0.16996902055343202\n",
            "Epoch: 12\n",
            "Train:  0.16623659257098158\n",
            "Test 0.19658144103574665\n",
            "0.17560113332389865\n",
            "Epoch: 13\n",
            "Train:  0.21474990414476003\n",
            "Test 0.14819409450577511\n",
            "0.169867560354324\n",
            "Epoch: 14\n",
            "Train:  0.16107136572987496\n",
            "Test 0.19523428627989176\n",
            "0.17512591753506054\n",
            "Epoch: 15\n",
            "Train:  0.17909090496145952\n",
            "Test 0.15932441702378647\n",
            "0.17187408652708194\n",
            "Epoch: 16\n",
            "Train:  0.14085982152816903\n",
            "Test 0.18423956526518415\n",
            "0.1744041543369307\n",
            "Epoch: 17\n",
            "Train:  0.16386136191729933\n",
            "Test 0.21495852974199114\n",
            "0.18266382236943637\n",
            "Epoch: 18\n",
            "Train:  0.17969182433198877\n",
            "Test 0.15033063288068488\n",
            "0.17610262769118015\n",
            "Epoch: 19\n",
            "Train:  0.12372638500592374\n",
            "Test 0.1605916876915583\n",
            "0.17296425673763804\n",
            "Epoch: 20\n",
            "Train:  0.11998373100912751\n",
            "Test 0.1559610731094639\n",
            "0.16953196268703458\n",
            "Epoch: 21\n",
            "Train:  0.1174441196673444\n",
            "Test 0.1497189075581136\n",
            "0.16553989540385122\n",
            "Epoch: 22\n",
            "Train:  0.11034536741238135\n",
            "Test 0.2056008035337532\n",
            "0.1735996534438669\n",
            "Epoch: 23\n",
            "Train:  0.1297570869237894\n",
            "Test 0.17031961281940805\n",
            "0.1729405327093101\n",
            "Epoch: 24\n",
            "Train:  0.10748550154212452\n",
            "Test 0.1888279327648332\n",
            "0.1761300624229875\n",
            "Epoch: 25\n",
            "Train:  0.11047699470805378\n",
            "Test 0.275816753548877\n",
            "0.19612784022295862\n",
            "Epoch: 26\n",
            "Train:  0.1509662861259903\n",
            "Test 0.21772578567771356\n",
            "0.20045789875302447\n",
            "Epoch: 27\n",
            "Train:  0.11265719319739811\n",
            "Test 0.3235006901159001\n",
            "0.22511414914995115\n",
            "Epoch: 28\n",
            "Train:  0.1664289236751113\n",
            "Test 0.2699900106044846\n",
            "0.23410323137185649\n",
            "Epoch: 29\n",
            "Train:  0.14225503125570477\n",
            "Test 0.4492290936954232\n",
            "0.2771817324378718\n",
            "Epoch: 30\n",
            "Train:  0.23143172153464586\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-10-15 12:18:47,338]\u001b[0m Trial 0 finished with value: 0.2897461642402153 and parameters: {'layer_size1': 512, 'layer_size2': 384, 'layer_size3': 256, 'layer_size4': 64, 'layer_size5': 128, 'learning_rate': 0.00020517752953342884, 'b1': 0.9569164721605181}. Best is trial 0 with value: 0.2897461642402153.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test 0.3413764289085627\n",
            "0.2900333994064996\n",
            "Epoch: 0\n",
            "Train:  0.6118858931210888\n",
            "Test 0.3116219233407642\n",
            "0.3116219233407642\n",
            "Epoch: 1\n",
            "Train:  0.3718375306535553\n",
            "Test 0.1469686738737337\n",
            "0.22014789585908065\n",
            "Epoch: 2\n",
            "Train:  0.2260886481229639\n",
            "Test 0.1330065532918378\n",
            "0.1844342308725057\n",
            "Epoch: 3\n",
            "Train:  0.20478879867101107\n",
            "Test 0.12764737277117733\n",
            "0.16519749032327521\n",
            "Epoch: 4\n",
            "Train:  0.18214753935891356\n",
            "Test 0.17781758365722802\n",
            "0.1689516827715001\n",
            "Epoch: 5\n",
            "Train:  0.20255389864191467\n",
            "Test 0.24854944521841002\n",
            "0.1905271019445935\n",
            "Epoch: 6\n",
            "Train:  0.23827580191133604\n",
            "Test 0.23491604708053254\n",
            "0.20176075976920027\n",
            "Epoch: 7\n",
            "Train:  0.20604239176658593\n",
            "Test 0.11720397661102343\n",
            "0.18144017468563062\n",
            "Epoch: 8\n",
            "Train:  0.12935315598921351\n",
            "Test 0.16030945084415948\n",
            "0.17655887264818923\n",
            "Epoch: 9\n",
            "Train:  0.15393973502497643\n",
            "Test 0.1252962908312685\n",
            "0.16507307853240838\n",
            "Epoch: 10\n",
            "Train:  0.10629152996109921\n",
            "Test 0.12505900568069528\n",
            "0.15631822803030795\n",
            "Epoch: 11\n",
            "Train:  0.09695029641064941\n",
            "Test 0.13859602965622622\n",
            "0.15251224305985714\n",
            "Epoch: 12\n",
            "Train:  0.09462118012943192\n",
            "Test 0.14456309089880615\n",
            "0.15082992628486144\n",
            "Epoch: 13\n",
            "Train:  0.17095785677320435\n",
            "Test 0.12936794476953742\n",
            "0.14634006373873326\n",
            "Epoch: 14\n",
            "Train:  0.12468947133884319\n",
            "Test 0.20358391067920587\n",
            "0.1582063406282165\n",
            "Epoch: 15\n",
            "Train:  0.14748229548990072\n",
            "Test 0.23628539654798122\n",
            "0.17427442827169265\n",
            "Epoch: 16\n",
            "Train:  0.14038652484091987\n",
            "Test 0.17039951288826582\n",
            "0.17348159211183684\n",
            "Epoch: 17\n",
            "Train:  0.12329355150864386\n",
            "Test 0.3372912778597557\n",
            "0.2068445427496626\n",
            "Epoch: 18\n",
            "Train:  0.24940108098413782\n",
            "Test 0.13388861803126423\n",
            "0.19204000188690154\n",
            "Epoch: 19\n",
            "Train:  0.09177688056528023\n",
            "Test 0.13944810918180933\n",
            "0.18139894025804557\n",
            "Epoch: 20\n",
            "Train:  0.07833682058850046\n",
            "Test 0.20025801238341262\n",
            "0.18520586738835906\n",
            "Epoch: 21\n",
            "Train:  0.10156975091059676\n",
            "Test 0.3093079717747949\n",
            "0.2102107920439277\n",
            "Epoch: 22\n",
            "Train:  0.1596374851687203\n",
            "Test 0.8031421850767043\n",
            "0.329501237150103\n",
            "Epoch: 23\n",
            "Train:  0.4535667586814549\n",
            "Test 0.15753320136684038\n",
            "0.2949444401334637\n",
            "Epoch: 24\n",
            "Train:  0.09510694415224955\n",
            "Test 0.23734034796094228\n",
            "0.2833799322233229\n",
            "Epoch: 25\n",
            "Train:  0.15346122602193898\n",
            "Test 0.21503652363415166\n",
            "0.2696698142163672\n",
            "Epoch: 26\n",
            "Train:  0.1332025151517909\n",
            "Test 0.16180980756158306\n",
            "0.24804552857091536\n",
            "Epoch: 27\n",
            "Train:  0.08306814807476604\n",
            "Test 0.20178050130534067\n",
            "0.238774590515581\n",
            "Epoch: 28\n",
            "Train:  0.10318052449581915\n",
            "Test 0.272107981776498\n",
            "0.24545160094094975\n",
            "Epoch: 29\n",
            "Train:  0.151265057584722\n",
            "Test 0.2266144483339983\n",
            "0.24167950078574513\n",
            "Epoch: 30\n",
            "Train:  0.13701319463387454\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-10-15 12:19:19,193]\u001b[0m Trial 1 finished with value: 0.233908620886667 and parameters: {'layer_size1': 512, 'layer_size2': 256, 'layer_size3': 512, 'layer_size4': 64, 'layer_size5': 192, 'learning_rate': 0.0005269523924132061, 'b1': 0.9230938601001594}. Best is trial 1 with value: 0.233908620886667.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test 0.2040218402131432\n",
            "0.23414050240886727\n",
            "Epoch: 0\n",
            "Train:  0.6929705677888333\n",
            "Test 0.693074603438814\n",
            "0.693074603438814\n",
            "Epoch: 1\n",
            "Train:  1.0394057285436344\n",
            "Test 0.6930069822968145\n",
            "0.6930370361377033\n",
            "Epoch: 2\n",
            "Train:  1.0392805754920065\n",
            "Test 0.6929437256121374\n",
            "0.6929987941190286\n",
            "Epoch: 3\n",
            "Train:  1.0391673466443143\n",
            "Test 0.6928736028217134\n",
            "0.6929563851429733\n",
            "Epoch: 4\n",
            "Train:  1.039056318583506\n",
            "Test 0.6928022161071554\n",
            "0.6929105233403144\n",
            "Epoch: 5\n",
            "Train:  1.0389459224847646\n",
            "Test 0.6927354372901358\n",
            "0.6928630652861201\n",
            "Epoch: 6\n",
            "Train:  1.0388382084858723\n",
            "Test 0.6926811817801479\n",
            "0.6928170354229689\n",
            "Epoch: 7\n",
            "Train:  1.038722582024969\n",
            "Test 0.6926118635432624\n",
            "0.6927677287620173\n",
            "Epoch: 8\n",
            "Train:  1.0386082369547625\n",
            "Test 0.6925467610795856\n",
            "0.6927166841311492\n",
            "Epoch: 9\n",
            "Train:  1.0384971082428873\n",
            "Test 0.6924737770478804\n",
            "0.6926622588437601\n",
            "Epoch: 10\n",
            "Train:  1.0383830343410645\n",
            "Test 0.6924064272925967\n",
            "0.6926062843621708\n",
            "Epoch: 11\n",
            "Train:  1.0382666262514861\n",
            "Test 0.6923312747871483\n",
            "0.6925472238389121\n",
            "Epoch: 12\n",
            "Train:  1.0381467167711083\n",
            "Test 0.6922626707143399\n",
            "0.6924870025115117\n",
            "Epoch: 13\n",
            "Train:  1.038020005265435\n",
            "Test 0.6921831258050688\n",
            "0.6924234312777967\n",
            "Epoch: 14\n",
            "Train:  1.037892684722558\n",
            "Test 0.6921108079043937\n",
            "0.6923586264872525\n",
            "Epoch: 15\n",
            "Train:  1.0377653963836557\n",
            "Test 0.6920293148183997\n",
            "0.6922908566007597\n",
            "Epoch: 16\n",
            "Train:  1.0376291103633768\n",
            "Test 0.6919453611304035\n",
            "0.6922201656888661\n",
            "Epoch: 17\n",
            "Train:  1.0374908558614961\n",
            "Test 0.6918598044486273\n",
            "0.6921467712847748\n",
            "Epoch: 18\n",
            "Train:  1.0373391518881032\n",
            "Test 0.6917646472707336\n",
            "0.6920692289795767\n",
            "Epoch: 19\n",
            "Train:  1.0371842572103926\n",
            "Test 0.6916679340404469\n",
            "0.6919880338759402\n",
            "Epoch: 20\n",
            "Train:  1.037027310539078\n",
            "Test 0.6915745300687713\n",
            "0.691904563233719\n",
            "Epoch: 21\n",
            "Train:  1.03686022179904\n",
            "Test 0.6914766387188391\n",
            "0.6918183421312991\n",
            "Epoch: 22\n",
            "Train:  1.036689443575157\n",
            "Test 0.6913623486683046\n",
            "0.6917266018999582\n",
            "Epoch: 23\n",
            "Train:  1.0365106151217507\n",
            "Test 0.6912449349413862\n",
            "0.6916298114281638\n",
            "Epoch: 24\n",
            "Train:  1.0363215162203863\n",
            "Test 0.6911201852581876\n",
            "0.6915274996712795\n",
            "Epoch: 25\n",
            "Train:  1.0361206728023487\n",
            "Test 0.6909868653877315\n",
            "0.6914190450305311\n",
            "Epoch: 26\n",
            "Train:  1.0359157366412026\n",
            "Test 0.6908447829794971\n",
            "0.6913039142511808\n",
            "Epoch: 27\n",
            "Train:  1.0356993555149316\n",
            "Test 0.6907072958055434\n",
            "0.6911843593091633\n",
            "Epoch: 28\n",
            "Train:  1.035480259975671\n",
            "Test 0.6905566879681179\n",
            "0.6910586304850224\n",
            "Epoch: 29\n",
            "Train:  1.0352549523442656\n",
            "Test 0.6904148470351111\n",
            "0.6909297142044145\n",
            "Epoch: 30\n",
            "Train:  1.0350076370623522\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-10-15 12:19:51,938]\u001b[0m Trial 2 finished with value: 0.6901119435644876 and parameters: {'layer_size1': 512, 'layer_size2': 512, 'layer_size3': 256, 'layer_size4': 256, 'layer_size5': 256, 'learning_rate': 1.0054696708431635e-06, 'b1': 0.976046039775625}. Best is trial 1 with value: 0.233908620886667.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test 0.6902621792349624\n",
            "0.6907960748605284\n",
            "Epoch: 0\n",
            "Train:  0.6925960106727405\n",
            "Test 0.6934735530462021\n",
            "0.6934735530462021\n",
            "Epoch: 1\n",
            "Train:  1.0383139580160707\n",
            "Test 0.6923690348754435\n",
            "0.6928599318402252\n",
            "Epoch: 2\n",
            "Train:  1.036174672427195\n",
            "Test 0.6899548768997192\n",
            "0.6916693355531325\n",
            "Epoch: 3\n",
            "Train:  1.032114484807947\n",
            "Test 0.6859659642090291\n",
            "0.6897372991899539\n",
            "Epoch: 4\n",
            "Train:  1.0245330883906438\n",
            "Test 0.6781944870512128\n",
            "0.6863035735418277\n",
            "Epoch: 5\n",
            "Train:  1.008844670358595\n",
            "Test 0.6596906706963703\n",
            "0.6790899972219341\n",
            "Epoch: 6\n",
            "Train:  0.9734861155351003\n",
            "Test 0.619016483371511\n",
            "0.6638869934819093\n",
            "Epoch: 7\n",
            "Train:  0.906411275213018\n",
            "Test 0.5576580579464252\n",
            "0.6383581826371569\n",
            "Epoch: 8\n",
            "Train:  0.806871609155075\n",
            "Test 0.4683538474442758\n",
            "0.5990863378117454\n",
            "Epoch: 9\n",
            "Train:  0.6761872648319482\n",
            "Test 0.37456966358008403\n",
            "0.5487815696088004\n",
            "Epoch: 10\n",
            "Train:  0.5507817959119549\n",
            "Test 0.3011257012030144\n",
            "0.49459588069141525\n",
            "Epoch: 11\n",
            "Train:  0.45592365787797795\n",
            "Test 0.25394024342407673\n",
            "0.4429131425141201\n",
            "Epoch: 12\n",
            "Train:  0.3900317532238943\n",
            "Test 0.21195901744749956\n",
            "0.3940352256014484\n",
            "Epoch: 13\n",
            "Train:  0.33833475020669757\n",
            "Test 0.1872916694853332\n",
            "0.3507843194073343\n",
            "Epoch: 14\n",
            "Train:  0.3018824373245676\n",
            "Test 0.1747165398719983\n",
            "0.3142866146766338\n",
            "Epoch: 15\n",
            "Train:  0.2804094259064276\n",
            "Test 0.1629875539546157\n",
            "0.2831503958863447\n",
            "Epoch: 16\n",
            "Train:  0.2657457296071308\n",
            "Test 0.15697037597824803\n",
            "0.25733303665771673\n",
            "Epoch: 17\n",
            "Train:  0.2586631814884397\n",
            "Test 0.15403556478492944\n",
            "0.2362945465381068\n",
            "Epoch: 18\n",
            "Train:  0.25345048959957156\n",
            "Test 0.15098230161400505\n",
            "0.21898260619950083\n",
            "Epoch: 19\n",
            "Train:  0.2469241116264146\n",
            "Test 0.14871498931458582\n",
            "0.20476516690751612\n",
            "Epoch: 20\n",
            "Train:  0.2403391185506578\n",
            "Test 0.15099917681062178\n",
            "0.19391186484538986\n",
            "Epoch: 21\n",
            "Train:  0.23839217977727944\n",
            "Test 0.14676632704179146\n",
            "0.1844126655654614\n",
            "Epoch: 22\n",
            "Train:  0.23342143720691347\n",
            "Test 0.1458685349659387\n",
            "0.17665806435952824\n",
            "Epoch: 23\n",
            "Train:  0.23155813370131967\n",
            "Test 0.14701783572470312\n",
            "0.17070189140101774\n",
            "Epoch: 24\n",
            "Train:  0.23194357085522715\n",
            "Test 0.1431770994713455\n",
            "0.16517605700296228\n",
            "Epoch: 25\n",
            "Train:  0.2254800949204754\n",
            "Test 0.1451469039332954\n",
            "0.16115808280715926\n",
            "Epoch: 26\n",
            "Train:  0.22364362312187425\n",
            "Test 0.15126548697933173\n",
            "0.15917476828131635\n",
            "Epoch: 27\n",
            "Train:  0.228924738366034\n",
            "Test 0.15245316790300847\n",
            "0.15782784287300966\n",
            "Epoch: 28\n",
            "Train:  0.23043945510172364\n",
            "Test 0.16422139336065059\n",
            "0.1591085347452211\n",
            "Epoch: 29\n",
            "Train:  0.24173463506439885\n",
            "Test 0.1465834875151024\n",
            "0.15660042040403127\n",
            "Epoch: 30\n",
            "Train:  0.21849916555028367\n",
            "Test 0.13902900930180218\n",
            "0.15308265435683452\n",
            "Epoch: 31\n",
            "Train:  0.22168025520422083\n",
            "Test 0.15154330164958268\n",
            "0.15277453970180455\n",
            "Epoch: 32\n",
            "Train:  0.22231681164586065\n",
            "Test 0.15236473148995702\n",
            "0.15269252607712475\n",
            "Epoch: 33\n",
            "Train:  0.22683338801830244\n",
            "Test 0.13828921876165456\n",
            "0.14981040320411476\n",
            "Epoch: 34\n",
            "Train:  0.20786582163429304\n",
            "Test 0.13701301280941283\n",
            "0.1472498864561848\n",
            "Epoch: 35\n",
            "Train:  0.20316005833856352\n",
            "Test 0.1360093449266293\n",
            "0.14500104836058753\n",
            "Epoch: 36\n",
            "Train:  0.20050104299130347\n",
            "Test 0.1362784846307157\n",
            "0.14325608259560016\n",
            "Epoch: 37\n",
            "Train:  0.20117686987741962\n",
            "Test 0.13517165407129042\n",
            "0.14163886100695525\n",
            "Epoch: 38\n",
            "Train:  0.1974074581719853\n",
            "Test 0.1355126749437589\n",
            "0.14041342018303468\n",
            "Epoch: 39\n",
            "Train:  0.1963926576309916\n",
            "Test 0.137044355976003\n",
            "0.13973951776463225\n",
            "Epoch: 40\n",
            "Train:  0.1964433202451784\n",
            "Test 0.1386006979455987\n",
            "0.1395117295782308\n",
            "Epoch: 41\n",
            "Train:  0.1939689477346155\n",
            "Test 0.13254218489859568\n",
            "0.13811770205155718\n",
            "Epoch: 42\n",
            "Train:  0.18630086210293648\n",
            "Test 0.14772100632007307\n",
            "0.14003849362756113\n",
            "Epoch: 43\n",
            "Train:  0.1986394103739288\n",
            "Test 0.13001365307377372\n",
            "0.13803341635001296\n",
            "Epoch: 44\n",
            "Train:  0.18381689962736525\n",
            "Test 0.13033533636685257\n",
            "0.13649373329072542\n",
            "Epoch: 45\n",
            "Train:  0.18268024572768274\n",
            "Test 0.1294327031125079\n",
            "0.13508147804516882\n",
            "Epoch: 46\n",
            "Train:  0.18011559370987035\n",
            "Test 0.1284485101263165\n",
            "0.1337548474803356\n",
            "Epoch: 47\n",
            "Train:  0.17603841353712718\n",
            "Test 0.12837538614377872\n",
            "0.13267893121928984\n",
            "Epoch: 48\n",
            "Train:  0.1744039129370298\n",
            "Test 0.1268389752277961\n",
            "0.13151091918296004\n",
            "Epoch: 49\n",
            "Train:  0.17270972504666\n",
            "Test 0.12582700586990342\n",
            "0.13037412029541284\n",
            "Epoch: 50\n",
            "Train:  0.16936446181515524\n",
            "Test 0.12594136918789192\n",
            "0.129487559951179\n",
            "Epoch: 51\n",
            "Train:  0.16854776772789848\n",
            "Test 0.12562739774721227\n",
            "0.1287155204582795\n",
            "Epoch: 52\n",
            "Train:  0.16394176853704692\n",
            "Test 0.12455663598064101\n",
            "0.12788373748449092\n",
            "Epoch: 53\n",
            "Train:  0.16455238345062068\n",
            "Test 0.14060774137139756\n",
            "0.13042855313888121\n",
            "Epoch: 54\n",
            "Train:  0.1718795544744193\n",
            "Test 0.12437491432077936\n",
            "0.12921781971289642\n",
            "Epoch: 55\n",
            "Train:  0.16203362997894213\n",
            "Test 0.12352754326192696\n",
            "0.12807976016471626\n",
            "Epoch: 56\n",
            "Train:  0.15899132680183706\n",
            "Test 0.12220114921543733\n",
            "0.12690403445573076\n",
            "Epoch: 57\n",
            "Train:  0.15474079654555453\n",
            "Test 0.12185939966322301\n",
            "0.12589510508132332\n",
            "Epoch: 58\n",
            "Train:  0.1522848183637137\n",
            "Test 0.12097052279211608\n",
            "0.12491018673675316\n",
            "Epoch: 59\n",
            "Train:  0.1510471989095361\n",
            "Test 0.12341760929022326\n",
            "0.12461167078997283\n",
            "Epoch: 60\n",
            "Train:  0.15067320358180425\n",
            "Test 0.12054588052788716\n",
            "0.1237985117406256\n",
            "Epoch: 61\n",
            "Train:  0.14627392163957323\n",
            "Test 0.12019032301319825\n",
            "0.1230768732873592\n",
            "Epoch: 62\n",
            "Train:  0.14503248259356935\n",
            "Test 0.11987114311690568\n",
            "0.12243572675020073\n",
            "Epoch: 63\n",
            "Train:  0.1430122713079069\n",
            "Test 0.12018326227126759\n",
            "0.12198523357163495\n",
            "Epoch: 64\n",
            "Train:  0.14241444639820647\n",
            "Test 0.1195889793527432\n",
            "0.12150598248719198\n",
            "Epoch: 65\n",
            "Train:  0.13923385046804562\n",
            "Test 0.11891752014775853\n",
            "0.12098828981133027\n",
            "Epoch: 66\n",
            "Train:  0.1372844577176776\n",
            "Test 0.118851556970598\n",
            "0.12056094310583988\n",
            "Epoch: 67\n",
            "Train:  0.13538314839748278\n",
            "Test 0.12246904172167018\n",
            "0.12094256292712424\n",
            "Epoch: 68\n",
            "Train:  0.13248010196351198\n",
            "Test 0.12005571554663963\n",
            "0.12076519341454453\n",
            "Epoch: 69\n",
            "Train:  0.13511400770962292\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-10-15 12:21:02,085]\u001b[0m Trial 3 finished with value: 0.12057808925100155 and parameters: {'layer_size1': 384, 'layer_size2': 256, 'layer_size3': 512, 'layer_size4': 64, 'layer_size5': 192, 'learning_rate': 1.713644852336342e-05, 'b1': 0.9308401877808863}. Best is trial 3 with value: 0.12057808925100155.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test 0.11982977195666769\n",
            "0.12057810909218435\n",
            "Epoch: 0\n",
            "Train:  0.6909379616325155\n",
            "Test 0.673991261384426\n",
            "0.673991261384426\n",
            "Epoch: 1\n",
            "Train:  0.9186005746816104\n",
            "Test 0.3803254299329751\n",
            "0.5108435772447311\n",
            "Epoch: 2\n",
            "Train:  0.534604263775078\n",
            "Test 0.20556570818108735\n",
            "0.38572969648094263\n",
            "Epoch: 3\n",
            "Train:  0.32007359620183706\n",
            "Test 0.15322471756638187\n",
            "0.3069678472551429\n",
            "Epoch: 4\n",
            "Train:  0.2675576919328162\n",
            "Test 0.15617165515274356\n",
            "0.26210938934748007\n",
            "Epoch: 5\n",
            "Train:  0.24731574130445827\n",
            "Test 0.144159994296211\n",
            "0.23013854542908166\n",
            "Epoch: 6\n",
            "Train:  0.2286518540765558\n",
            "Test 0.14238954682053226\n",
            "0.2079316148115247\n",
            "Epoch: 7\n",
            "Train:  0.22026554658845232\n",
            "Test 0.17695931511702556\n",
            "0.20048838876071168\n",
            "Epoch: 8\n",
            "Train:  0.2377766184645258\n",
            "Test 0.14364166137499687\n",
            "0.18735651271654274\n",
            "Epoch: 9\n",
            "Train:  0.19320570916319504\n",
            "Test 0.13279651274611226\n",
            "0.1751319055195146\n",
            "Epoch: 10\n",
            "Train:  0.1812976391460651\n",
            "Test 0.1916436377244118\n",
            "0.17874457817896378\n",
            "Epoch: 11\n",
            "Train:  0.2228974924856053\n",
            "Test 0.12912043590685388\n",
            "0.16808739357508423\n",
            "Epoch: 12\n",
            "Train:  0.16589801111036823\n",
            "Test 0.1286972727039795\n",
            "0.15975107546618453\n",
            "Epoch: 13\n",
            "Train:  0.15319924083139216\n",
            "Test 0.2346445394632144\n",
            "0.175418844013556\n",
            "Epoch: 14\n",
            "Train:  0.21454648797710738\n",
            "Test 0.1353828666574789\n",
            "0.1671196464885832\n",
            "Epoch: 15\n",
            "Train:  0.1502783162759842\n",
            "Test 0.13414024011719794\n",
            "0.16033273051268074\n",
            "Epoch: 16\n",
            "Train:  0.13260092741072915\n",
            "Test 0.14877535814194234\n",
            "0.1579680072034619\n",
            "Epoch: 17\n",
            "Train:  0.13598681162384377\n",
            "Test 0.23180970483742683\n",
            "0.17300727000362587\n",
            "Epoch: 18\n",
            "Train:  0.1879703765648678\n",
            "Test 0.1420116670900485\n",
            "0.16671750434482321\n",
            "Epoch: 19\n",
            "Train:  0.1183893742268366\n",
            "Test 0.18068942008710606\n",
            "0.1695444803070787\n",
            "Epoch: 20\n",
            "Train:  0.1338841346068642\n",
            "Test 0.1481682731200269\n",
            "0.16522943964428122\n",
            "Epoch: 21\n",
            "Train:  0.10894231268310503\n",
            "Test 0.1805054114205292\n",
            "0.16830734493198096\n",
            "Epoch: 22\n",
            "Train:  0.13184461257069316\n",
            "Test 0.16449685170291325\n",
            "0.16754072093684294\n",
            "Epoch: 23\n",
            "Train:  0.10004230991480087\n",
            "Test 0.16673831396181765\n",
            "0.1673794780940414\n",
            "Epoch: 24\n",
            "Train:  0.0966216996570298\n",
            "Test 0.1838713316690354\n",
            "0.17069035695573245\n",
            "Epoch: 25\n",
            "Train:  0.10695494596706799\n",
            "Test 0.25620044774423617\n",
            "0.18784421948171764\n",
            "Epoch: 26\n",
            "Train:  0.14884833054895932\n",
            "Test 0.1916046349482373\n",
            "0.18859812540770055\n",
            "Epoch: 27\n",
            "Train:  0.10598974690550103\n",
            "Test 0.20730940512717946\n",
            "0.192347633955908\n",
            "Epoch: 28\n",
            "Train:  0.12298605129091392\n",
            "Test 0.2605975017033862\n",
            "0.2060187625522432\n",
            "Epoch: 29\n",
            "Train:  0.14778430876631252\n",
            "Test 0.17891493409044396\n",
            "0.20059127795939324\n",
            "Epoch: 30\n",
            "Train:  0.10640387856529665\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-10-15 12:21:31,706]\u001b[0m Trial 4 finished with value: 0.1991742725408514 and parameters: {'layer_size1': 256, 'layer_size2': 256, 'layer_size3': 512, 'layer_size4': 128, 'layer_size5': 192, 'learning_rate': 0.00012426777723393675, 'b1': 0.9039033906640599}. Best is trial 3 with value: 0.12057808925100155.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test 0.19449953076475354\n",
            "0.1993717207294852\n",
            "Epoch: 0\n",
            "Train:  0.6928937310700888\n",
            "Test 0.694334599561307\n",
            "0.694334599561307\n",
            "Epoch: 1\n",
            "Train:  1.0397899790561242\n",
            "Test 0.6939776105321808\n",
            "0.6941362723229036\n",
            "Epoch: 2\n",
            "Train:  1.0392927667160174\n",
            "Test 0.6936681342648936\n",
            "0.6939444124630635\n",
            "Epoch: 3\n",
            "Train:  1.0388308585563422\n",
            "Test 0.6933097435441209\n",
            "0.6937294162168092\n",
            "Epoch: 4\n",
            "Train:  1.038324013188645\n",
            "Test 0.6928903667918055\n",
            "0.6934798179823364\n",
            "Epoch: 5\n",
            "Train:  1.0377594512024206\n",
            "Test 0.6925062301394703\n",
            "0.6932159215464829\n",
            "Epoch: 6\n",
            "Train:  1.03712393894737\n",
            "Test 0.692049163601774\n",
            "0.6929206462369467\n",
            "Epoch: 7\n",
            "Train:  1.0363974361629276\n",
            "Test 0.6914525748172522\n",
            "0.6925678410677049\n",
            "Epoch: 8\n",
            "Train:  1.035543529978602\n",
            "Test 0.6907833471839682\n",
            "0.6921556141276419\n",
            "Epoch: 9\n",
            "Train:  1.0346054407484802\n",
            "Test 0.690070343541575\n",
            "0.6916883924665715\n",
            "Epoch: 10\n",
            "Train:  1.033513109544258\n",
            "Test 0.6893175827277885\n",
            "0.6911696728423812\n",
            "Epoch: 11\n",
            "Train:  1.0323484963549798\n",
            "Test 0.6883796418542827\n",
            "0.6905704911955193\n",
            "Epoch: 12\n",
            "Train:  1.0309074481764993\n",
            "Test 0.6873028501049503\n",
            "0.6898789448129672\n",
            "Epoch: 13\n",
            "Train:  1.0293428696992197\n",
            "Test 0.6861385345022321\n",
            "0.6890964481851825\n",
            "Epoch: 14\n",
            "Train:  1.0274829046848493\n",
            "Test 0.6846759847668937\n",
            "0.6881801148899064\n",
            "Epoch: 15\n",
            "Train:  1.0254068573315938\n",
            "Test 0.6831056359923366\n",
            "0.6871358249620809\n",
            "Epoch: 16\n",
            "Train:  1.0230628171246567\n",
            "Test 0.681370850666102\n",
            "0.6859562688607942\n",
            "Epoch: 17\n",
            "Train:  1.0205008141942076\n",
            "Test 0.6794513743439\n",
            "0.6846314236681517\n",
            "Epoch: 18\n",
            "Train:  1.017721795118772\n",
            "Test 0.6771673732624822\n",
            "0.6831167853483857\n",
            "Epoch: 19\n",
            "Train:  1.0143660544912456\n",
            "Test 0.6748669282857315\n",
            "0.6814475691837342\n",
            "Epoch: 20\n",
            "Train:  1.0107862984304463\n",
            "Test 0.6721808969319522\n",
            "0.6795769816082415\n",
            "Epoch: 21\n",
            "Train:  1.0066776824739827\n",
            "Test 0.6689558077207852\n",
            "0.6774369562305691\n",
            "Epoch: 22\n",
            "Train:  1.0016957628421295\n",
            "Test 0.665045474256788\n",
            "0.6749439436872178\n",
            "Epoch: 23\n",
            "Train:  0.9961081938647525\n",
            "Test 0.6607310145329206\n",
            "0.6720878704317441\n",
            "Epoch: 24\n",
            "Train:  0.989694357245833\n",
            "Test 0.655967252595084\n",
            "0.6688515202792223\n",
            "Epoch: 25\n",
            "Train:  0.982424971821544\n",
            "Test 0.6504221464688088\n",
            "0.6651544718739559\n",
            "Epoch: 26\n",
            "Train:  0.9741504417234288\n",
            "Test 0.6441828302848034\n",
            "0.6609499777130263\n",
            "Epoch: 27\n",
            "Train:  0.9647965181223203\n",
            "Test 0.6366642503948002\n",
            "0.6560834189557261\n",
            "Epoch: 28\n",
            "Train:  0.9541430737509395\n",
            "Test 0.6281841875432612\n",
            "0.6504949248975407\n",
            "Epoch: 29\n",
            "Train:  0.9416544570590987\n",
            "Test 0.6190010189136743\n",
            "0.6441883365225066\n",
            "Epoch: 30\n",
            "Train:  0.9278479503406273\n",
            "Test 0.6081383346201299\n",
            "0.6369711886249497\n",
            "Epoch: 31\n",
            "Train:  0.9121437703733479\n",
            "Test 0.5969171917045509\n",
            "0.6289540373992678\n",
            "Epoch: 32\n",
            "Train:  0.8956847317489512\n",
            "Test 0.5839874670182392\n",
            "0.6199550195178527\n",
            "Epoch: 33\n",
            "Train:  0.8766269744970859\n",
            "Test 0.5691790310017791\n",
            "0.6097946699053242\n",
            "Epoch: 34\n",
            "Train:  0.8553990842876854\n",
            "Test 0.5530921067946997\n",
            "0.5984495551579131\n",
            "Epoch: 35\n",
            "Train:  0.8326032834175305\n",
            "Test 0.5360715293185615\n",
            "0.5859699001104366\n",
            "Epoch: 36\n",
            "Train:  0.8090697535665043\n",
            "Test 0.5184690414112566\n",
            "0.5724662226154887\n",
            "Epoch: 37\n",
            "Train:  0.7842640975565264\n",
            "Test 0.5001869675440666\n",
            "0.5580073686147161\n",
            "Epoch: 38\n",
            "Train:  0.7590243538002391\n",
            "Test 0.4824166913608928\n",
            "0.5428867208154053\n",
            "Epoch: 39\n",
            "Train:  0.7334003904800275\n",
            "Test 0.462478580055656\n",
            "0.5268029547642441\n",
            "Epoch: 40\n",
            "Train:  0.7066458051021283\n",
            "Test 0.4440361241717915\n",
            "0.5102478282027377\n",
            "Epoch: 41\n",
            "Train:  0.6811732246980562\n",
            "Test 0.4249893898492331\n",
            "0.49319468981146297\n",
            "Epoch: 42\n",
            "Train:  0.6555278831785851\n",
            "Test 0.40734955897698033\n",
            "0.47602449510166717\n",
            "Epoch: 43\n",
            "Train:  0.6321326644866021\n",
            "Test 0.39042489803754366\n",
            "0.45890364354101965\n",
            "Epoch: 44\n",
            "Train:  0.6087732320521777\n",
            "Test 0.3744876747166281\n",
            "0.4420197143773088\n",
            "Epoch: 45\n",
            "Train:  0.5876293897410452\n",
            "Test 0.3592106601694128\n",
            "0.42545732642073947\n",
            "Epoch: 46\n",
            "Train:  0.5670454323073446\n",
            "Test 0.3452773111643809\n",
            "0.4094208763384838\n",
            "Epoch: 47\n",
            "Train:  0.5496322650175828\n",
            "Test 0.33328644150779363\n",
            "0.39419364979384647\n",
            "Epoch: 48\n",
            "Train:  0.5327110684616662\n",
            "Test 0.32189585503204404\n",
            "0.3797338328697317\n",
            "Epoch: 49\n",
            "Train:  0.520011245221882\n",
            "Test 0.31203505173052626\n",
            "0.36619388339327413\n",
            "Epoch: 50\n",
            "Train:  0.5049909572952833\n",
            "Test 0.3029346335611064\n",
            "0.35354188896660177\n",
            "Epoch: 51\n",
            "Train:  0.4929548992396711\n",
            "Test 0.294771487677927\n",
            "0.3417877013415889\n",
            "Epoch: 52\n",
            "Train:  0.4821928329629339\n",
            "Test 0.28734828002286916\n",
            "0.3308997375139602\n",
            "Epoch: 53\n",
            "Train:  0.47218465966073586\n",
            "Test 0.28072174783154724\n",
            "0.3208640809089633\n",
            "Epoch: 54\n",
            "Train:  0.4621153727119222\n",
            "Test 0.27363355244909016\n",
            "0.31141793103918547\n",
            "Epoch: 55\n",
            "Train:  0.4531135761584991\n",
            "Test 0.2674889074358748\n",
            "0.30263209344680236\n",
            "Epoch: 56\n",
            "Train:  0.4438393486615939\n",
            "Test 0.2622333584905981\n",
            "0.29455232227155115\n",
            "Epoch: 57\n",
            "Train:  0.43644581931632953\n",
            "Test 0.25717282338893455\n",
            "0.28707640459376144\n",
            "Epoch: 58\n",
            "Train:  0.4280684328341222\n",
            "Test 0.2520481685360709\n",
            "0.28007074396204373\n",
            "Epoch: 59\n",
            "Train:  0.42114060653216673\n",
            "Test 0.24739419229519674\n",
            "0.27353542361332506\n",
            "Epoch: 60\n",
            "Train:  0.4137739830619686\n",
            "Test 0.24292830997334294\n",
            "0.267413993380477\n",
            "Epoch: 61\n",
            "Train:  0.40606297923750057\n",
            "Test 0.23829461088329007\n",
            "0.26159011116899256\n",
            "Epoch: 62\n",
            "Train:  0.3995957747101784\n",
            "Test 0.2340588608940879\n",
            "0.25608385679359674\n",
            "Epoch: 63\n",
            "Train:  0.3932183596950311\n",
            "Test 0.23006606514091457\n",
            "0.2508802951967317\n",
            "Epoch: 64\n",
            "Train:  0.3861096335008686\n",
            "Test 0.22601742753179083\n",
            "0.2459077191666743\n",
            "Epoch: 65\n",
            "Train:  0.3797220539697361\n",
            "Test 0.2221591287043505\n",
            "0.2411579991660831\n",
            "Epoch: 66\n",
            "Train:  0.3735833621068752\n",
            "Test 0.21890297279635193\n",
            "0.23670699246163845\n",
            "Epoch: 67\n",
            "Train:  0.36753181615782965\n",
            "Test 0.21555225411941717\n",
            "0.2324760437053746\n",
            "Epoch: 68\n",
            "Train:  0.3616860621769131\n",
            "Test 0.21232942812444963\n",
            "0.2284467197604058\n",
            "Epoch: 69\n",
            "Train:  0.3564662266686395\n",
            "Test 0.20950059232475993\n",
            "0.2246574936497577\n",
            "Epoch: 70\n",
            "Train:  0.3511860087350175\n",
            "Test 0.20646111880029952\n",
            "0.22101821820079054\n",
            "Epoch: 71\n",
            "Train:  0.34533100910894166\n",
            "Test 0.20290719076390668\n",
            "0.21739601233195094\n",
            "Epoch: 72\n",
            "Train:  0.3412514729868798\n",
            "Test 0.20011731813023814\n",
            "0.21394027320046294\n",
            "Epoch: 73\n",
            "Train:  0.3354450605891563\n",
            "Test 0.19848446511141546\n",
            "0.21084911137430953\n",
            "Epoch: 74\n",
            "Train:  0.3320258683405625\n",
            "Test 0.1948076090314886\n",
            "0.20764081073275414\n",
            "Epoch: 75\n",
            "Train:  0.32607665226791366\n",
            "Test 0.19285816306268777\n",
            "0.20468428107120823\n",
            "Epoch: 76\n",
            "Train:  0.3224784047530466\n",
            "Test 0.1897630308082689\n",
            "0.2017000309156377\n",
            "Epoch: 77\n",
            "Train:  0.31691204828820824\n",
            "Test 0.18715866060156525\n",
            "0.19879175677253452\n",
            "Epoch: 78\n",
            "Train:  0.31256423919246745\n",
            "Test 0.18472413631367596\n",
            "0.1959782326186245\n",
            "Epoch: 79\n",
            "Train:  0.3081551290529988\n",
            "Test 0.18254936573815433\n",
            "0.19329245919507693\n",
            "Epoch: 80\n",
            "Train:  0.30414687082062275\n",
            "Test 0.17984327300018443\n",
            "0.1906026219180782\n",
            "Epoch: 81\n",
            "Train:  0.3017989956934155\n",
            "Test 0.17792764327901622\n",
            "0.1880676261616005\n",
            "Epoch: 82\n",
            "Train:  0.29665747858010805\n",
            "Test 0.1772963516004793\n",
            "0.18591337122988832\n",
            "Epoch: 83\n",
            "Train:  0.29443707587299767\n",
            "Test 0.1754957875612127\n",
            "0.18382985448107478\n",
            "Epoch: 84\n",
            "Train:  0.290564502951017\n",
            "Test 0.17348041519140586\n",
            "0.18175996661115718\n",
            "Epoch: 85\n",
            "Train:  0.28660410757248217\n",
            "Test 0.1707617393780104\n",
            "0.17956032115433976\n",
            "Epoch: 86\n",
            "Train:  0.28334465281758114\n",
            "Test 0.1701344532394038\n",
            "0.17767514756436734\n",
            "Epoch: 87\n",
            "Train:  0.28086589635332754\n",
            "Test 0.16778174902384096\n",
            "0.17569646785039672\n",
            "Epoch: 88\n",
            "Train:  0.2779705921126591\n",
            "Test 0.16674727155066235\n",
            "0.17390662858620537\n",
            "Epoch: 89\n",
            "Train:  0.2759450905761876\n",
            "Test 0.16628578889282633\n",
            "0.172382460644638\n",
            "Epoch: 90\n",
            "Train:  0.27391652869326727\n",
            "Test 0.16419121781329968\n",
            "0.17074421207588397\n",
            "Epoch: 91\n",
            "Train:  0.2707506226914706\n",
            "Test 0.16364608302494107\n",
            "0.16932458626397173\n",
            "Epoch: 92\n",
            "Train:  0.26861361066909717\n",
            "Test 0.16186467981163835\n",
            "0.16783260497205582\n",
            "Epoch: 93\n",
            "Train:  0.26945820920196645\n",
            "Test 0.16131547742929214\n",
            "0.1665291794624902\n",
            "Epoch: 94\n",
            "Train:  0.26457381294869675\n",
            "Test 0.15993342458546816\n",
            "0.1652100284862658\n",
            "Epoch: 95\n",
            "Train:  0.2626440287891762\n",
            "Test 0.15983017618621226\n",
            "0.16413405802571998\n",
            "Epoch: 96\n",
            "Train:  0.2610838735005358\n",
            "Test 0.15848763270692512\n",
            "0.16300477296151172\n",
            "Epoch: 97\n",
            "Train:  0.25972291812191517\n",
            "Test 0.15771732520271134\n",
            "0.16194728340941505\n",
            "Epoch: 98\n",
            "Train:  0.2578979850688697\n",
            "Test 0.1577536769402333\n",
            "0.16110856211536514\n",
            "Epoch: 99\n",
            "Train:  0.25692669853513495\n",
            "Test 0.15818434014861837\n",
            "0.16052371772189664\n",
            "Epoch: 100\n",
            "Train:  0.25608461391139814\n",
            "Test 0.1563411359248799\n",
            "0.15968720136235695\n",
            "Epoch: 101\n",
            "Train:  0.254820122844079\n",
            "Test 0.15721608111600735\n",
            "0.1591929773130226\n",
            "Epoch: 102\n",
            "Train:  0.25389028101777417\n",
            "Test 0.15488519735170372\n",
            "0.15833142132066894\n",
            "Epoch: 103\n",
            "Train:  0.2518110165966081\n",
            "Test 0.15418988746000734\n",
            "0.15750311454846752\n",
            "Epoch: 104\n",
            "Train:  0.2501496348202556\n",
            "Test 0.15485856447355215\n",
            "0.15697420453344915\n",
            "Epoch: 105\n",
            "Train:  0.25006539972273856\n",
            "Test 0.15298495774972679\n",
            "0.15617635517666206\n",
            "Epoch: 106\n",
            "Train:  0.24797151410515547\n",
            "Test 0.15343976932349224\n",
            "0.15562903800600472\n",
            "Epoch: 107\n",
            "Train:  0.2473540955356189\n",
            "Test 0.15319755723215503\n",
            "0.15514274185121815\n",
            "Epoch: 108\n",
            "Train:  0.24730223595018025\n",
            "Test 0.1526895555439013\n",
            "0.15465210458974138\n",
            "Epoch: 109\n",
            "Train:  0.2455108041428166\n",
            "Test 0.15165449384149615\n",
            "0.15405258244007924\n",
            "Epoch: 110\n",
            "Train:  0.24451138197884456\n",
            "Test 0.1518386462873919\n",
            "0.15360979520953402\n",
            "Epoch: 111\n",
            "Train:  0.24345107533160473\n",
            "Test 0.15082578142020073\n",
            "0.15305299245165954\n",
            "Epoch: 112\n",
            "Train:  0.2430620507981915\n",
            "Test 0.15131012156551138\n",
            "0.15270441827442602\n",
            "Epoch: 113\n",
            "Train:  0.2420503757075294\n",
            "Test 0.15089946802391674\n",
            "0.1523434282243209\n",
            "Epoch: 114\n",
            "Train:  0.24157638570819145\n",
            "Test 0.15114153970046576\n",
            "0.15210305051954817\n",
            "Epoch: 115\n",
            "Train:  0.2406498463619705\n",
            "Test 0.1494820159382354\n",
            "0.1515788436032826\n",
            "Epoch: 116\n",
            "Train:  0.23910740301466715\n",
            "Test 0.14884160197043156\n",
            "0.1510313952767099\n",
            "Epoch: 117\n",
            "Train:  0.2389863826361768\n",
            "Test 0.14895211517701656\n",
            "0.1506155392567697\n",
            "Epoch: 118\n",
            "Train:  0.2375800164327735\n",
            "Test 0.1489987822843122\n",
            "0.15029218786227727\n",
            "Epoch: 119\n",
            "Train:  0.23699611587784228\n",
            "Test 0.14943657646249064\n",
            "0.15012106558231955\n",
            "Epoch: 120\n",
            "Train:  0.23668865862237665\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-10-15 12:23:34,468]\u001b[0m Trial 5 finished with value: 0.14970388959837735 and parameters: {'layer_size1': 512, 'layer_size2': 512, 'layer_size3': 384, 'layer_size4': 192, 'layer_size5': 192, 'learning_rate': 2.99945591218097e-06, 'b1': 0.9033498018349781}. Best is trial 3 with value: 0.12057808925100155.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test 0.14803518566401888\n",
            "0.14970388959865863\n",
            "Epoch: 0\n",
            "Train:  0.6915342713887002\n",
            "Test 0.6794540065548795\n",
            "0.6794540065548796\n",
            "Epoch: 1\n",
            "Train:  0.9242183498410514\n",
            "Test 0.3465487973375635\n",
            "0.49450666810081517\n",
            "Epoch: 2\n",
            "Train:  0.45232407777355266\n",
            "Test 0.1710718680759926\n",
            "0.36195142218900256\n",
            "Epoch: 3\n",
            "Train:  0.3001175587485125\n",
            "Test 0.1859730329269018\n",
            "0.30233814669371095\n",
            "Epoch: 4\n",
            "Train:  0.28297832646431065\n",
            "Test 0.1562788780410211\n",
            "0.25888881641863665\n",
            "Epoch: 5\n",
            "Train:  0.24863526837784292\n",
            "Test 0.14827186666811124\n",
            "0.22890547285281207\n",
            "Epoch: 6\n",
            "Train:  0.22966668719678243\n",
            "Test 0.1399268522558413\n",
            "0.20638735771331532\n",
            "Epoch: 7\n",
            "Train:  0.21957687009467092\n",
            "Test 0.14133101390613304\n",
            "0.19075309491163298\n",
            "Epoch: 8\n",
            "Train:  0.19911848317026656\n",
            "Test 0.133775931506694\n",
            "0.17759108749992683\n",
            "Epoch: 9\n",
            "Train:  0.1805723363758771\n",
            "Test 0.12849123570931592\n",
            "0.16658987045634513\n",
            "Epoch: 10\n",
            "Train:  0.19326876066863918\n",
            "Test 0.14361120776815728\n",
            "0.1615622703587793\n",
            "Epoch: 11\n",
            "Train:  0.18745656666301547\n",
            "Test 0.14389278514194728\n",
            "0.15776760596380127\n",
            "Epoch: 12\n",
            "Train:  0.17865026861449684\n",
            "Test 0.12844133038660546\n",
            "0.15156114716767968\n",
            "Epoch: 13\n",
            "Train:  0.1463373063623414\n",
            "Test 0.15828714275650763\n",
            "0.15296823046323374\n",
            "Epoch: 14\n",
            "Train:  0.16324206252988332\n",
            "Test 0.18343256693418675\n",
            "0.15928328913136675\n",
            "Epoch: 15\n",
            "Train:  0.1608513706033681\n",
            "Test 0.1961228219014439\n",
            "0.16686459034359707\n",
            "Epoch: 16\n",
            "Train:  0.1599081957891017\n",
            "Test 0.15070398234431343\n",
            "0.16355801120076263\n",
            "Epoch: 17\n",
            "Train:  0.11777741066947743\n",
            "Test 0.15343637011208378\n",
            "0.1614965469443997\n",
            "Epoch: 18\n",
            "Train:  0.12708617158271646\n",
            "Test 0.16820308139802284\n",
            "0.16285746675659335\n",
            "Epoch: 19\n",
            "Train:  0.14179933117260182\n",
            "Test 0.17339105025315896\n",
            "0.16498875554264614\n",
            "Epoch: 20\n",
            "Train:  0.13356488549590603\n",
            "Test 0.2571413043558925\n",
            "0.1835908392439331\n",
            "Epoch: 21\n",
            "Train:  0.16027362293294278\n",
            "Test 0.18281880363944794\n",
            "0.18343528433036405\n",
            "Epoch: 22\n",
            "Train:  0.10945770866424144\n",
            "Test 0.20624977221979576\n",
            "0.18802527643936565\n",
            "Epoch: 23\n",
            "Train:  0.11569041868631344\n",
            "Test 0.20211449675215068\n",
            "0.1908564905324617\n",
            "Epoch: 24\n",
            "Train:  0.11747988514892584\n",
            "Test 0.23676867777644625\n",
            "0.20007374980225026\n",
            "Epoch: 25\n",
            "Train:  0.12442090927570362\n",
            "Test 0.31980756883707323\n",
            "0.22409310766393875\n",
            "Epoch: 26\n",
            "Train:  0.17581900190358923\n",
            "Test 0.29423529176770175\n",
            "0.23815554537275718\n",
            "Epoch: 27\n",
            "Train:  0.14836891575142103\n",
            "Test 0.27366099533788163\n",
            "0.24527039749126817\n",
            "Epoch: 28\n",
            "Train:  0.1412556692358078\n",
            "Test 0.27495371297892324\n",
            "0.2512162613674998\n",
            "Epoch: 29\n",
            "Train:  0.13874598779978195\n",
            "Test 0.2992930396979388\n",
            "0.26084353502111257\n",
            "Epoch: 30\n",
            "Train:  0.1499233043245506\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-10-15 12:24:04,459]\u001b[0m Trial 6 finished with value: 0.27887598685318693 and parameters: {'layer_size1': 384, 'layer_size2': 256, 'layer_size3': 256, 'layer_size4': 128, 'layer_size5': 192, 'learning_rate': 0.00027963513310666423, 'b1': 0.9838721699912112}. Best is trial 3 with value: 0.12057808925100155.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test 0.35229742880544984\n",
            "0.27915244604520595\n",
            "Epoch: 0\n",
            "Train:  0.6761347345816784\n",
            "Test 0.4989851671697456\n",
            "0.4989851671697456\n",
            "Epoch: 1\n",
            "Train:  0.5925717138763749\n",
            "Test 0.1766017531573554\n",
            "0.3198832704961955\n",
            "Epoch: 2\n",
            "Train:  0.26645113343045446\n",
            "Test 0.14020926715471807\n",
            "0.24624638388083592\n",
            "Epoch: 3\n",
            "Train:  0.21726483769796706\n",
            "Test 0.13613251921458122\n",
            "0.20894493921069543\n",
            "Epoch: 4\n",
            "Train:  0.1965559895931583\n",
            "Test 0.12412026400537991\n",
            "0.1837115160772722\n",
            "Epoch: 5\n",
            "Train:  0.2038834997880931\n",
            "Test 0.13412015899442709\n",
            "0.1702695010817053\n",
            "Epoch: 6\n",
            "Train:  0.18488165517525249\n",
            "Test 0.14758870011065905\n",
            "0.16452959542464438\n",
            "Epoch: 7\n",
            "Train:  0.1610512818608965\n",
            "Test 0.12243832847028426\n",
            "0.15441427244906114\n",
            "Epoch: 8\n",
            "Train:  0.11720517932543115\n",
            "Test 0.15001921426991408\n",
            "0.15339899220568212\n",
            "Epoch: 9\n",
            "Train:  0.12107590703412442\n",
            "Test 0.12307008309460385\n",
            "0.14660355597404287\n",
            "Epoch: 10\n",
            "Train:  0.12482025229368672\n",
            "Test 0.22518389118471158\n",
            "0.163796484315125\n",
            "Epoch: 11\n",
            "Train:  0.18861972449073183\n",
            "Test 0.17792219802355155\n",
            "0.1668300952101361\n",
            "Epoch: 12\n",
            "Train:  0.15832972016540311\n",
            "Test 0.14274687532867705\n",
            "0.16173324915893003\n",
            "Epoch: 13\n",
            "Train:  0.1016796771642682\n",
            "Test 0.1670190535984454\n",
            "0.16283904339149857\n",
            "Epoch: 14\n",
            "Train:  0.10912493886004725\n",
            "Test 0.15553354290689278\n",
            "0.1613246606901275\n",
            "Epoch: 15\n",
            "Train:  0.09113488969501388\n",
            "Test 0.15413702274958396\n",
            "0.15984549838446502\n",
            "Epoch: 16\n",
            "Train:  0.10849220587903098\n",
            "Test 0.15193454055657146\n",
            "0.15822685828412256\n",
            "Epoch: 17\n",
            "Train:  0.09617897890021619\n",
            "Test 0.20997877064261652\n",
            "0.16876711717996415\n",
            "Epoch: 18\n",
            "Train:  0.1209201463654505\n",
            "Test 0.21897313319617412\n",
            "0.1789551453426854\n",
            "Epoch: 19\n",
            "Train:  0.12704783608376188\n",
            "Test 0.23699360610507839\n",
            "0.19069822599733477\n",
            "Epoch: 20\n",
            "Train:  0.1533199116483057\n",
            "Test 0.15804885288708403\n",
            "0.18410756324071081\n",
            "Epoch: 21\n",
            "Train:  0.08777687474799684\n",
            "Test 0.18530177100726575\n",
            "0.18434818023406024\n",
            "Epoch: 22\n",
            "Train:  0.0957122069973973\n",
            "Test 0.18988408202191528\n",
            "0.18546193503958594\n",
            "Epoch: 23\n",
            "Train:  0.09604966715030239\n",
            "Test 0.20768783326241982\n",
            "0.1899282060526884\n",
            "Epoch: 24\n",
            "Train:  0.10405853653170774\n",
            "Test 0.38931455686537586\n",
            "0.22995669958821144\n",
            "Epoch: 25\n",
            "Train:  0.19469425871660626\n",
            "Test 0.41619794981915764\n",
            "0.26731786683373576\n",
            "Epoch: 26\n",
            "Train:  0.20811655264315249\n",
            "Test 0.42739677180173574\n",
            "0.29941124485399045\n",
            "Epoch: 27\n",
            "Train:  0.21370612822368576\n",
            "Test 0.4323433363384179\n",
            "0.32604918842730346\n",
            "Epoch: 28\n",
            "Train:  0.21617701846691728\n",
            "Test 0.43730288116402777\n",
            "0.3483344116873459\n",
            "Epoch: 29\n",
            "Train:  0.21865552803347613\n",
            "Test 0.4423112996318239\n",
            "0.3671530856662462\n",
            "Epoch: 30\n",
            "Train:  0.22115872693700964\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-10-15 12:24:32,235]\u001b[0m Trial 7 finished with value: 0.3828498653210193 and parameters: {'layer_size1': 256, 'layer_size2': 256, 'layer_size3': 256, 'layer_size4': 128, 'layer_size5': 256, 'learning_rate': 0.0007566228443206493, 'b1': 0.9676227402960883}. Best is trial 3 with value: 0.12057808925100155.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test 0.4474550379612853\n",
            "0.38322939733317124\n",
            "Epoch: 0\n",
            "Train:  0.5940126196477876\n",
            "Test 0.4310081094066739\n",
            "0.4310081094066739\n",
            "Epoch: 1\n",
            "Train:  0.632055731128642\n",
            "Test 0.2467224190195838\n",
            "0.32862717030273497\n",
            "Epoch: 2\n",
            "Train:  0.32194424840884334\n",
            "Test 0.1585105640110952\n",
            "0.2589072496914072\n",
            "Epoch: 3\n",
            "Train:  0.22427287714166955\n",
            "Test 0.13964881095694098\n",
            "0.21850804957810563\n",
            "Epoch: 4\n",
            "Train:  0.21075735243903848\n",
            "Test 0.16214457710679525\n",
            "0.20174119079915798\n",
            "Epoch: 5\n",
            "Train:  0.20251312864698714\n",
            "Test 0.1494716926590427\n",
            "0.18757325067530853\n",
            "Epoch: 6\n",
            "Train:  0.20615818325580257\n",
            "Test 0.14302281958934587\n",
            "0.17629872506480387\n",
            "Epoch: 7\n",
            "Train:  0.18391674694233326\n",
            "Test 0.17712280599079727\n",
            "0.17649676720816534\n",
            "Epoch: 8\n",
            "Train:  0.17144825606992392\n",
            "Test 0.2003342027438211\n",
            "0.18200333307502933\n",
            "Epoch: 9\n",
            "Train:  0.168785478121468\n",
            "Test 0.17824969879068406\n",
            "0.18116230109716483\n",
            "Epoch: 10\n",
            "Train:  0.15343198848669945\n",
            "Test 0.1758146378358369\n",
            "0.1799922629317923\n",
            "Epoch: 11\n",
            "Train:  0.1320071626410243\n",
            "Test 0.14625695178578624\n",
            "0.1727473329019515\n",
            "Epoch: 12\n",
            "Train:  0.12552303489768407\n",
            "Test 0.22331742859094134\n",
            "0.18344972210863617\n",
            "Epoch: 13\n",
            "Train:  0.14899354728259445\n",
            "Test 0.150620109030756\n",
            "0.17658174255805237\n",
            "Epoch: 14\n",
            "Train:  0.10228789734340489\n",
            "Test 0.17963590486926193\n",
            "0.17721485052663324\n",
            "Epoch: 15\n",
            "Train:  0.10394272280974715\n",
            "Test 0.24399010968077314\n",
            "0.19095670106344217\n",
            "Epoch: 16\n",
            "Train:  0.13023300309159755\n",
            "Test 0.24663102238749515\n",
            "0.2023480762944815\n",
            "Epoch: 17\n",
            "Train:  0.1582744081469252\n",
            "Test 0.27558461000849477\n",
            "0.2172640859799291\n",
            "Epoch: 18\n",
            "Train:  0.2129587390623823\n",
            "Test 0.15166230084913554\n",
            "0.20395187984468183\n",
            "Epoch: 19\n",
            "Train:  0.09351789178347915\n",
            "Test 0.21302661013022114\n",
            "0.2057879948667282\n",
            "Epoch: 20\n",
            "Train:  0.13525432820109187\n",
            "Test 0.2656863639646369\n",
            "0.21787919027997663\n",
            "Epoch: 21\n",
            "Train:  0.15350829131039928\n",
            "Test 0.1742532754859771\n",
            "0.20908914825895317\n",
            "Epoch: 22\n",
            "Train:  0.09687213670778354\n",
            "Test 0.2139395078888927\n",
            "0.21006498048166788\n",
            "Epoch: 23\n",
            "Train:  0.11504157937141969\n",
            "Test 0.24495461300585242\n",
            "0.21707601566406032\n",
            "Epoch: 24\n",
            "Train:  0.13302231499944528\n",
            "Test 0.23856299691884728\n",
            "0.22138970858611573\n",
            "Epoch: 25\n",
            "Train:  0.13626771892191528\n",
            "Test 0.25615401818133926\n",
            "0.22836364794354447\n",
            "Epoch: 26\n",
            "Train:  0.14165173145981227\n",
            "Test 0.19403254726646646\n",
            "0.22148078606926355\n",
            "Epoch: 27\n",
            "Train:  0.09934386211785257\n",
            "Test 0.3468368979001253\n",
            "0.24660059721668381\n",
            "Epoch: 28\n",
            "Train:  0.23117163906622226\n",
            "Test 0.15877850977829724\n",
            "0.22900895798580578\n",
            "Epoch: 29\n",
            "Train:  0.09023702947883193\n",
            "Test 0.22569332859098729\n",
            "0.22834501017926837\n",
            "Epoch: 30\n",
            "Train:  0.14693223268940006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-10-15 12:25:03,548]\u001b[0m Trial 8 finished with value: 0.23772384937784138 and parameters: {'layer_size1': 512, 'layer_size2': 384, 'layer_size3': 512, 'layer_size4': 192, 'layer_size5': 64, 'learning_rate': 0.0005492995264631445, 'b1': 0.9178365829472029}. Best is trial 3 with value: 0.12057808925100155.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test 0.27636991589562115\n",
            "0.237959513065003\n",
            "Epoch: 0\n",
            "Train:  0.6927653773800357\n",
            "Test 0.6938568425702525\n",
            "0.6938568425702525\n",
            "Epoch: 1\n",
            "Train:  1.0396111899024838\n",
            "Test 0.693780650585999\n",
            "0.6938145136901118\n",
            "Epoch: 2\n",
            "Train:  1.0395048195189172\n",
            "Test 0.6937238927725907\n",
            "0.6937773739698163\n",
            "Epoch: 3\n",
            "Train:  1.0394042469424642\n",
            "Test 0.6936629119810167\n",
            "0.6937385995833666\n",
            "Epoch: 4\n",
            "Train:  1.0393110428537642\n",
            "Test 0.6936103574958913\n",
            "0.6937004504616759\n",
            "Epoch: 5\n",
            "Train:  1.0392132623073382\n",
            "Test 0.693547513022091\n",
            "0.6936589959123914\n",
            "Epoch: 6\n",
            "Train:  1.0391145660763694\n",
            "Test 0.6934814459674961\n",
            "0.6936140627579399\n",
            "Epoch: 7\n",
            "Train:  1.039014803511756\n",
            "Test 0.6934152732401977\n",
            "0.6935662898985888\n",
            "Epoch: 8\n",
            "Train:  1.0389193021334135\n",
            "Test 0.693344690424182\n",
            "0.6935150993206401\n",
            "Epoch: 9\n",
            "Train:  1.0388174923785003\n",
            "Test 0.6932807708834554\n",
            "0.6934625961479637\n",
            "Epoch: 10\n",
            "Train:  1.0387191374004978\n",
            "Test 0.6932141383488973\n",
            "0.6934082350011999\n",
            "Epoch: 11\n",
            "Train:  1.0386177936753074\n",
            "Test 0.693142532428979\n",
            "0.6933511732318224\n",
            "Epoch: 12\n",
            "Train:  1.0385120463021946\n",
            "Test 0.6930779795070271\n",
            "0.693293355948075\n",
            "Epoch: 13\n",
            "Train:  1.0384039959628066\n",
            "Test 0.6930003838661389\n",
            "0.6932320659699428\n",
            "Epoch: 14\n",
            "Train:  1.0382870496847691\n",
            "Test 0.6929237622044462\n",
            "0.6931681566060027\n",
            "Epoch: 15\n",
            "Train:  1.038169795012736\n",
            "Test 0.6928509268568549\n",
            "0.6931028730885167\n",
            "Epoch: 16\n",
            "Train:  1.0380452618057474\n",
            "Test 0.692765257297418\n",
            "0.6930337944168982\n",
            "Epoch: 17\n",
            "Train:  1.0379137957925761\n",
            "Test 0.6926736257451794\n",
            "0.6929604392330397\n",
            "Epoch: 18\n",
            "Train:  1.0377795118770319\n",
            "Test 0.6925846416871626\n",
            "0.6928841807229112\n",
            "Epoch: 19\n",
            "Train:  1.0376395766551678\n",
            "Test 0.6924851547667396\n",
            "0.6928034447088084\n",
            "Epoch: 20\n",
            "Train:  1.0374887498307142\n",
            "Test 0.6923862374745883\n",
            "0.6927192264859628\n",
            "Epoch: 21\n",
            "Train:  1.037338526148499\n",
            "Test 0.6922820409138998\n",
            "0.6926311394036044\n",
            "Epoch: 22\n",
            "Train:  1.0371838567894458\n",
            "Test 0.6921684903539581\n",
            "0.6925380601507451\n",
            "Epoch: 23\n",
            "Train:  1.037016354419373\n",
            "Test 0.6920528210999765\n",
            "0.6924405518707581\n",
            "Epoch: 24\n",
            "Train:  1.0368424509907816\n",
            "Test 0.6919330325755444\n",
            "0.6923386630867726\n",
            "Epoch: 25\n",
            "Train:  1.0366638589909662\n",
            "Test 0.6918138245959858\n",
            "0.6922333771814918\n",
            "Epoch: 26\n",
            "Train:  1.0364777606267195\n",
            "Test 0.691688746323079\n",
            "0.6921241870041599\n",
            "Epoch: 27\n",
            "Train:  1.0362864822258442\n",
            "Test 0.6915709500784403\n",
            "0.6920133251810634\n",
            "Epoch: 28\n",
            "Train:  1.0361019971169831\n",
            "Test 0.6914487745299007\n",
            "0.6919002400600821\n",
            "Epoch: 29\n",
            "Train:  1.035906624226343\n",
            "Test 0.6913095306564163\n",
            "0.691781951745508\n",
            "Epoch: 30\n",
            "Train:  1.0356979025152577\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-10-15 12:25:34,526]\u001b[0m Trial 9 finished with value: 0.6909751771791399 and parameters: {'layer_size1': 384, 'layer_size2': 384, 'layer_size3': 384, 'layer_size4': 256, 'layer_size5': 128, 'learning_rate': 1.177583473286093e-06, 'b1': 0.9909471213278065}. Best is trial 3 with value: 0.12057808925100155.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test 0.6911736172197502\n",
            "0.6916601642278409\n",
            "Epoch: 0\n",
            "Train:  0.6940824546656765\n",
            "Test 0.6919645581926618\n",
            "0.6919645581926618\n",
            "Epoch: 1\n",
            "Train:  1.0383119928094493\n",
            "Test 0.6912435216781421\n",
            "0.691563982351262\n",
            "Epoch: 2\n",
            "Train:  1.036500361267027\n",
            "Test 0.6900404958061246\n",
            "0.6909396026196483\n",
            "Epoch: 3\n",
            "Train:  1.034158197078076\n",
            "Test 0.6881621853335873\n",
            "0.6899987431054\n",
            "Epoch: 4\n",
            "Train:  1.0304507047702105\n",
            "Test 0.6844313459081964\n",
            "0.6883425683085165\n",
            "Epoch: 5\n",
            "Train:  1.024306092725132\n",
            "Test 0.6781651475927332\n",
            "0.6855839214408938\n",
            "Epoch: 6\n",
            "Train:  1.0137224175554491\n",
            "Test 0.6686010164218944\n",
            "0.6812860012432639\n",
            "Epoch: 7\n",
            "Train:  0.9960507730861287\n",
            "Test 0.6489244101248381\n",
            "0.6735089023376504\n",
            "Epoch: 8\n",
            "Train:  0.9642439705111605\n",
            "Test 0.6180688245392545\n",
            "0.6607019693265768\n",
            "Epoch: 9\n",
            "Train:  0.9129160386083763\n",
            "Test 0.5678730060111036\n",
            "0.6399028928299857\n",
            "Epoch: 10\n",
            "Train:  0.8371737131596485\n",
            "Test 0.5093522925516625\n",
            "0.6113391674468731\n",
            "Epoch: 11\n",
            "Train:  0.7499281754205515\n",
            "Test 0.4461392281037984\n",
            "0.5758611486939256\n",
            "Epoch: 12\n",
            "Train:  0.6621950560764516\n",
            "Test 0.3875663391836397\n",
            "0.5360114250673125\n",
            "Epoch: 13\n",
            "Train:  0.5825439928433834\n",
            "Test 0.33778685385927615\n",
            "0.4945426968721172\n",
            "Epoch: 14\n",
            "Train:  0.5165634383976241\n",
            "Test 0.30449349555995436\n",
            "0.4551467344075331\n",
            "Epoch: 15\n",
            "Train:  0.47601552113836065\n",
            "Test 0.2756736947175784\n",
            "0.4182125207774055\n",
            "Epoch: 16\n",
            "Train:  0.4353229967065347\n",
            "Test 0.2539082097483205\n",
            "0.38459465145277144\n",
            "Epoch: 17\n",
            "Train:  0.40317937082205063\n",
            "Test 0.2365682819387415\n",
            "0.3544462726396104\n",
            "Epoch: 18\n",
            "Train:  0.3774864425807645\n",
            "Test 0.21985571121885664\n",
            "0.3271345570526102\n",
            "Epoch: 19\n",
            "Train:  0.35194784155859177\n",
            "Test 0.21132167108056746\n",
            "0.3037018187795331\n",
            "Epoch: 20\n",
            "Train:  0.3361652390519669\n",
            "Test 0.1950322980190808\n",
            "0.2817655886155542\n",
            "Epoch: 21\n",
            "Train:  0.31315047591378836\n",
            "Test 0.1854995390052324\n",
            "0.26236925904244807\n",
            "Epoch: 22\n",
            "Train:  0.29589686351708877\n",
            "Test 0.17827979756362272\n",
            "0.2454515019352727\n",
            "Epoch: 23\n",
            "Train:  0.28261458849186427\n",
            "Test 0.17502404569269536\n",
            "0.2312991782276255\n",
            "Epoch: 24\n",
            "Train:  0.2749112324700469\n",
            "Test 0.166976230744368\n",
            "0.21838580338012556\n",
            "Epoch: 25\n",
            "Train:  0.2628805663354777\n",
            "Test 0.16093171123183253\n",
            "0.20686015080299594\n",
            "Epoch: 26\n",
            "Train:  0.2547930420100034\n",
            "Test 0.1593202846636484\n",
            "0.1973291329880791\n",
            "Epoch: 27\n",
            "Train:  0.2495080355773151\n",
            "Test 0.15736628831415386\n",
            "0.18932107421486857\n",
            "Epoch: 28\n",
            "Train:  0.24530366678541396\n",
            "Test 0.15713858888262794\n",
            "0.1828746017153964\n",
            "Epoch: 29\n",
            "Train:  0.2449621088502608\n",
            "Test 0.15059965701548608\n",
            "0.17641161198164942\n",
            "Epoch: 30\n",
            "Train:  0.23514786812957827\n",
            "Test 0.15046688754643714\n",
            "0.17121752311814958\n",
            "Epoch: 31\n",
            "Train:  0.23334862201068646\n",
            "Test 0.15081350364800775\n",
            "0.16713348351458696\n",
            "Epoch: 32\n",
            "Train:  0.22913065244999778\n",
            "Test 0.14662549083185938\n",
            "0.16302928363231936\n",
            "Epoch: 33\n",
            "Train:  0.22565810146635815\n",
            "Test 0.14759481048736817\n",
            "0.159940822967723\n",
            "Epoch: 34\n",
            "Train:  0.2240442330556693\n",
            "Test 0.16570383203881128\n",
            "0.1610938925225209\n",
            "Epoch: 35\n",
            "Train:  0.2372762489613596\n",
            "Test 0.14381497497278037\n",
            "0.15763698718265176\n",
            "Epoch: 36\n",
            "Train:  0.21641330059017344\n",
            "Test 0.1429443264127651\n",
            "0.15469769194400274\n",
            "Epoch: 37\n",
            "Train:  0.21364505812798665\n",
            "Test 0.14519237484032418\n",
            "0.15279623360582079\n",
            "Epoch: 38\n",
            "Train:  0.2173897386375037\n",
            "Test 0.14501284390701588\n",
            "0.15123929697559024\n",
            "Epoch: 39\n",
            "Train:  0.2153590430928592\n",
            "Test 0.14119282277512463\n",
            "0.1492297350188959\n",
            "Epoch: 40\n",
            "Train:  0.2080161812759581\n",
            "Test 0.13991121924567573\n",
            "0.14736583366026249\n",
            "Epoch: 41\n",
            "Train:  0.20770958073491796\n",
            "Test 0.13912224570364307\n",
            "0.14571697579962473\n",
            "Epoch: 42\n",
            "Train:  0.20293576153329548\n",
            "Test 0.13809813403152613\n",
            "0.1441931037366465\n",
            "Epoch: 43\n",
            "Train:  0.19916443772197806\n",
            "Test 0.14508788364738118\n",
            "0.14437206946261438\n",
            "Epoch: 44\n",
            "Train:  0.20557520290556955\n",
            "Test 0.14711796346669778\n",
            "0.1449212721845833\n",
            "Epoch: 45\n",
            "Train:  0.20270522510046105\n",
            "Test 0.1362600253396855\n",
            "0.1431889624534195\n",
            "Epoch: 46\n",
            "Train:  0.19553533305615295\n",
            "Test 0.13572727392117181\n",
            "0.14169658314550657\n",
            "Epoch: 47\n",
            "Train:  0.1926242271267669\n",
            "Test 0.13900115398260263\n",
            "0.1411574852906419\n",
            "Epoch: 48\n",
            "Train:  0.1979378043186097\n",
            "Test 0.13664749432559853\n",
            "0.14025547100516064\n",
            "Epoch: 49\n",
            "Train:  0.18786180032342126\n",
            "Test 0.14538957718964463\n",
            "0.141282306897549\n",
            "Epoch: 50\n",
            "Train:  0.19372824376837894\n",
            "Test 0.13798840310520086\n",
            "0.14062351861704697\n",
            "Epoch: 51\n",
            "Train:  0.18508971427591184\n",
            "Test 0.13372681314473625\n",
            "0.1392441649230368\n",
            "Epoch: 52\n",
            "Train:  0.18270457225541273\n",
            "Test 0.13560123583336017\n",
            "0.13851557378091575\n",
            "Epoch: 53\n",
            "Train:  0.18076410085890757\n",
            "Test 0.1380019010805385\n",
            "0.13841283864024997\n",
            "Epoch: 54\n",
            "Train:  0.18416191480589875\n",
            "Test 0.13490572938142897\n",
            "0.13771141350805702\n",
            "Epoch: 55\n",
            "Train:  0.17816612196083254\n",
            "Test 0.13198138278782803\n",
            "0.13656540307627718\n",
            "Epoch: 56\n",
            "Train:  0.17562317264508523\n",
            "Test 0.13572925306010597\n",
            "0.13639817257249603\n",
            "Epoch: 57\n",
            "Train:  0.1783108329843907\n",
            "Test 0.134038117260505\n",
            "0.1359261603798532\n",
            "Epoch: 58\n",
            "Train:  0.17200833855149072\n",
            "Test 0.13020689987437628\n",
            "0.1347823060875683\n",
            "Epoch: 59\n",
            "Train:  0.16890107070679192\n",
            "Test 0.13844948614036645\n",
            "0.13551574322211707\n",
            "Epoch: 60\n",
            "Train:  0.17014740118176946\n",
            "Test 0.12953612612280654\n",
            "0.1343198183360553\n",
            "Epoch: 61\n",
            "Train:  0.16654144118338715\n",
            "Test 0.14005192546617418\n",
            "0.13546624088648707\n",
            "Epoch: 62\n",
            "Train:  0.18307343703923207\n",
            "Test 0.12866641686130792\n",
            "0.13410627501437072\n",
            "Epoch: 63\n",
            "Train:  0.16418206588716516\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-10-15 12:26:37,488]\u001b[0m Trial 10 finished with value: 0.1347055642964758 and parameters: {'layer_size1': 384, 'layer_size2': 256, 'layer_size3': 512, 'layer_size4': 64, 'layer_size5': 64, 'learning_rate': 1.677071527341477e-05, 'b1': 0.9375981092362581}. Best is trial 3 with value: 0.12057808925100155.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test 0.13710314232426193\n",
            "0.134705648852582\n",
            "Epoch: 0\n",
            "Train:  0.6926429300081163\n",
            "Test 0.6924457379749843\n",
            "0.6924457379749843\n",
            "Epoch: 1\n",
            "Train:  1.0377013995533897\n",
            "Test 0.6916533228241917\n",
            "0.6920055073356552\n",
            "Epoch: 2\n",
            "Train:  1.035881356441931\n",
            "Test 0.689814805547833\n",
            "0.6911076787340887\n",
            "Epoch: 3\n",
            "Train:  1.032541728936709\n",
            "Test 0.6870140383095095\n",
            "0.6897209441729167\n",
            "Epoch: 4\n",
            "Train:  1.0274857782618902\n",
            "Test 0.6818718901484004\n",
            "0.6873860280542482\n",
            "Epoch: 5\n",
            "Train:  1.0185672001087622\n",
            "Test 0.6731918006589561\n",
            "0.6835386032463475\n",
            "Epoch: 6\n",
            "Train:  1.0029501434647556\n",
            "Test 0.6575631261308551\n",
            "0.6769649029510888\n",
            "Epoch: 7\n",
            "Train:  0.9744042029310932\n",
            "Test 0.6285525988309811\n",
            "0.6653305158774461\n",
            "Epoch: 8\n",
            "Train:  0.9230276798153971\n",
            "Test 0.5774525240227416\n",
            "0.6450302637940436\n",
            "Epoch: 9\n",
            "Train:  0.8395321243630224\n",
            "Test 0.5056034053638304\n",
            "0.6137905537876515\n",
            "Epoch: 10\n",
            "Train:  0.7364297283219767\n",
            "Test 0.4325072992415655\n",
            "0.5741268135338958\n",
            "Epoch: 11\n",
            "Train:  0.6412287998548795\n",
            "Test 0.379193820359506\n",
            "0.5322633817741124\n",
            "Epoch: 12\n",
            "Train:  0.5644193466329749\n",
            "Test 0.3226891528446596\n",
            "0.48791019368666777\n",
            "Epoch: 13\n",
            "Train:  0.49740541677226074\n",
            "Test 0.2902022047248079\n",
            "0.4465495348828028\n",
            "Epoch: 14\n",
            "Train:  0.4507094408511679\n",
            "Test 0.2598866090014741\n",
            "0.40785552527488317\n",
            "Epoch: 15\n",
            "Train:  0.4063948945793913\n",
            "Test 0.23557748440857773\n",
            "0.3724019887652872\n",
            "Epoch: 16\n",
            "Train:  0.3719553304460896\n",
            "Test 0.21865432068105145\n",
            "0.34094408615609706\n",
            "Epoch: 17\n",
            "Train:  0.34543206911165636\n",
            "Test 0.19999031138507437\n",
            "0.3122361754582061\n",
            "Epoch: 18\n",
            "Train:  0.3235931948864416\n",
            "Test 0.19400824328045269\n",
            "0.28824483740305445\n",
            "Epoch: 19\n",
            "Train:  0.3020871831274731\n",
            "Test 0.17881945436035757\n",
            "0.2661045000843756\n",
            "Epoch: 20\n",
            "Train:  0.28766529938895186\n",
            "Test 0.17431684400572445\n",
            "0.24757607430441952\n",
            "Epoch: 21\n",
            "Train:  0.27699352611170147\n",
            "Test 0.1687315514945722\n",
            "0.23168995084090815\n",
            "Epoch: 22\n",
            "Train:  0.26819959469821864\n",
            "Test 0.1671232787462381\n",
            "0.21869993691399858\n",
            "Epoch: 23\n",
            "Train:  0.26209191743270815\n",
            "Test 0.16173144185663144\n",
            "0.20725217738662916\n",
            "Epoch: 24\n",
            "Train:  0.25656813389243005\n",
            "Test 0.16044106271677402\n",
            "0.19785445084559206\n",
            "Epoch: 25\n",
            "Train:  0.2535729699191593\n",
            "Test 0.15717327529257472\n",
            "0.18969355092843573\n",
            "Epoch: 26\n",
            "Train:  0.24621248605487112\n",
            "Test 0.15759214227370946\n",
            "0.18325770828480478\n",
            "Epoch: 27\n",
            "Train:  0.24374773509240957\n",
            "Test 0.15994813186781748\n",
            "0.17858675806969984\n",
            "Epoch: 28\n",
            "Train:  0.2436165753547307\n",
            "Test 0.15414448920296225\n",
            "0.1736907280568693\n",
            "Epoch: 29\n",
            "Train:  0.23807812378410892\n",
            "Test 0.15257368774422797\n",
            "0.16946208518802183\n",
            "Epoch: 30\n",
            "Train:  0.23337257510194412\n",
            "Test 0.1533516797718111\n",
            "0.16623680994689272\n",
            "Epoch: 31\n",
            "Train:  0.23280973735200616\n",
            "Test 0.15044926494469135\n",
            "0.1630767973265181\n",
            "Epoch: 32\n",
            "Train:  0.2312101668545178\n",
            "Test 0.16134818091702002\n",
            "0.16273085477747853\n",
            "Epoch: 33\n",
            "Train:  0.23410033821998225\n",
            "Test 0.15121470129751896\n",
            "0.16042645561229263\n",
            "Epoch: 34\n",
            "Train:  0.2249526171893864\n",
            "Test 0.14942759310915357\n",
            "0.1582257904158065\n",
            "Epoch: 35\n",
            "Train:  0.22299125371671422\n",
            "Test 0.15410163922187609\n",
            "0.15740069241741136\n",
            "Epoch: 36\n",
            "Train:  0.22339640511370404\n",
            "Test 0.14705039252400834\n",
            "0.1553300948808765\n",
            "Epoch: 37\n",
            "Train:  0.2179298896219704\n",
            "Test 0.146747048275593\n",
            "0.15361312895994952\n",
            "Epoch: 38\n",
            "Train:  0.2158770206292252\n",
            "Test 0.15230235580232118\n",
            "0.1533509307632759\n",
            "Epoch: 39\n",
            "Train:  0.2164279761427379\n",
            "Test 0.1476445993128823\n",
            "0.15220951275271974\n",
            "Epoch: 40\n",
            "Train:  0.21157134418809043\n",
            "Test 0.14440973206754132\n",
            "0.1506493907150529\n",
            "Epoch: 41\n",
            "Train:  0.2107898181393033\n",
            "Test 0.1445310157297295\n",
            "0.14942561161037565\n",
            "Epoch: 42\n",
            "Train:  0.2064332894899033\n",
            "Test 0.1505819156820521\n",
            "0.1496568881645776\n",
            "Epoch: 43\n",
            "Train:  0.20995257063444717\n",
            "Test 0.1484319503340638\n",
            "0.14941188725935678\n",
            "Epoch: 44\n",
            "Train:  0.2069000388962991\n",
            "Test 0.14204528726528198\n",
            "0.1479385030856101\n",
            "Epoch: 45\n",
            "Train:  0.2024121091022214\n",
            "Test 0.1432333168310997\n",
            "0.14699743304320295\n",
            "Epoch: 46\n",
            "Train:  0.203183148424704\n",
            "Test 0.1465846370503088\n",
            "0.14691487154314542\n",
            "Epoch: 47\n",
            "Train:  0.20107811667373057\n",
            "Test 0.14212079821052132\n",
            "0.14595603549386216\n",
            "Epoch: 48\n",
            "Train:  0.19587277530968844\n",
            "Test 0.14566556040211256\n",
            "0.14589793943904397\n",
            "Epoch: 49\n",
            "Train:  0.1942425069634567\n",
            "Test 0.14259667230613066\n",
            "0.14523767658887504\n",
            "Epoch: 50\n",
            "Train:  0.19576168537221766\n",
            "Test 0.13979928993070737\n",
            "0.14414998683802\n",
            "Epoch: 51\n",
            "Train:  0.1922162634528655\n",
            "Test 0.14396676892626198\n",
            "0.1441133429209487\n",
            "Epoch: 52\n",
            "Train:  0.1930966256186366\n",
            "Test 0.14465672616938968\n",
            "0.14422202036479823\n",
            "Epoch: 53\n",
            "Train:  0.18897914999052062\n",
            "Test 0.1380601957672354\n",
            "0.14298964824083016\n",
            "Epoch: 54\n",
            "Train:  0.18380938255101878\n",
            "Test 0.13936939407754076\n",
            "0.14226559402191172\n",
            "Epoch: 55\n",
            "Train:  0.18451080487993282\n",
            "Test 0.14626668926819666\n",
            "0.1430658160651548\n",
            "Epoch: 56\n",
            "Train:  0.18725320293428205\n",
            "Test 0.1398746505543426\n",
            "0.14242758105265582\n",
            "Epoch: 57\n",
            "Train:  0.18117519604526597\n",
            "Test 0.14337322414057813\n",
            "0.14261671012311444\n",
            "Epoch: 58\n",
            "Train:  0.17862070985343104\n",
            "Test 0.13605033987007298\n",
            "0.14130343355676803\n",
            "Epoch: 59\n",
            "Train:  0.17486115589383103\n",
            "Test 0.13624174457602886\n",
            "0.14029109420921468\n",
            "Epoch: 60\n",
            "Train:  0.17342781494525109\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-10-15 12:27:37,387]\u001b[0m Trial 11 finished with value: 0.14071356826033732 and parameters: {'layer_size1': 384, 'layer_size2': 256, 'layer_size3': 512, 'layer_size4': 64, 'layer_size5': 64, 'learning_rate': 1.5592978278315834e-05, 'b1': 0.9385475976649323}. Best is trial 3 with value: 0.12057808925100155.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test 0.14240432444673318\n",
            "0.14071374077488155\n",
            "Epoch: 0\n",
            "Train:  0.6945220987438719\n",
            "Test 0.6921141007881024\n",
            "0.6921141007881024\n",
            "Epoch: 1\n",
            "Train:  1.0393678069988013\n",
            "Test 0.6913400558761624\n",
            "0.6916840758370247\n",
            "Epoch: 2\n",
            "Train:  1.0377244625117752\n",
            "Test 0.6901413462100885\n",
            "0.6910518095964772\n",
            "Epoch: 3\n",
            "Train:  1.0349524664136516\n",
            "Test 0.687928013749175\n",
            "0.6899936131712392\n",
            "Epoch: 4\n",
            "Train:  1.0301250459510327\n",
            "Test 0.6838957726300418\n",
            "0.6881796434719301\n",
            "Epoch: 5\n",
            "Train:  1.0223543720367627\n",
            "Test 0.6770052250488338\n",
            "0.6851507547936254\n",
            "Epoch: 6\n",
            "Train:  1.0088924689170642\n",
            "Test 0.6633393092033191\n",
            "0.6796308597911387\n",
            "Epoch: 7\n",
            "Train:  0.985698985966134\n",
            "Test 0.6409266667488294\n",
            "0.6703295143705602\n",
            "Epoch: 8\n",
            "Train:  0.9453029121671405\n",
            "Test 0.6018760378980811\n",
            "0.6545164217059696\n",
            "Epoch: 9\n",
            "Train:  0.8770293337958199\n",
            "Test 0.5368601088122134\n",
            "0.6281545776781778\n",
            "Epoch: 10\n",
            "Train:  0.7754966568597507\n",
            "Test 0.4590693507002387\n",
            "0.591159696157583\n",
            "Epoch: 11\n",
            "Train:  0.6564979257382753\n",
            "Test 0.3719249882977524\n",
            "0.5440772752579284\n",
            "Epoch: 12\n",
            "Train:  0.5342820685206752\n",
            "Test 0.3021649861292088\n",
            "0.49288023010977616\n",
            "Epoch: 13\n",
            "Train:  0.44455317508825015\n",
            "Test 0.2505811231258588\n",
            "0.4421910761455614\n",
            "Epoch: 14\n",
            "Train:  0.3799495443210497\n",
            "Test 0.21882471854324306\n",
            "0.39588868403238475\n",
            "Epoch: 15\n",
            "Train:  0.33875881106807637\n",
            "Test 0.1987072372392857\n",
            "0.35531021223330495\n",
            "Epoch: 16\n",
            "Train:  0.3124149686796761\n",
            "Test 0.18400055999720927\n",
            "0.3202589986233218\n",
            "Epoch: 17\n",
            "Train:  0.2912533595721364\n",
            "Test 0.17112565433586036\n",
            "0.2898851633937425\n",
            "Epoch: 18\n",
            "Train:  0.27623687045914785\n",
            "Test 0.16575536430700794\n",
            "0.2646961922449409\n",
            "Epoch: 19\n",
            "Train:  0.2700060207751535\n",
            "Test 0.16143414689289345\n",
            "0.2438028999142303\n",
            "Epoch: 20\n",
            "Train:  0.26605126556459363\n",
            "Test 0.15771592722270952\n",
            "0.22642522461147313\n",
            "Epoch: 21\n",
            "Train:  0.2578932924039198\n",
            "Test 0.15501162467094567\n",
            "0.21203633334549243\n",
            "Epoch: 22\n",
            "Train:  0.25391478908858894\n",
            "Test 0.1531505524129658\n",
            "0.20018924428863502\n",
            "Epoch: 23\n",
            "Train:  0.25231613797364216\n",
            "Test 0.1579675976555426\n",
            "0.19170484853588632\n",
            "Epoch: 24\n",
            "Train:  0.24932160798883263\n",
            "Test 0.1506442346852341\n",
            "0.18346158359128886\n",
            "Epoch: 25\n",
            "Train:  0.24367743304797582\n",
            "Test 0.1489336588061773\n",
            "0.17653506451488774\n",
            "Epoch: 26\n",
            "Train:  0.24430733947799757\n",
            "Test 0.15678191356934035\n",
            "0.17257485913671297\n",
            "Epoch: 27\n",
            "Train:  0.24569190243743497\n",
            "Test 0.14896640040990197\n",
            "0.16784401661106632\n",
            "Epoch: 28\n",
            "Train:  0.2380626604520467\n",
            "Test 0.14573466557422618\n",
            "0.16341529328628998\n",
            "Epoch: 29\n",
            "Train:  0.23337145623556532\n",
            "Test 0.14427846609597733\n",
            "0.15958318392661616\n",
            "Epoch: 30\n",
            "Train:  0.23084807627656984\n",
            "Test 0.1463723438467844\n",
            "0.15693839664018802\n",
            "Epoch: 31\n",
            "Train:  0.23044184282517585\n",
            "Test 0.1466465878535758\n",
            "0.15487840278758827\n",
            "Epoch: 32\n",
            "Train:  0.22854627445749529\n",
            "Test 0.14230516048032285\n",
            "0.15236215946745763\n",
            "Epoch: 33\n",
            "Train:  0.22856378832306617\n",
            "Test 0.14799906108733063\n",
            "0.15148909709621666\n",
            "Epoch: 34\n",
            "Train:  0.2258707578720409\n",
            "Test 0.1407569918658707\n",
            "0.14934180500499278\n",
            "Epoch: 35\n",
            "Train:  0.22080897515291695\n",
            "Test 0.1408659014509711\n",
            "0.1476460739980147\n",
            "Epoch: 36\n",
            "Train:  0.21874598116228433\n",
            "Test 0.1423045760327643\n",
            "0.1465774969865116\n",
            "Epoch: 37\n",
            "Train:  0.21638405857942042\n",
            "Test 0.13900970820433053\n",
            "0.14506362481112578\n",
            "Epoch: 38\n",
            "Train:  0.21331467742830407\n",
            "Test 0.138681443551412\n",
            "0.1437869764395885\n",
            "Epoch: 39\n",
            "Train:  0.21289365721573106\n",
            "Test 0.13637136424560742\n",
            "0.1423036568337976\n",
            "Epoch: 40\n",
            "Train:  0.20836617393443027\n",
            "Test 0.13699848181653373\n",
            "0.14124250898975108\n",
            "Epoch: 41\n",
            "Train:  0.20549469823938804\n",
            "Test 0.13472427407811796\n",
            "0.13993875109596896\n",
            "Epoch: 42\n",
            "Train:  0.20386747784840947\n",
            "Test 0.13603862847164\n",
            "0.13915867348177177\n",
            "Epoch: 43\n",
            "Train:  0.20359467569015402\n",
            "Test 0.13313353878374284\n",
            "0.13795358093068666\n",
            "Epoch: 44\n",
            "Train:  0.1994382399594882\n",
            "Test 0.13219008231774354\n",
            "0.1368008309987572\n",
            "Epoch: 45\n",
            "Train:  0.1969740315998867\n",
            "Test 0.13151488826361113\n",
            "0.13574360561279994\n",
            "Epoch: 46\n",
            "Train:  0.1938065661751962\n",
            "Test 0.13105512196846278\n",
            "0.13480588274403404\n",
            "Epoch: 47\n",
            "Train:  0.19163235935686163\n",
            "Test 0.1319530437267198\n",
            "0.13423530221620023\n",
            "Epoch: 48\n",
            "Train:  0.190589133428321\n",
            "Test 0.13013960364455487\n",
            "0.1334161478876696\n",
            "Epoch: 49\n",
            "Train:  0.1891881438354269\n",
            "Test 0.12887670089500947\n",
            "0.13250824553112212\n",
            "Epoch: 50\n",
            "Train:  0.18505707323455658\n",
            "Test 0.13035743697222335\n",
            "0.13207807890770779\n",
            "Epoch: 51\n",
            "Train:  0.18411709153990605\n",
            "Test 0.12847375742845482\n",
            "0.13135720802714487\n",
            "Epoch: 52\n",
            "Train:  0.18100085960284912\n",
            "Test 0.12680784591402\n",
            "0.13044732895557115\n",
            "Epoch: 53\n",
            "Train:  0.18101671039409964\n",
            "Test 0.12940273293372476\n",
            "0.1302384085298517\n",
            "Epoch: 54\n",
            "Train:  0.17948657738884072\n",
            "Test 0.129508424021522\n",
            "0.13009241094538346\n",
            "Epoch: 55\n",
            "Train:  0.17661655903196868\n",
            "Test 0.124665617560729\n",
            "0.12900704820762848\n",
            "Epoch: 56\n",
            "Train:  0.1774894147804314\n",
            "Test 0.12455134905001401\n",
            "0.12811590570877762\n",
            "Epoch: 57\n",
            "Train:  0.17038055685700187\n",
            "Test 0.125220089168339\n",
            "0.127536741013866\n",
            "Epoch: 58\n",
            "Train:  0.1688005576599321\n",
            "Test 0.13108006457119306\n",
            "0.1282454070828659\n",
            "Epoch: 59\n",
            "Train:  0.1751873244244892\n",
            "Test 0.12912124655577917\n",
            "0.12842057524589298\n",
            "Epoch: 60\n",
            "Train:  0.17149462613776914\n",
            "Test 0.12896521882948914\n",
            "0.12852950409615857\n",
            "Epoch: 61\n",
            "Train:  0.16712093159245947\n",
            "Test 0.12408021853165531\n",
            "0.12763964611048775\n",
            "Epoch: 62\n",
            "Train:  0.164125042653646\n",
            "Test 0.12843093483439294\n",
            "0.12779790397944385\n",
            "Epoch: 63\n",
            "Train:  0.16336513548106937\n",
            "Test 0.12432613803053295\n",
            "0.12710355035380883\n",
            "Epoch: 64\n",
            "Train:  0.1601876845897172\n",
            "Test 0.12497808835418014\n",
            "0.1266784577404151\n",
            "Epoch: 65\n",
            "Train:  0.15906135551290307\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-10-15 12:28:41,323]\u001b[0m Trial 12 finished with value: 0.12776290372128368 and parameters: {'layer_size1': 384, 'layer_size2': 256, 'layer_size3': 384, 'layer_size4': 64, 'layer_size5': 128, 'learning_rate': 1.641323617905515e-05, 'b1': 0.9403788894041717}. Best is trial 3 with value: 0.12057808925100155.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test 0.13210094210029932\n",
            "0.12776295504807197\n",
            "Epoch: 0\n",
            "Train:  0.6922987031412648\n",
            "Test 0.6923043221344442\n",
            "0.6923043221344442\n",
            "Epoch: 1\n",
            "Train:  1.034561696070018\n",
            "Test 0.6843641845734565\n",
            "0.6878931346005622\n",
            "Epoch: 2\n",
            "Train:  1.016063819547276\n",
            "Test 0.6561728338182191\n",
            "0.6748930113291102\n",
            "Epoch: 3\n",
            "Train:  0.9486152672723973\n",
            "Test 0.554612011263222\n",
            "0.6341474151008282\n",
            "Epoch: 4\n",
            "Train:  0.740447284865292\n",
            "Test 0.3414783803097931\n",
            "0.5470849939944993\n",
            "Epoch: 5\n",
            "Train:  0.445998313444438\n",
            "Test 0.18991481122516451\n",
            "0.45027201618600154\n",
            "Epoch: 6\n",
            "Train:  0.2916756882554009\n",
            "Test 0.15375432814215564\n",
            "0.37523129971420655\n",
            "Epoch: 7\n",
            "Train:  0.25442826745165137\n",
            "Test 0.1513180558061425\n",
            "0.32142073651361375\n",
            "Epoch: 8\n",
            "Train:  0.24731516725496278\n",
            "Test 0.1502590318357115\n",
            "0.2818815335954228\n",
            "Epoch: 9\n",
            "Train:  0.2392918813987311\n",
            "Test 0.14636567864744437\n",
            "0.25151811540249186\n",
            "Epoch: 10\n",
            "Train:  0.23591771950065107\n",
            "Test 0.14699893618077586\n",
            "0.22864991620468914\n",
            "Epoch: 11\n",
            "Train:  0.22800628508649248\n",
            "Test 0.13892161597125915\n",
            "0.20938004037416158\n",
            "Epoch: 12\n",
            "Train:  0.2167462379715982\n",
            "Test 0.13940458660160665\n",
            "0.19457080319584819\n",
            "Epoch: 13\n",
            "Train:  0.22113574495464017\n",
            "Test 0.14736325591256766\n",
            "0.1846949490818915\n",
            "Epoch: 14\n",
            "Train:  0.21656464976377976\n",
            "Test 0.13356026612740735\n",
            "0.1740950621241748\n",
            "Epoch: 15\n",
            "Train:  0.2012682447598858\n",
            "Test 0.13539331665624194\n",
            "0.16613053142117437\n",
            "Epoch: 16\n",
            "Train:  0.19756175640410992\n",
            "Test 0.13014489156791034\n",
            "0.15876760508909402\n",
            "Epoch: 17\n",
            "Train:  0.1903030849744194\n",
            "Test 0.1277085119592292\n",
            "0.15244183145601398\n",
            "Epoch: 18\n",
            "Train:  0.1873360786812155\n",
            "Test 0.13338598303305796\n",
            "0.14857493390463405\n",
            "Epoch: 19\n",
            "Train:  0.1874189582063165\n",
            "Test 0.12519392068583124\n",
            "0.14384418949120306\n",
            "Epoch: 20\n",
            "Train:  0.18443475643363902\n",
            "Test 0.12358298601800978\n",
            "0.13975422553740116\n",
            "Epoch: 21\n",
            "Train:  0.1717181990047637\n",
            "Test 0.15556258756169306\n",
            "0.14293940038435224\n",
            "Epoch: 22\n",
            "Train:  0.19165262280478937\n",
            "Test 0.12511302441385858\n",
            "0.13935295455075702\n",
            "Epoch: 23\n",
            "Train:  0.16341213786790332\n",
            "Test 0.1220044969639062\n",
            "0.13586680013461797\n",
            "Epoch: 24\n",
            "Train:  0.1605456450155803\n",
            "Test 0.12109668318168584\n",
            "0.13290157443807674\n",
            "Epoch: 25\n",
            "Train:  0.15391232791073592\n",
            "Test 0.11947708601480002\n",
            "0.13020853754885\n",
            "Epoch: 26\n",
            "Train:  0.1533234035630366\n",
            "Test 0.12703547318339783\n",
            "0.12957238655704123\n",
            "Epoch: 27\n",
            "Train:  0.153262693694223\n",
            "Test 0.11764548055063455\n",
            "0.1271823824154146\n",
            "Epoch: 28\n",
            "Train:  0.1442967433953187\n",
            "Test 0.1153360000545425\n",
            "0.12480943398339625\n",
            "Epoch: 29\n",
            "Train:  0.13564294151323864\n",
            "Test 0.11726441485432042\n",
            "0.1232985597859177\n",
            "Epoch: 30\n",
            "Train:  0.1340581116713447\n",
            "Test 0.11529140616340679\n",
            "0.12169554150900855\n",
            "Epoch: 31\n",
            "Train:  0.13144769526646224\n",
            "Test 0.13025333718806095\n",
            "0.12340845775688764\n",
            "Epoch: 32\n",
            "Train:  0.14258035754779824\n",
            "Test 0.1186347480849687\n",
            "0.12245311029911471\n",
            "Epoch: 33\n",
            "Train:  0.1291938318492292\n",
            "Test 0.11852089531255729\n",
            "0.12166626832552319\n",
            "Epoch: 34\n",
            "Train:  0.127709224656388\n",
            "Test 0.11352933995466638\n",
            "0.12003822223739957\n",
            "Epoch: 35\n",
            "Train:  0.11945982656915818\n",
            "Test 0.1144861509620925\n",
            "0.11892744751533191\n",
            "Epoch: 36\n",
            "Train:  0.1132007284915491\n",
            "Test 0.11491062012292111\n",
            "0.11812387341708644\n",
            "Epoch: 37\n",
            "Train:  0.12317285221315248\n",
            "Test 0.11453622312117846\n",
            "0.11740619430178423\n",
            "Epoch: 38\n",
            "Train:  0.106767678646978\n",
            "Test 0.13040448521901837\n",
            "0.12000628449931632\n",
            "Epoch: 39\n",
            "Train:  0.11981786520735467\n",
            "Test 0.11603939545003104\n",
            "0.11921280121744\n",
            "Epoch: 40\n",
            "Train:  0.11072486414294348\n",
            "Test 0.11676647633761031\n",
            "0.11872348420836469\n",
            "Epoch: 41\n",
            "Train:  0.1021328397183048\n",
            "Test 0.1218009439020694\n",
            "0.11933902851182378\n",
            "Epoch: 42\n",
            "Train:  0.10019268455400025\n",
            "Test 0.11342766568501354\n",
            "0.11815667547968406\n",
            "Epoch: 43\n",
            "Train:  0.09365444769571116\n",
            "Test 0.1306369610458285\n",
            "0.12065286849858796\n",
            "Epoch: 44\n",
            "Train:  0.10218818815111186\n",
            "Test 0.12772132788064988\n",
            "0.1220666219526479\n",
            "Epoch: 45\n",
            "Train:  0.11384114783364706\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-10-15 12:29:26,243]\u001b[0m Trial 13 finished with value: 0.12279833128080016 and parameters: {'layer_size1': 256, 'layer_size2': 384, 'layer_size3': 384, 'layer_size4': 64, 'layer_size5': 128, 'learning_rate': 4.634118656361141e-05, 'b1': 0.9469195175942126}. Best is trial 3 with value: 0.12057808925100155.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test 0.1257464355983577\n",
            "0.12280261032724175\n",
            "Epoch: 0\n",
            "Train:  0.6918617441104009\n",
            "Test 0.6899501238113794\n",
            "0.6899501238113793\n",
            "Epoch: 1\n",
            "Train:  1.0306069687172608\n",
            "Test 0.677498222270728\n",
            "0.6830324007332398\n",
            "Epoch: 2\n",
            "Train:  0.9983123217746889\n",
            "Test 0.6214313891344455\n",
            "0.6577860845042257\n",
            "Epoch: 3\n",
            "Train:  0.8509697084461812\n",
            "Test 0.4128805145675883\n",
            "0.5748234930622753\n",
            "Epoch: 4\n",
            "Train:  0.5967216262450585\n",
            "Test 0.27846295291032547\n",
            "0.4866629325696677\n",
            "Epoch: 5\n",
            "Train:  0.46912995130915347\n",
            "Test 0.2572483823603981\n",
            "0.42447883426071054\n",
            "Epoch: 6\n",
            "Train:  0.4237939449225044\n",
            "Test 0.2426088137395216\n",
            "0.3784523839174446\n",
            "Epoch: 7\n",
            "Train:  0.3876868013442654\n",
            "Test 0.23418364851247697\n",
            "0.34378189382546026\n",
            "Epoch: 8\n",
            "Train:  0.3392150034998363\n",
            "Test 0.1962070834069025\n",
            "0.30969138049636363\n",
            "Epoch: 9\n",
            "Train:  0.2885885325843816\n",
            "Test 0.1829716668842913\n",
            "0.28129880857797945\n",
            "Epoch: 10\n",
            "Train:  0.25786101909511255\n",
            "Test 0.21179811640100166\n",
            "0.26609245425216904\n",
            "Epoch: 11\n",
            "Train:  0.28223835988031637\n",
            "Test 0.1604261608869383\n",
            "0.24339976591055396\n",
            "Epoch: 12\n",
            "Train:  0.23156071710144424\n",
            "Test 0.1608831628665819\n",
            "0.22593638582874873\n",
            "Epoch: 13\n",
            "Train:  0.21445003825993764\n",
            "Test 0.15008718020968384\n",
            "0.21006867542095367\n",
            "Epoch: 14\n",
            "Train:  0.206735859761499\n",
            "Test 0.1504291812172876\n",
            "0.19770579644628658\n",
            "Epoch: 15\n",
            "Train:  0.19846230474191517\n",
            "Test 0.16729935661176623\n",
            "0.1914483778026848\n",
            "Epoch: 16\n",
            "Train:  0.20221709644920005\n",
            "Test 0.18475156214647678\n",
            "0.19007816011203815\n",
            "Epoch: 17\n",
            "Train:  0.21862925583626325\n",
            "Test 0.14155078742093655\n",
            "0.18019463990207912\n",
            "Epoch: 18\n",
            "Train:  0.1740159886128409\n",
            "Test 0.1449857889017902\n",
            "0.17304990319458605\n",
            "Epoch: 19\n",
            "Train:  0.18064104648001642\n",
            "Test 0.15572492211320244\n",
            "0.16954449234277397\n",
            "Epoch: 20\n",
            "Train:  0.17667625749299487\n",
            "Test 0.139766355274559\n",
            "0.1635334225965218\n",
            "Epoch: 21\n",
            "Train:  0.16147745721385007\n",
            "Test 0.1489152763134394\n",
            "0.16058806040286905\n",
            "Epoch: 22\n",
            "Train:  0.16735016972409908\n",
            "Test 0.15434330266528515\n",
            "0.15933169256866425\n",
            "Epoch: 23\n",
            "Train:  0.16262691242163216\n",
            "Test 0.16334587379252954\n",
            "0.16013833808920705\n",
            "Epoch: 24\n",
            "Train:  0.15804136762798052\n",
            "Test 0.1555467437843591\n",
            "0.1592165367612816\n",
            "Epoch: 25\n",
            "Train:  0.16103443871644554\n",
            "Test 0.1515156237012792\n",
            "0.1576716851216947\n",
            "Epoch: 26\n",
            "Train:  0.13962839713879613\n",
            "Test 0.15267924969886248\n",
            "0.15667077799218443\n",
            "Epoch: 27\n",
            "Train:  0.1408526636933014\n",
            "Test 0.16574540243044003\n",
            "0.15848922025872755\n",
            "Epoch: 28\n",
            "Train:  0.170390902150204\n",
            "Test 0.1673105591601068\n",
            "0.16025622234228934\n",
            "Epoch: 29\n",
            "Train:  0.16025344288188131\n",
            "Test 0.15024124099378347\n",
            "0.15825074340991982\n",
            "Epoch: 30\n",
            "Train:  0.13092226851066308\n",
            "Test 0.2026992470653721\n",
            "0.16714925680182463\n",
            "Epoch: 31\n",
            "Train:  0.15219852541856496\n",
            "Test 0.15339806415277085\n",
            "0.1643968375808404\n",
            "Epoch: 32\n",
            "Train:  0.12641251719498756\n",
            "Test 0.15942400244297886\n",
            "0.16340163977171807\n",
            "Epoch: 33\n",
            "Train:  0.1265009826037162\n",
            "Test 0.1706156785586668\n",
            "0.1648451794907043\n",
            "Epoch: 34\n",
            "Train:  0.1308060682558023\n",
            "Test 0.16316203562194828\n",
            "0.1645084141086847\n",
            "Epoch: 35\n",
            "Train:  0.11382874106219032\n",
            "Test 0.18124150109115728\n",
            "0.16785611789717073\n",
            "Epoch: 36\n",
            "Train:  0.12175474590928918\n",
            "Test 0.16537186313057428\n",
            "0.16735913792047283\n",
            "Epoch: 37\n",
            "Train:  0.10654359426942245\n",
            "Test 0.17130383587145542\n",
            "0.1681482414010503\n",
            "Epoch: 38\n",
            "Train:  0.11311016262478225\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-10-15 12:30:03,570]\u001b[0m Trial 14 finished with value: 0.1686861275698171 and parameters: {'layer_size1': 256, 'layer_size2': 384, 'layer_size3': 384, 'layer_size4': 128, 'layer_size5': 128, 'learning_rate': 5.822835840638315e-05, 'b1': 0.9589673549554758}. Best is trial 3 with value: 0.12057808925100155.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test 0.17097736433857963\n",
            "0.16871416001791475\n",
            "Epoch: 0\n",
            "Train:  0.6929305770021655\n",
            "Test 0.6930986590437836\n",
            "0.6930986590437836\n",
            "Epoch: 1\n",
            "Train:  1.0391998823745783\n",
            "Test 0.6928196948963207\n",
            "0.6929436789618598\n",
            "Epoch: 2\n",
            "Train:  1.038728843678485\n",
            "Test 0.692604647451268\n",
            "0.6928047316214533\n",
            "Epoch: 3\n",
            "Train:  1.0382793172375187\n",
            "Test 0.6923822928697635\n",
            "0.6926616290632929\n",
            "Epoch: 4\n",
            "Train:  1.0377992673234626\n",
            "Test 0.6920616687872471\n",
            "0.6924831544452402\n",
            "Epoch: 5\n",
            "Train:  1.0372328522441152\n",
            "Test 0.6916252350632525\n",
            "0.6922506105933267\n",
            "Epoch: 6\n",
            "Train:  1.0365404535780895\n",
            "Test 0.6911760149421272\n",
            "0.6919786591016115\n",
            "Epoch: 7\n",
            "Train:  1.0357225436867374\n",
            "Test 0.6904837421445182\n",
            "0.6916194024449024\n",
            "Epoch: 8\n",
            "Train:  1.0346725781758626\n",
            "Test 0.6896872906894475\n",
            "0.6911730750441365\n",
            "Epoch: 9\n",
            "Train:  1.0334648141712497\n",
            "Test 0.6887334729288961\n",
            "0.6906264625516142\n",
            "Epoch: 10\n",
            "Train:  1.0320033319703825\n",
            "Test 0.6876152740730034\n",
            "0.6899676317182327\n",
            "Epoch: 11\n",
            "Train:  1.0302746474961222\n",
            "Test 0.6863329834117121\n",
            "0.6891870616932564\n",
            "Epoch: 12\n",
            "Train:  1.0282461230571454\n",
            "Test 0.6846643472329165\n",
            "0.6882298981805957\n",
            "Epoch: 13\n",
            "Train:  1.02578289102722\n",
            "Test 0.682753996971326\n",
            "0.6870843355619604\n",
            "Epoch: 14\n",
            "Train:  1.0229299780213352\n",
            "Test 0.6806869201171093\n",
            "0.6857581929789051\n",
            "Epoch: 15\n",
            "Train:  1.019369662899674\n",
            "Test 0.6779360138016306\n",
            "0.68414844681711\n",
            "Epoch: 16\n",
            "Train:  1.0151120332571177\n",
            "Test 0.6746167092969566\n",
            "0.6821981832824392\n",
            "Epoch: 17\n",
            "Train:  1.0097771465996683\n",
            "Test 0.6708431060497577\n",
            "0.6798855063520552\n",
            "Epoch: 18\n",
            "Train:  1.0035996520038926\n",
            "Test 0.6657716470323639\n",
            "0.677021459218993\n",
            "Epoch: 19\n",
            "Train:  0.9959127277463347\n",
            "Test 0.6597260937585936\n",
            "0.6735220405768517\n",
            "Epoch: 20\n",
            "Train:  0.986959084158852\n",
            "Test 0.6527117872849489\n",
            "0.6693212444125972\n",
            "Epoch: 21\n",
            "Train:  0.976149130762715\n",
            "Test 0.6442732568625565\n",
            "0.6642744078213974\n",
            "Epoch: 22\n",
            "Train:  0.9629767199794015\n",
            "Test 0.6339434044701713\n",
            "0.6581721859913506\n",
            "Epoch: 23\n",
            "Train:  0.9478299493318075\n",
            "Test 0.6228327928008613\n",
            "0.6510707718732403\n",
            "Epoch: 24\n",
            "Train:  0.9305814612697769\n",
            "Test 0.6096492931519673\n",
            "0.642755060258738\n",
            "Epoch: 25\n",
            "Train:  0.9110363577748393\n",
            "Test 0.5940685772197151\n",
            "0.6329882452638766\n",
            "Epoch: 26\n",
            "Train:  0.8876847737219744\n",
            "Test 0.576331879629757\n",
            "0.6216295083964983\n",
            "Epoch: 27\n",
            "Train:  0.8616427750814528\n",
            "Test 0.5567552805383563\n",
            "0.6086295171848211\n",
            "Epoch: 28\n",
            "Train:  0.8331528088767013\n",
            "Test 0.5356575313941899\n",
            "0.5940125012901563\n",
            "Epoch: 29\n",
            "Train:  0.8034864825643463\n",
            "Test 0.5155291463429238\n",
            "0.5782963746783144\n",
            "Epoch: 30\n",
            "Train:  0.7739083997277549\n",
            "Test 0.4930305594489688\n",
            "0.5612263062555061\n",
            "Epoch: 31\n",
            "Train:  0.7423596522965275\n",
            "Test 0.4705246226254837\n",
            "0.5430715858781371\n",
            "Epoch: 32\n",
            "Train:  0.7117538965228714\n",
            "Test 0.44831958227541857\n",
            "0.524109166296311\n",
            "Epoch: 33\n",
            "Train:  0.6806840582208319\n",
            "Test 0.4271115658484099\n",
            "0.5046998044910738\n",
            "Epoch: 34\n",
            "Train:  0.651468215517072\n",
            "Test 0.40718745180975385\n",
            "0.48518941960245304\n",
            "Epoch: 35\n",
            "Train:  0.62440249924258\n",
            "Test 0.3889433843093914\n",
            "0.4659339637911708\n",
            "Epoch: 36\n",
            "Train:  0.5990192422390858\n",
            "Test 0.3710347837580866\n",
            "0.4469491990578397\n",
            "Epoch: 37\n",
            "Train:  0.5777339392201805\n",
            "Test 0.35666174024015995\n",
            "0.4288879561209053\n",
            "Epoch: 38\n",
            "Train:  0.5560027950412625\n",
            "Test 0.342675282841637\n",
            "0.41164255608148526\n",
            "Epoch: 39\n",
            "Train:  0.5389172593097546\n",
            "Test 0.3301220314624982\n",
            "0.39533628368230983\n",
            "Epoch: 40\n",
            "Train:  0.5210429772243395\n",
            "Test 0.3181310583165277\n",
            "0.37989359646097864\n",
            "Epoch: 41\n",
            "Train:  0.5043193040204136\n",
            "Test 0.30720648355099744\n",
            "0.3653549370666248\n",
            "Epoch: 42\n",
            "Train:  0.48888052208519683\n",
            "Test 0.2967164608148428\n",
            "0.3516263074941553\n",
            "Epoch: 43\n",
            "Train:  0.474617063999176\n",
            "Test 0.28705027350139267\n",
            "0.33871039748657433\n",
            "Epoch: 44\n",
            "Train:  0.46119522136864644\n",
            "Test 0.2787456219340419\n",
            "0.3267169199864472\n",
            "Epoch: 45\n",
            "Train:  0.4487952505657961\n",
            "Test 0.26977158520684574\n",
            "0.3153274561656353\n",
            "Epoch: 46\n",
            "Train:  0.43627446731586594\n",
            "Test 0.26188557390328293\n",
            "0.3046387817564092\n",
            "Epoch: 47\n",
            "Train:  0.4260534563616955\n",
            "Test 0.254888521364102\n",
            "0.2946885077794231\n",
            "Epoch: 48\n",
            "Train:  0.41528161712018125\n",
            "Test 0.24895067381989824\n",
            "0.2855407777865616\n",
            "Epoch: 49\n",
            "Train:  0.40627834301837634\n",
            "Test 0.24335886183239164\n",
            "0.27710427418592465\n",
            "Epoch: 50\n",
            "Train:  0.3989017688884185\n",
            "Test 0.23822890773360983\n",
            "0.2693291121188047\n",
            "Epoch: 51\n",
            "Train:  0.38965224521064057\n",
            "Test 0.2330559030338958\n",
            "0.26207440403452453\n",
            "Epoch: 52\n",
            "Train:  0.3821949964396028\n",
            "Test 0.22943847667384934\n",
            "0.2555471708645797\n",
            "Epoch: 53\n",
            "Train:  0.37331518091452426\n",
            "Test 0.2229666616699416\n",
            "0.24903103093225532\n",
            "Epoch: 54\n",
            "Train:  0.3640209425295338\n",
            "Test 0.21746200781602126\n",
            "0.24271719678043585\n",
            "Epoch: 55\n",
            "Train:  0.3547562389146714\n",
            "Test 0.21189805906225037\n",
            "0.2365533461750957\n",
            "Epoch: 56\n",
            "Train:  0.34745731844733924\n",
            "Test 0.20873955877381803\n",
            "0.230990572044593\n",
            "Epoch: 57\n",
            "Train:  0.3404931701828927\n",
            "Test 0.20281033332531267\n",
            "0.22535451080505142\n",
            "Epoch: 58\n",
            "Train:  0.33080213683428783\n",
            "Test 0.19890023814343707\n",
            "0.22006364613744545\n",
            "Epoch: 59\n",
            "Train:  0.3238910796741645\n",
            "Test 0.19480720675471938\n",
            "0.21501235051981224\n",
            "Epoch: 60\n",
            "Train:  0.3171074383861416\n",
            "Test 0.19129294899357108\n",
            "0.21026846439857658\n",
            "Epoch: 61\n",
            "Train:  0.3102353266798533\n",
            "Test 0.18578214190163456\n",
            "0.2053711950959604\n",
            "Epoch: 62\n",
            "Train:  0.302934970556598\n",
            "Test 0.18245691737849198\n",
            "0.20078833595658258\n",
            "Epoch: 63\n",
            "Train:  0.29633445944978204\n",
            "Test 0.17901487849079645\n",
            "0.1964336417299395\n",
            "Epoch: 64\n",
            "Train:  0.29178645919612695\n",
            "Test 0.17556888121606667\n",
            "0.1922606875316403\n",
            "Epoch: 65\n",
            "Train:  0.28519143679967296\n",
            "Test 0.17236821511726239\n",
            "0.18828219145046554\n",
            "Epoch: 66\n",
            "Train:  0.2789172974207026\n",
            "Test 0.1714214074183187\n",
            "0.1849100335602664\n",
            "Epoch: 67\n",
            "Train:  0.27520852422362174\n",
            "Test 0.16674006181758838\n",
            "0.18127603827739394\n",
            "Epoch: 68\n",
            "Train:  0.2692737597631011\n",
            "Test 0.16430436675146823\n",
            "0.1778817032740346\n",
            "Epoch: 69\n",
            "Train:  0.26483632932543316\n",
            "Test 0.16295985309850602\n",
            "0.17489733274784935\n",
            "Epoch: 70\n",
            "Train:  0.26112646197443046\n",
            "Test 0.1599069153651213\n",
            "0.1718992488766349\n",
            "Epoch: 71\n",
            "Train:  0.2566970123366995\n",
            "Test 0.1582684507081797\n",
            "0.16917308895584574\n",
            "Epoch: 72\n",
            "Train:  0.2537423701404215\n",
            "Test 0.15721800923347473\n",
            "0.16678207280992882\n",
            "Epoch: 73\n",
            "Train:  0.25072703038379823\n",
            "Test 0.15541154488020545\n",
            "0.16450796707070975\n",
            "Epoch: 74\n",
            "Train:  0.24772858580458404\n",
            "Test 0.15401654216314192\n",
            "0.16240968197605687\n",
            "Epoch: 75\n",
            "Train:  0.24557848446985414\n",
            "Test 0.1527979607547159\n",
            "0.16048733764886658\n",
            "Epoch: 76\n",
            "Train:  0.24339628665820584\n",
            "Test 0.15412252625593773\n",
            "0.15921437532635252\n",
            "Epoch: 77\n",
            "Train:  0.24375172984196153\n",
            "Test 0.15260989766144928\n",
            "0.15789347975690593\n",
            "Epoch: 78\n",
            "Train:  0.2406944696938162\n",
            "Test 0.15000979210703802\n",
            "0.15631674219210917\n",
            "Epoch: 79\n",
            "Train:  0.23668786338206393\n",
            "Test 0.1493132821123897\n",
            "0.15491605015141718\n",
            "Epoch: 80\n",
            "Train:  0.2347126554752335\n",
            "Test 0.1486425899760627\n",
            "0.1536613580986115\n",
            "Epoch: 81\n",
            "Train:  0.23675789072727546\n",
            "Test 0.15144270330994994\n",
            "0.15321762713586157\n",
            "Epoch: 82\n",
            "Train:  0.23382800839322826\n",
            "Test 0.1470985584841161\n",
            "0.15199381339444154\n",
            "Epoch: 83\n",
            "Train:  0.2324138296710075\n",
            "Test 0.1464357445964883\n",
            "0.15088219962680613\n",
            "Epoch: 84\n",
            "Train:  0.22920923805607982\n",
            "Test 0.14580678808820116\n",
            "0.1498671173132082\n",
            "Epoch: 85\n",
            "Train:  0.22755240236883198\n",
            "Test 0.14597323951703725\n",
            "0.14908834175036698\n",
            "Epoch: 86\n",
            "Train:  0.22614872581137843\n",
            "Test 0.14626611173562296\n",
            "0.14852389574532668\n",
            "Epoch: 87\n",
            "Train:  0.22552206222268142\n",
            "Test 0.1458485709441887\n",
            "0.14798883078351302\n",
            "Epoch: 88\n",
            "Train:  0.225009975142968\n",
            "Test 0.14579671909248\n",
            "0.14755040844426673\n",
            "Epoch: 89\n",
            "Train:  0.2233902808933795\n",
            "Test 0.14328963740732206\n",
            "0.14669825423526114\n",
            "Epoch: 90\n",
            "Train:  0.2231674372140086\n",
            "Test 0.14336566732780182\n",
            "0.14603173685275772\n",
            "Epoch: 91\n",
            "Train:  0.22057452623565227\n",
            "Test 0.14464962378744678\n",
            "0.14575531423935992\n",
            "Epoch: 92\n",
            "Train:  0.22017124690961487\n",
            "Test 0.1424911352686393\n",
            "0.14510247844458166\n",
            "Epoch: 93\n",
            "Train:  0.21741429526672695\n",
            "Test 0.14435643219685818\n",
            "0.14495326919492102\n",
            "Epoch: 94\n",
            "Train:  0.21820447733114054\n",
            "Test 0.14155749212472868\n",
            "0.14427411378046034\n",
            "Epoch: 95\n",
            "Train:  0.21927958718695484\n",
            "Test 0.14147209414645975\n",
            "0.14371370985338153\n",
            "Epoch: 96\n",
            "Train:  0.2150252577712275\n",
            "Test 0.14129595593600483\n",
            "0.1432301590697138\n",
            "Epoch: 97\n",
            "Train:  0.2143871086434676\n",
            "Test 0.14155074812117077\n",
            "0.14289427687989828\n",
            "Epoch: 98\n",
            "Train:  0.21354726306248062\n",
            "Test 0.14035633921404897\n",
            "0.14238668934659918\n",
            "Epoch: 99\n",
            "Train:  0.2140362497842137\n",
            "Test 0.14009721114576518\n",
            "0.1419287937063391\n",
            "Epoch: 100\n",
            "Train:  0.21083582485360758\n",
            "Test 0.1420859890979725\n",
            "0.1419602327846709\n",
            "Epoch: 101\n",
            "Train:  0.21231923114522036\n",
            "Test 0.13966757632218874\n",
            "0.1415017014921147\n",
            "Epoch: 102\n",
            "Train:  0.20987355438890037\n",
            "Test 0.1391970167420941\n",
            "0.1410407645420625\n",
            "Epoch: 103\n",
            "Train:  0.20851032996052132\n",
            "Test 0.13891150055268964\n",
            "0.14061491174415242\n",
            "Epoch: 104\n",
            "Train:  0.2074367194828806\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-10-15 12:31:48,790]\u001b[0m Trial 15 finished with value: 0.14053254820382077 and parameters: {'layer_size1': 256, 'layer_size2': 512, 'layer_size3': 384, 'layer_size4': 64, 'layer_size5': 256, 'learning_rate': 5.49371421224227e-06, 'b1': 0.9267592796813164}. Best is trial 3 with value: 0.12057808925100155.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test 0.14020309408942422\n",
            "0.14053254821320127\n",
            "Epoch: 0\n",
            "Train:  0.6921479426897489\n",
            "Test 0.6906426538041223\n",
            "0.6906426538041223\n",
            "Epoch: 1\n",
            "Train:  1.0313012113064637\n",
            "Test 0.6791083817080263\n",
            "0.6842347248618469\n",
            "Epoch: 2\n",
            "Train:  0.9996549155249264\n",
            "Test 0.6198132321948097\n",
            "0.6578324737687988\n",
            "Epoch: 3\n",
            "Train:  0.8465765332564329\n",
            "Test 0.3886400507046626\n",
            "0.5666426285573706\n",
            "Epoch: 4\n",
            "Train:  0.5566421250502268\n",
            "Test 0.2706941353095757\n",
            "0.47860464270307657\n",
            "Epoch: 5\n",
            "Train:  0.43940300876513505\n",
            "Test 0.23018582989444664\n",
            "0.41126933261313225\n",
            "Epoch: 6\n",
            "Train:  0.3532846828738412\n",
            "Test 0.19528219125646373\n",
            "0.356608749148369\n",
            "Epoch: 7\n",
            "Train:  0.29642672804030745\n",
            "Test 0.15372275410991013\n",
            "0.307851429268645\n",
            "Epoch: 8\n",
            "Train:  0.2514691514137027\n",
            "Test 0.14706636983014287\n",
            "0.2707092828795579\n",
            "Epoch: 9\n",
            "Train:  0.23550406731528678\n",
            "Test 0.14421124849127326\n",
            "0.24236637997576346\n",
            "Epoch: 10\n",
            "Train:  0.22736142270075968\n",
            "Test 0.14696934319786972\n",
            "0.22149405342133027\n",
            "Epoch: 11\n",
            "Train:  0.23127092472908697\n",
            "Test 0.1560041993965596\n",
            "0.20742957931523845\n",
            "Epoch: 12\n",
            "Train:  0.22215854341075533\n",
            "Test 0.13583650778392295\n",
            "0.19227799801821166\n",
            "Epoch: 13\n",
            "Train:  0.20322339852159713\n",
            "Test 0.13354279388138007\n",
            "0.17999054948952578\n",
            "Epoch: 14\n",
            "Train:  0.1986386777505606\n",
            "Test 0.13067120476028857\n",
            "0.16976697033046637\n",
            "Epoch: 15\n",
            "Train:  0.19471312653368864\n",
            "Test 0.13038061727384181\n",
            "0.16166155248933523\n",
            "Epoch: 16\n",
            "Train:  0.18476178208297808\n",
            "Test 0.128804491853321\n",
            "0.15493875645352354\n",
            "Epoch: 17\n",
            "Train:  0.17751741882809352\n",
            "Test 0.12692409909531582\n",
            "0.14923303993065692\n",
            "Epoch: 18\n",
            "Train:  0.17217889409802253\n",
            "Test 0.12361570507127642\n",
            "0.14403465635612747\n",
            "Epoch: 19\n",
            "Train:  0.1648209159993379\n",
            "Test 0.12643809897668196\n",
            "0.14047429672844952\n",
            "Epoch: 20\n",
            "Train:  0.1829242273592032\n",
            "Test 0.14031549424850706\n",
            "0.14044224056655377\n",
            "Epoch: 21\n",
            "Train:  0.16807423942106617\n",
            "Test 0.14394684796368246\n",
            "0.14114837237911093\n",
            "Epoch: 22\n",
            "Train:  0.16601752792570346\n",
            "Test 0.1332201339080998\n",
            "0.13955330909315916\n",
            "Epoch: 23\n",
            "Train:  0.1490453213846461\n",
            "Test 0.12290732037180509\n",
            "0.13620831506118636\n",
            "Epoch: 24\n",
            "Train:  0.14687591989016358\n",
            "Test 0.12074150286969684\n",
            "0.13310322191263974\n",
            "Epoch: 25\n",
            "Train:  0.13405242603145975\n",
            "Test 0.12093013323052025\n",
            "0.13066122368945718\n",
            "Epoch: 26\n",
            "Train:  0.1302120840831936\n",
            "Test 0.12256085219359769\n",
            "0.1290372227970655\n",
            "Epoch: 27\n",
            "Train:  0.12600266646283367\n",
            "Test 0.12253789214550384\n",
            "0.12773483748718806\n",
            "Epoch: 28\n",
            "Train:  0.12623391961960306\n",
            "Test 0.1688641103414389\n",
            "0.13597344067898687\n",
            "Epoch: 29\n",
            "Train:  0.151221514955818\n",
            "Test 0.1251090355592715\n",
            "0.1337978664245658\n",
            "Epoch: 30\n",
            "Train:  0.11505836294622812\n",
            "Test 0.12618616007732383\n",
            "0.13227401600676053\n",
            "Epoch: 31\n",
            "Train:  0.11043010920886592\n",
            "Test 0.14518236707991514\n",
            "0.1348577332530903\n",
            "Epoch: 32\n",
            "Train:  0.12799463156719892\n",
            "Test 0.14940451316180683\n",
            "0.13776893442779187\n",
            "Epoch: 33\n",
            "Train:  0.13912687059483345\n",
            "Test 0.1283103145536158\n",
            "0.13587625074831572\n",
            "Epoch: 34\n",
            "Train:  0.1104729092976713\n",
            "Test 0.12614446911183033\n",
            "0.13392910456468954\n",
            "Epoch: 35\n",
            "Train:  0.10483941438287196\n",
            "Test 0.1287479306668305\n",
            "0.13289253339854212\n",
            "Epoch: 36\n",
            "Train:  0.09797048529416759\n",
            "Test 0.12790848700936897\n",
            "0.13189546526702114\n",
            "Epoch: 37\n",
            "Train:  0.09276207788393666\n",
            "Test 0.1305554973387122\n",
            "0.1316274160097067\n",
            "Epoch: 38\n",
            "Train:  0.09406722123899255\n",
            "Test 0.13840686250605957\n",
            "0.1329835306321675\n",
            "Epoch: 39\n",
            "Train:  0.10407743297539473\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-10-15 12:32:27,976]\u001b[0m Trial 16 finished with value: 0.14625381647817273 and parameters: {'layer_size1': 256, 'layer_size2': 384, 'layer_size3': 384, 'layer_size4': 192, 'layer_size5': 192, 'learning_rate': 5.008568844118077e-05, 'b1': 0.9514778509866569}. Best is trial 3 with value: 0.12057808925100155.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test 0.199423342578141\n",
            "0.14627325952933284\n",
            "Epoch: 0\n",
            "Train:  0.6930505074424185\n",
            "Test 0.6945940395851276\n",
            "0.6945940395851276\n",
            "Epoch: 1\n",
            "Train:  1.0400117461061302\n",
            "Test 0.6942878712664594\n",
            "0.6944239460747564\n",
            "Epoch: 2\n",
            "Train:  1.039593246830252\n",
            "Test 0.6939936077201759\n",
            "0.6942475778966497\n",
            "Epoch: 3\n",
            "Train:  1.0390773308582795\n",
            "Test 0.6935873232481681\n",
            "0.6940239143978415\n",
            "Epoch: 4\n",
            "Train:  1.0384988562091366\n",
            "Test 0.6931394255641616\n",
            "0.6937607989665946\n",
            "Epoch: 5\n",
            "Train:  1.0378205276234247\n",
            "Test 0.6926207896117326\n",
            "0.6934517930481331\n",
            "Epoch: 6\n",
            "Train:  1.037035501265264\n",
            "Test 0.6920208433172205\n",
            "0.6930896578455041\n",
            "Epoch: 7\n",
            "Train:  1.0361154813032885\n",
            "Test 0.6912029863713862\n",
            "0.6926362552114087\n",
            "Epoch: 8\n",
            "Train:  1.0349490963495696\n",
            "Test 0.6904232715949034\n",
            "0.6921250450173277\n",
            "Epoch: 9\n",
            "Train:  1.033685836381528\n",
            "Test 0.6894465383592543\n",
            "0.6915249040388212\n",
            "Epoch: 10\n",
            "Train:  1.0321062349137806\n",
            "Test 0.6880976324116354\n",
            "0.6907750365900039\n",
            "Epoch: 11\n",
            "Train:  1.0301210613914462\n",
            "Test 0.6864979463619191\n",
            "0.6898564969832494\n",
            "Epoch: 12\n",
            "Train:  1.0277255251730755\n",
            "Test 0.6847438589557187\n",
            "0.6887744851480326\n",
            "Epoch: 13\n",
            "Train:  1.0250440868702564\n",
            "Test 0.6825751760503748\n",
            "0.6874775850594005\n",
            "Epoch: 14\n",
            "Train:  1.0218345588380164\n",
            "Test 0.6802553204826383\n",
            "0.6859804566199705\n",
            "Epoch: 15\n",
            "Train:  1.0183812183338208\n",
            "Test 0.677681137353946\n",
            "0.6842725185849012\n",
            "Epoch: 16\n",
            "Train:  1.0140568570339636\n",
            "Test 0.6739441003554907\n",
            "0.6821592483232035\n",
            "Epoch: 17\n",
            "Train:  1.0084980505726713\n",
            "Test 0.6699997540358659\n",
            "0.6796827365965792\n",
            "Epoch: 18\n",
            "Train:  1.00215659342406\n",
            "Test 0.6647675605047316\n",
            "0.6766560826986353\n",
            "Epoch: 19\n",
            "Train:  0.9944118645601657\n",
            "Test 0.6586212487447829\n",
            "0.6730070453718129\n",
            "Epoch: 20\n",
            "Train:  0.9850541440558521\n",
            "Test 0.651786458797944\n",
            "0.6687234185734103\n",
            "Epoch: 21\n",
            "Train:  0.9744147472765856\n",
            "Test 0.6433073066093109\n",
            "0.6636024098053329\n",
            "Epoch: 22\n",
            "Train:  0.9614784991566515\n",
            "Test 0.6332192656758068\n",
            "0.6574896978971344\n",
            "Epoch: 23\n",
            "Train:  0.9460750296439007\n",
            "Test 0.6214361317428477\n",
            "0.6502447714685398\n",
            "Epoch: 24\n",
            "Train:  0.9284716003980392\n",
            "Test 0.6068555979064969\n",
            "0.6415340284996214\n",
            "Epoch: 25\n",
            "Train:  0.9066973329682053\n",
            "Test 0.5911170560798366\n",
            "0.6314200664409861\n",
            "Epoch: 26\n",
            "Train:  0.8820881785708906\n",
            "Test 0.5717032645648216\n",
            "0.6194477588021031\n",
            "Epoch: 27\n",
            "Train:  0.8536970087023446\n",
            "Test 0.5514046237582252\n",
            "0.6058127578658358\n",
            "Epoch: 28\n",
            "Train:  0.8232960476106777\n",
            "Test 0.5284114543334905\n",
            "0.5903085054908741\n",
            "Epoch: 29\n",
            "Train:  0.7895538082052936\n",
            "Test 0.5045026289674389\n",
            "0.573126059348134\n",
            "Epoch: 30\n",
            "Train:  0.7549391438017835\n",
            "Test 0.47930168603366113\n",
            "0.554342582430717\n",
            "Epoch: 31\n",
            "Train:  0.7190924091435178\n",
            "Test 0.45425015633359495\n",
            "0.5343082243575197\n",
            "Epoch: 32\n",
            "Train:  0.6821488417657741\n",
            "Test 0.4288646971786415\n",
            "0.5132061438892581\n",
            "Epoch: 33\n",
            "Train:  0.645930820223176\n",
            "Test 0.40291205976472233\n",
            "0.49113613624097396\n",
            "Epoch: 34\n",
            "Train:  0.6094958397931668\n",
            "Test 0.3782972360486949\n",
            "0.468559197908301\n",
            "Epoch: 35\n",
            "Train:  0.5749044525863487\n",
            "Test 0.3555770776210687\n",
            "0.4459554385115479\n",
            "Epoch: 36\n",
            "Train:  0.542661910092001\n",
            "Test 0.33436425832601696\n",
            "0.42363140682446176\n",
            "Epoch: 37\n",
            "Train:  0.5127127469677628\n",
            "Test 0.31443508302335776\n",
            "0.40178760528415636\n",
            "Epoch: 38\n",
            "Train:  0.48467139255651187\n",
            "Test 0.29545799170658266\n",
            "0.38051814857397737\n",
            "Epoch: 39\n",
            "Train:  0.45832373403804205\n",
            "Test 0.278733104576558\n",
            "0.36015843350416776\n",
            "Epoch: 40\n",
            "Train:  0.43498994360913285\n",
            "Test 0.2635893157986931\n",
            "0.3408425559466558\n",
            "Epoch: 41\n",
            "Train:  0.41370881367952395\n",
            "Test 0.2502132896538619\n",
            "0.3227151605798466\n",
            "Epoch: 42\n",
            "Train:  0.3949869944280757\n",
            "Test 0.23943510597005432\n",
            "0.3060580160313735\n",
            "Epoch: 43\n",
            "Train:  0.37931223350130155\n",
            "Test 0.22892219101116335\n",
            "0.290630011046843\n",
            "Epoch: 44\n",
            "Train:  0.36447433756166325\n",
            "Test 0.21967570729308075\n",
            "0.27643853217000774\n",
            "Epoch: 45\n",
            "Train:  0.3510324921145107\n",
            "Test 0.2119161442959265\n",
            "0.2635336049241066\n",
            "Epoch: 46\n",
            "Train:  0.33997579088141194\n",
            "Test 0.20384049677586819\n",
            "0.2515946504849828\n",
            "Epoch: 47\n",
            "Train:  0.3281143149395129\n",
            "Test 0.1970068437385035\n",
            "0.24067684566050343\n",
            "Epoch: 48\n",
            "Train:  0.3182974387055788\n",
            "Test 0.19172607777101217\n",
            "0.23088651741731273\n",
            "Epoch: 49\n",
            "Train:  0.3089060348086741\n",
            "Test 0.18550827984626478\n",
            "0.2218107403692846\n",
            "Epoch: 50\n",
            "Train:  0.3011562588723588\n",
            "Test 0.18077647162007762\n",
            "0.21360379291266865\n",
            "Epoch: 51\n",
            "Train:  0.2948255531981096\n",
            "Test 0.17715575963586241\n",
            "0.20631411967062377\n",
            "Epoch: 52\n",
            "Train:  0.2902599749438492\n",
            "Test 0.17390685509412718\n",
            "0.19983261939170813\n",
            "Epoch: 53\n",
            "Train:  0.28250033875088115\n",
            "Test 0.17089297984054674\n",
            "0.19404465764501358\n",
            "Epoch: 54\n",
            "Train:  0.2778132693166589\n",
            "Test 0.16814412010130864\n",
            "0.18886452590980535\n",
            "Epoch: 55\n",
            "Train:  0.2728654918134649\n",
            "Test 0.16601480898402987\n",
            "0.18429456542639816\n",
            "Epoch: 56\n",
            "Train:  0.27006504324438807\n",
            "Test 0.16454705549574597\n",
            "0.1803450516187593\n",
            "Epoch: 57\n",
            "Train:  0.2665014173494372\n",
            "Test 0.16200985489310799\n",
            "0.17667800349279325\n",
            "Epoch: 58\n",
            "Train:  0.26236001167432726\n",
            "Test 0.16007899102710543\n",
            "0.17335819464016533\n",
            "Epoch: 59\n",
            "Train:  0.26077321774902795\n",
            "Test 0.15901661123875732\n",
            "0.17048987356419448\n",
            "Epoch: 60\n",
            "Train:  0.25735071978289564\n",
            "Test 0.15714094903824966\n",
            "0.16782008538585472\n",
            "Epoch: 61\n",
            "Train:  0.2570556866503133\n",
            "Test 0.15610591818888983\n",
            "0.16547724964861513\n",
            "Epoch: 62\n",
            "Train:  0.25456884201793445\n",
            "Test 0.15490699405253153\n",
            "0.16336319687063283\n",
            "Epoch: 63\n",
            "Train:  0.2536573749608718\n",
            "Test 0.15727944379406317\n",
            "0.16214644549155166\n",
            "Epoch: 64\n",
            "Train:  0.25048233296776756\n",
            "Test 0.15332415790703052\n",
            "0.16038198708859266\n",
            "Epoch: 65\n",
            "Train:  0.24659302635902997\n",
            "Test 0.15416444286758646\n",
            "0.1591384777448308\n",
            "Epoch: 66\n",
            "Train:  0.24769987336499788\n",
            "Test 0.15167561599186488\n",
            "0.15764590491454322\n",
            "Epoch: 67\n",
            "Train:  0.24476675861156905\n",
            "Test 0.1517300098424866\n",
            "0.15646272559592458\n",
            "Epoch: 68\n",
            "Train:  0.24299915849944173\n",
            "Test 0.15101895489535488\n",
            "0.15537397123186686\n",
            "Epoch: 69\n",
            "Train:  0.24163901944382069\n",
            "Test 0.1497783825183526\n",
            "0.15425485330501262\n",
            "Epoch: 70\n",
            "Train:  0.24082656638635383\n",
            "Test 0.15169593507437643\n",
            "0.153743069591514\n",
            "Epoch: 71\n",
            "Train:  0.24015069619800228\n",
            "Test 0.14878735418393935\n",
            "0.1527519264056195\n",
            "Epoch: 72\n",
            "Train:  0.23755833996466666\n",
            "Test 0.14797516176033587\n",
            "0.15179657339607444\n",
            "Epoch: 73\n",
            "Train:  0.23615666501046645\n",
            "Test 0.14772341867069622\n",
            "0.15098194239609278\n",
            "Epoch: 74\n",
            "Train:  0.23511832668667748\n",
            "Test 0.14695781673349084\n",
            "0.1501771172201763\n",
            "Epoch: 75\n",
            "Train:  0.23506607468352542\n",
            "Test 0.1489136112997165\n",
            "0.14992441602518383\n",
            "Epoch: 76\n",
            "Train:  0.23340151302734793\n",
            "Test 0.14605521493942747\n",
            "0.14915057578132834\n",
            "Epoch: 77\n",
            "Train:  0.2327476731184256\n",
            "Test 0.1455733563218798\n",
            "0.14843513186968738\n",
            "Epoch: 78\n",
            "Train:  0.23068397778731126\n",
            "Test 0.14611321566933458\n",
            "0.14797074861936066\n",
            "Epoch: 79\n",
            "Train:  0.23038488926345502\n",
            "Test 0.14561484462066449\n",
            "0.14749956781129636\n",
            "Epoch: 80\n",
            "Train:  0.22931688307569578\n",
            "Test 0.14594409366107577\n",
            "0.147188472976855\n",
            "Epoch: 81\n",
            "Train:  0.22804324402415874\n",
            "Test 0.14443635558470702\n",
            "0.14663804949220133\n",
            "Epoch: 82\n",
            "Train:  0.22622560707668027\n",
            "Test 0.14337103606471213\n",
            "0.14598464680079262\n",
            "Epoch: 83\n",
            "Train:  0.22664721562585113\n",
            "Test 0.14324617145699023\n",
            "0.1454369517280685\n",
            "Epoch: 84\n",
            "Train:  0.22396286983629723\n",
            "Test 0.14352202357471863\n",
            "0.1450539660951812\n",
            "Epoch: 85\n",
            "Train:  0.22401612269395327\n",
            "Test 0.14273184947260134\n",
            "0.14458954276851418\n",
            "Epoch: 86\n",
            "Train:  0.22368457632296251\n",
            "Test 0.14309476189751982\n",
            "0.14429058659320754\n",
            "Epoch: 87\n",
            "Train:  0.22242481918875878\n",
            "Test 0.1418082105139127\n",
            "0.1437941113758769\n",
            "Epoch: 88\n",
            "Train:  0.22062882143430984\n",
            "Test 0.1439348429564264\n",
            "0.14382225769205353\n",
            "Epoch: 89\n",
            "Train:  0.2202399914961431\n",
            "Test 0.14118905765969894\n",
            "0.1432956176845835\n",
            "Epoch: 90\n",
            "Train:  0.21871017594736464\n",
            "Test 0.14196322007862094\n",
            "0.14302913816298657\n",
            "Epoch: 91\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-10-15 12:33:16,084]\u001b[0m Trial 17 finished with value: 0.14293432025900837 and parameters: {'layer_size1': 256, 'layer_size2': 512, 'layer_size3': 512, 'layer_size4': 128, 'layer_size5': 128, 'learning_rate': 4.873797924381152e-06, 'b1': 0.9315061954827539}. Best is trial 3 with value: 0.12057808925100155.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:  0.21933270874006788\n",
            "Test 0.14255504951140274\n",
            "0.14293432043255466\n",
            "Epoch: 0\n",
            "Train:  0.6921045963580792\n",
            "Test 0.6920724784061586\n",
            "0.6920724784061586\n",
            "Epoch: 1\n",
            "Train:  1.0337380858568044\n",
            "Test 0.6845816046327025\n",
            "0.6879108818653498\n",
            "Epoch: 2\n",
            "Train:  1.014971755363129\n",
            "Test 0.6545760443795732\n",
            "0.674249063223638\n",
            "Epoch: 3\n",
            "Train:  0.9474854755314278\n",
            "Test 0.5567223340163737\n",
            "0.6344364855789006\n",
            "Epoch: 4\n",
            "Train:  0.7523105172883897\n",
            "Test 0.3668027916452387\n",
            "0.5548215123716\n",
            "Epoch: 5\n",
            "Train:  0.47964240037477934\n",
            "Test 0.2158782293290009\n",
            "0.4629490377850686\n",
            "Epoch: 6\n",
            "Train:  0.3151499541142048\n",
            "Test 0.16431594659120607\n",
            "0.3873729692098252\n",
            "Epoch: 7\n",
            "Train:  0.2684034906027518\n",
            "Test 0.16477012848515651\n",
            "0.3338773205363397\n",
            "Epoch: 8\n",
            "Train:  0.26174821596142356\n",
            "Test 0.162474417642796\n",
            "0.29428239963374503\n",
            "Epoch: 9\n",
            "Train:  0.251523814085639\n",
            "Test 0.15382037689097416\n",
            "0.2628107527301341\n",
            "Epoch: 10\n",
            "Train:  0.24196489454475623\n",
            "Test 0.14772859390402016\n",
            "0.23763143395107936\n",
            "Epoch: 11\n",
            "Train:  0.23398005009898337\n",
            "Test 0.14693252123455644\n",
            "0.21815311126509926\n",
            "Epoch: 12\n",
            "Train:  0.22876720435084988\n",
            "Test 0.1438793336269838\n",
            "0.2024341994199921\n",
            "Epoch: 13\n",
            "Train:  0.22419922616701204\n",
            "Test 0.14557889797093668\n",
            "0.190540027936214\n",
            "Epoch: 14\n",
            "Train:  0.2189538683128226\n",
            "Test 0.1419298311511239\n",
            "0.18046345053036672\n",
            "Epoch: 15\n",
            "Train:  0.21631252319439426\n",
            "Test 0.14551541809633975\n",
            "0.173271405986513\n",
            "Epoch: 16\n",
            "Train:  0.2141710255472433\n",
            "Test 0.14764645037961094\n",
            "0.16802835178028533\n",
            "Epoch: 17\n",
            "Train:  0.20787260562672719\n",
            "Test 0.14451912132811634\n",
            "0.1632402509330865\n",
            "Epoch: 18\n",
            "Train:  0.20723061910369894\n",
            "Test 0.1355583839316344\n",
            "0.15762292331010916\n",
            "Epoch: 19\n",
            "Train:  0.1987730000635452\n",
            "Test 0.13616929937413325\n",
            "0.1532821528467766\n",
            "Epoch: 20\n",
            "Train:  0.1948668944475415\n",
            "Test 0.13280722747246423\n",
            "0.14914904659528883\n",
            "Epoch: 21\n",
            "Train:  0.1848934082102863\n",
            "Test 0.13343705037683795\n",
            "0.14598328817746553\n",
            "Epoch: 22\n",
            "Train:  0.18363457027099508\n",
            "Test 0.12963491623654907\n",
            "0.1426941984303058\n",
            "Epoch: 23\n",
            "Train:  0.1810721265964019\n",
            "Test 0.13011668977283297\n",
            "0.14016676121401347\n",
            "Epoch: 24\n",
            "Train:  0.17659072501537126\n",
            "Test 0.13465618257557516\n",
            "0.13906046602125507\n",
            "Epoch: 25\n",
            "Train:  0.17520651472357165\n",
            "Test 0.12610281185134425\n",
            "0.13646107902212687\n",
            "Epoch: 26\n",
            "Train:  0.16463670745874062\n",
            "Test 0.14019730190436044\n",
            "0.13721013470408205\n",
            "Epoch: 27\n",
            "Train:  0.1738650430430532\n",
            "Test 0.130306434345128\n",
            "0.13582671871660082\n",
            "Epoch: 28\n",
            "Train:  0.16028514826898854\n",
            "Test 0.12607933602367455\n",
            "0.13387422083388353\n",
            "Epoch: 29\n",
            "Train:  0.16033940720491302\n",
            "Test 0.12276319321586099\n",
            "0.13164926094334473\n",
            "Epoch: 30\n",
            "Train:  0.15604205989712105\n",
            "Test 0.1330588601312972\n",
            "0.13193146025759936\n",
            "Epoch: 31\n",
            "Train:  0.15300955645093564\n",
            "Test 0.12290596903298363\n",
            "0.13012493073252823\n",
            "Epoch: 32\n",
            "Train:  0.14114880448057157\n",
            "Test 0.13567076689664329\n",
            "0.1312348014294788\n",
            "Epoch: 33\n",
            "Train:  0.14409951967014095\n",
            "Test 0.12415900908328675\n",
            "0.1298189250256111\n",
            "Epoch: 34\n",
            "Train:  0.13546257336784304\n",
            "Test 0.12416824883348121\n",
            "0.12868833116382913\n",
            "Epoch: 35\n",
            "Train:  0.13422626575912203\n",
            "Test 0.12483018013774912\n",
            "0.12791645046900646\n",
            "Epoch: 36\n",
            "Train:  0.1366722117572163\n",
            "Test 0.12632156596365537\n",
            "0.12759739073529358\n",
            "Epoch: 37\n",
            "Train:  0.12759944886112443\n",
            "Test 0.13708269235852\n",
            "0.1294948451458019\n",
            "Epoch: 38\n",
            "Train:  0.13292528965575245\n",
            "Test 0.14431964136973952\n",
            "0.13246029711081092\n",
            "Epoch: 39\n",
            "Train:  0.14157523124925656\n",
            "Test 0.1368387412900726\n",
            "0.133336102361149\n",
            "Epoch: 40\n",
            "Train:  0.12514134859598\n",
            "Test 0.12515244556543154\n",
            "0.13169919693636414\n",
            "Epoch: 41\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-10-15 12:33:35,611]\u001b[0m Trial 18 finished with value: 0.14386321619411396 and parameters: {'layer_size1': 384, 'layer_size2': 384, 'layer_size3': 384, 'layer_size4': 64, 'layer_size5': 128, 'learning_rate': 3.5849215380327975e-05, 'b1': 0.9179286862581453}. Best is trial 3 with value: 0.12057808925100155.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:  0.12106087998292603\n",
            "Test 0.19257531186818203\n",
            "0.1438754557642713\n",
            "Epoch: 0\n",
            "Train:  0.6877795933803796\n",
            "Test 0.671618898272951\n",
            "0.671618898272951\n",
            "Epoch: 1\n",
            "Train:  0.8797611150440279\n",
            "Test 0.28263629847393806\n",
            "0.4555174539401661\n",
            "Epoch: 2\n",
            "Train:  0.39827971138578633\n",
            "Test 0.1857024099636864\n",
            "0.34493751788423177\n",
            "Epoch: 3\n",
            "Train:  0.2940646785655956\n",
            "Test 0.17556055188656616\n",
            "0.2875604968823125\n",
            "Epoch: 4\n",
            "Train:  0.2891390789010231\n",
            "Test 0.1693550255422518\n",
            "0.2523970415812473\n",
            "Epoch: 5\n",
            "Train:  0.271719187835825\n",
            "Test 0.14770991161411062\n",
            "0.22402100886832324\n",
            "Epoch: 6\n",
            "Train:  0.24862103925628976\n",
            "Test 0.14692339890605802\n",
            "0.2045096605639486\n",
            "Epoch: 7\n",
            "Train:  0.23455052790760775\n",
            "Test 0.1920281004419912\n",
            "0.2015101069508521\n",
            "Epoch: 8\n",
            "Train:  0.25512078735336063\n",
            "Test 0.14198104891202826\n",
            "0.187758599218704\n",
            "Epoch: 9\n",
            "Train:  0.2175167507727395\n",
            "Test 0.13571751407678528\n",
            "0.1760983751660676\n",
            "Epoch: 10\n",
            "Train:  0.18630810033175207\n",
            "Test 0.14887892955661694\n",
            "0.17014291599689202\n",
            "Epoch: 11\n",
            "Train:  0.1822740324319173\n",
            "Test 0.15575923482058468\n",
            "0.167053904508518\n",
            "Epoch: 12\n",
            "Train:  0.17867075730688298\n",
            "Test 0.1616117723333912\n",
            "0.16590216026404134\n",
            "Epoch: 13\n",
            "Train:  0.17964858188372337\n",
            "Test 0.1362096178225982\n",
            "0.15969045823121794\n",
            "Epoch: 14\n",
            "Train:  0.144846624316095\n",
            "Test 0.16054139394081118\n",
            "0.15986685166535738\n",
            "Epoch: 15\n",
            "Train:  0.15431381389157567\n",
            "Test 0.1390187884425069\n",
            "0.15557647567252092\n",
            "Epoch: 16\n",
            "Train:  0.12660660331679896\n",
            "Test 0.14065609245659996\n",
            "0.1525236556333833\n",
            "Epoch: 17\n",
            "Train:  0.10924977688255273\n",
            "Test 0.15994772011407346\n",
            "0.15403570722954144\n",
            "Epoch: 18\n",
            "Train:  0.11162450418708635\n",
            "Test 0.16233474209650092\n",
            "0.155719784311473\n",
            "Epoch: 19\n",
            "Train:  0.10453621313194322\n",
            "Test 0.17590822802426723\n",
            "0.15980456739663723\n",
            "Epoch: 20\n",
            "Train:  0.10881988411862979\n",
            "Test 0.1787776523184427\n",
            "0.1636345093606116\n",
            "Epoch: 21\n",
            "Train:  0.10812070705431544\n",
            "Test 0.22072372604694404\n",
            "0.17513722777900453\n",
            "Epoch: 22\n",
            "Train:  0.13113373684325366\n",
            "Test 0.19128551134573563\n",
            "0.1783860622259767\n",
            "Epoch: 23\n",
            "Train:  0.10616382049829887\n",
            "Test 0.21604132457197767\n",
            "0.18595284782989588\n",
            "Epoch: 24\n",
            "Train:  0.11946516895551502\n",
            "Test 0.22917435935019573\n",
            "0.19462993122820324\n",
            "Epoch: 25\n",
            "Train:  0.12147220535816913\n",
            "Test 0.20254379576208553\n",
            "0.1962175022740492\n",
            "Epoch: 26\n",
            "Train:  0.10661156658908769\n",
            "Test 0.23663960407818957\n",
            "0.2043215169400217\n",
            "Epoch: 27\n",
            "Train:  0.12623034054481957\n",
            "Test 0.2524702476900626\n",
            "0.2139699258270246\n",
            "Epoch: 28\n",
            "Train:  0.14149874287433217\n",
            "Test 0.25071671520805006\n",
            "0.2213306739091922\n",
            "Epoch: 29\n",
            "Train:  0.1298087698402354\n",
            "Test 0.21259466771227428\n",
            "0.21958130705854076\n",
            "Epoch: 30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-10-15 12:33:50,221]\u001b[0m Trial 19 finished with value: 0.2238397182652952 and parameters: {'layer_size1': 384, 'layer_size2': 384, 'layer_size3': 512, 'layer_size4': 128, 'layer_size5': 192, 'learning_rate': 0.00012873949066715415, 'b1': 0.94539389469858}. Best is trial 3 with value: 0.12057808925100155.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:  0.10799236007296846\n",
            "Test 0.24196067705985855\n",
            "0.2240616181439892\n",
            "Epoch: 0\n",
            "Train:  0.6932501768891192\n",
            "Test 0.6951761542659103\n",
            "0.6951761542659103\n",
            "Epoch: 1\n",
            "Train:  1.0402793613545624\n",
            "Test 0.6945501705665729\n",
            "0.6948283855440562\n",
            "Epoch: 2\n",
            "Train:  1.0394553380571443\n",
            "Test 0.693871775826255\n",
            "0.694436332381023\n",
            "Epoch: 3\n",
            "Train:  1.0385112806117578\n",
            "Test 0.6930942574700156\n",
            "0.6939816999585949\n",
            "Epoch: 4\n",
            "Train:  1.0373837915095654\n",
            "Test 0.6920551026697124\n",
            "0.6934085808222068\n",
            "Epoch: 5\n",
            "Train:  1.0359506834120977\n",
            "Test 0.6908447264315007\n",
            "0.692713633734779\n",
            "Epoch: 6\n",
            "Train:  1.03415489535192\n",
            "Test 0.6893121759533446\n",
            "0.6918528155129342\n",
            "Epoch: 7\n",
            "Train:  1.031723012199332\n",
            "Test 0.6874087577337747\n",
            "0.6907848248580771\n",
            "Epoch: 8\n",
            "Train:  1.028639705408187\n",
            "Test 0.6845870605318538\n",
            "0.6893531105514522\n",
            "Epoch: 9\n",
            "Train:  1.0244520019480596\n",
            "Test 0.6814369790719979\n",
            "0.6875794375692527\n",
            "Epoch: 10\n",
            "Train:  1.0194752902993351\n",
            "Test 0.6765597687536107\n",
            "0.6851683969980733\n",
            "Epoch: 11\n",
            "Train:  1.0118105966092903\n",
            "Test 0.6708651457950746\n",
            "0.6820966584948631\n",
            "Epoch: 12\n",
            "Train:  1.002129119612795\n",
            "Test 0.6626341037261181\n",
            "0.6779777057174635\n",
            "Epoch: 13\n",
            "Train:  0.9892301917512775\n",
            "Test 0.6515332248621372\n",
            "0.6724455005918857\n",
            "Epoch: 14\n",
            "Train:  0.9718555304811988\n",
            "Test 0.6389536803021972\n",
            "0.6655028642330203\n",
            "Epoch: 15\n",
            "Train:  0.9513422454888131\n",
            "Test 0.6231992580951788\n",
            "0.6567970974553526\n",
            "Epoch: 16\n",
            "Train:  0.9258857548455179\n",
            "Test 0.6025923215425931\n",
            "0.6457064020135049\n",
            "Epoch: 17\n",
            "Train:  0.895827265667828\n",
            "Test 0.5822517275810242\n",
            "0.6327826535723536\n",
            "Epoch: 18\n",
            "Train:  0.8648995552962516\n",
            "Test 0.5584300948586656\n",
            "0.6176947015249165\n",
            "Epoch: 19\n",
            "Train:  0.8299624132804382\n",
            "Test 0.5348804534136594\n",
            "0.600938667988707\n",
            "Epoch: 20\n",
            "Train:  0.792938239190168\n",
            "Test 0.5064557157593332\n",
            "0.5818661647497855\n",
            "Epoch: 21\n",
            "Train:  0.7515123375169523\n",
            "Test 0.4778645956690932\n",
            "0.5609112308122765\n",
            "Epoch: 22\n",
            "Train:  0.7107161754544401\n",
            "Test 0.44820615343558484\n",
            "0.5382363665632717\n",
            "Epoch: 23\n",
            "Train:  0.6663158676235668\n",
            "Test 0.4191181677165049\n",
            "0.5142996890302249\n",
            "Epoch: 24\n",
            "Train:  0.6248846013685723\n",
            "Test 0.38986462965989727\n",
            "0.48931830013727656\n",
            "Epoch: 25\n",
            "Train:  0.5829955471522642\n",
            "Test 0.3631641834210127\n",
            "0.4640109901428306\n",
            "Epoch: 26\n",
            "Train:  0.5435828264161344\n",
            "Test 0.33645542484500035\n",
            "0.438438045497133\n",
            "Epoch: 27\n",
            "Train:  0.5065105328193078\n",
            "Test 0.31268079027588114\n",
            "0.4132378501860492\n",
            "Epoch: 28\n",
            "Train:  0.4745378554304004\n",
            "Test 0.2933562262590988\n",
            "0.3892243663342305\n",
            "Epoch: 29\n",
            "Train:  0.446341668511485\n",
            "Test 0.27350481285717027\n",
            "0.36605176935320144\n",
            "Epoch: 30\n",
            "Train:  0.41694654868199277\n",
            "Test 0.25800463480827135\n",
            "0.3444209202889031\n",
            "Epoch: 31\n",
            "Train:  0.39388914297133576\n",
            "Test 0.24210192612457626\n",
            "0.3239408955087219\n",
            "Epoch: 32\n",
            "Train:  0.373224346328786\n",
            "Test 0.23042691065059914\n",
            "0.3052262367128695\n",
            "Epoch: 33\n",
            "Train:  0.3544480453753646\n",
            "Test 0.21789024142555266\n",
            "0.2877501762399869\n",
            "Epoch: 34\n",
            "Train:  0.3405707391736272\n",
            "Test 0.2098919315870865\n",
            "0.2721722081348088\n",
            "Epoch: 35\n",
            "Train:  0.3241803533373735\n",
            "Test 0.20050337201073057\n",
            "0.25783378782657296\n",
            "Epoch: 36\n",
            "Train:  0.31195452967624526\n",
            "Test 0.19550823805096385\n",
            "0.24536544090352316\n",
            "Epoch: 37\n",
            "Train:  0.3031408042534367\n",
            "Test 0.18651415589146125\n",
            "0.2335927388065462\n",
            "Epoch: 38\n",
            "Train:  0.2921703373296903\n",
            "Test 0.18080448656728415\n",
            "0.22303333387661234\n",
            "Epoch: 39\n",
            "Train:  0.2823269265011335\n",
            "Test 0.1771027754528291\n",
            "0.21384600098584716\n",
            "Epoch: 40\n",
            "Train:  0.27821140525173466\n",
            "Test 0.17206928101214733\n",
            "0.20548976840404423\n",
            "Epoch: 41\n",
            "Train:  0.2717317446465894\n",
            "Test 0.1705836362781979\n",
            "0.19850794803128452\n",
            "Epoch: 42\n",
            "Train:  0.2719458188629631\n",
            "Test 0.16457941234384701\n",
            "0.19172177905106844\n",
            "Epoch: 43\n",
            "Train:  0.26339717122688616\n",
            "Test 0.16282967868305387\n",
            "0.1859430443532222\n",
            "Epoch: 44\n",
            "Train:  0.253775961178563\n",
            "Test 0.15974991812264963\n",
            "0.1807041909228587\n",
            "Epoch: 45\n",
            "Train:  0.2513244176222073\n",
            "Test 0.15719783630890724\n",
            "0.17600275617897732\n",
            "Epoch: 46\n",
            "Train:  0.24547244545631794\n",
            "Test 0.15826485722219988\n",
            "0.17245507749277378\n",
            "Epoch: 47\n",
            "Train:  0.24343073637576113\n",
            "Test 0.15348117692129953\n",
            "0.1686602127501672\n",
            "Epoch: 48\n",
            "Train:  0.24016139024506994\n",
            "Test 0.15206562089068548\n",
            "0.16534123516573215\n",
            "Epoch: 49\n",
            "Train:  0.23630310967564583\n",
            "Test 0.150935546819107\n",
            "0.16246005637484934\n",
            "Epoch: 50\n",
            "Train:  0.23366908330620426\n",
            "Test 0.14995486185555057\n",
            "0.1599589889138475\n",
            "Epoch: 51\n",
            "Train:  0.2315076059446885\n",
            "Test 0.14818188067757604\n",
            "0.15760354575106797\n",
            "Epoch: 52\n",
            "Train:  0.2290153059794571\n",
            "Test 0.14713755675724574\n",
            "0.15551033265613168\n",
            "Epoch: 53\n",
            "Train:  0.22687101123970507\n",
            "Test 0.14953460222308015\n",
            "0.15431517958264868\n",
            "Epoch: 54\n",
            "Train:  0.22607501955095666\n",
            "Test 0.145599652245477\n",
            "0.15257206596301143\n",
            "Epoch: 55\n",
            "Train:  0.22579961113850058\n",
            "Test 0.14539532147811882\n",
            "0.15113671169573503\n",
            "Epoch: 56\n",
            "Train:  0.22360191026177162\n",
            "Test 0.14500061834688152\n",
            "0.14990948935269718\n",
            "Epoch: 57\n",
            "Train:  0.22064081932189483\n",
            "Test 0.14335567687020634\n",
            "0.14859872371753888\n",
            "Epoch: 58\n",
            "Train:  0.22038835139719995\n",
            "Test 0.14355802710676369\n",
            "0.14759058246416887\n",
            "Epoch: 59\n",
            "Train:  0.22093541838310576\n",
            "Test 0.142032426280471\n",
            "0.14647894952385676\n",
            "Epoch: 60\n",
            "Train:  0.21917106966136685\n",
            "Test 0.1436601005521886\n",
            "0.14591517903834253\n",
            "Epoch: 61\n",
            "Train:  0.21420516938844444\n",
            "Test 0.14068895766354633\n",
            "0.14486993373820967\n",
            "Epoch: 62\n",
            "Train:  0.21225245556053826\n",
            "Test 0.141301623521707\n",
            "0.14415627113494253\n",
            "Epoch: 63\n",
            "Train:  0.21335816173217234\n",
            "Test 0.13966421341530352\n",
            "0.14325785902707233\n",
            "Epoch: 64\n",
            "Train:  0.20917788415724214\n",
            "Test 0.1395210379482189\n",
            "0.14251049443599897\n",
            "Epoch: 65\n",
            "Train:  0.20928035593240252\n",
            "Test 0.139028860413002\n",
            "0.14181416735166094\n",
            "Epoch: 66\n",
            "Train:  0.20870148758284557\n",
            "Test 0.14347550330253747\n",
            "0.14214643464862287\n",
            "Epoch: 67\n",
            "Train:  0.2078202755050563\n",
            "Test 0.13826488673127504\n",
            "0.1413701248655562\n",
            "Epoch: 68\n",
            "Train:  0.20579531633776132\n",
            "Test 0.13809516987739465\n",
            "0.14071513373320005\n",
            "Epoch: 69\n",
            "Train:  0.20338284901101075\n",
            "Test 0.13737469136496602\n",
            "0.14004704514961894\n",
            "Epoch: 70\n",
            "Train:  0.20099541888787195\n",
            "Test 0.13724188064480877\n",
            "0.13948601217480233\n",
            "Epoch: 71\n",
            "Train:  0.1996019948342126\n",
            "Test 0.13679360077058003\n",
            "0.13894752983724906\n",
            "Epoch: 72\n",
            "Train:  0.1984381428868561\n",
            "Test 0.135958341182288\n",
            "0.13834969205588912\n",
            "Epoch: 73\n",
            "Train:  0.19671958966194328\n",
            "Test 0.1358987786721834\n",
            "0.13785950934610972\n",
            "Epoch: 74\n",
            "Train:  0.19832038813894923\n",
            "Test 0.13551283920108725\n",
            "0.1373901752917988\n",
            "Epoch: 75\n",
            "Train:  0.19547552244410246\n",
            "Test 0.1352913624337523\n",
            "0.13697041270208266\n",
            "Epoch: 76\n",
            "Train:  0.19308613100849883\n",
            "Test 0.13559964931682572\n",
            "0.13669626001557061\n",
            "Epoch: 77\n",
            "Train:  0.19242720245537195\n",
            "Test 0.1342871909817824\n",
            "0.13621444619551154\n",
            "Epoch: 78\n",
            "Train:  0.19150068877681053\n",
            "Test 0.13573028199415613\n",
            "0.13611761335310185\n",
            "Epoch: 79\n",
            "Train:  0.19155184081124463\n",
            "Test 0.13341823996013993\n",
            "0.13557773866497072\n",
            "Epoch: 80\n",
            "Train:  0.18859937279775138\n",
            "Test 0.1335041424389178\n",
            "0.1351630194138982\n",
            "Epoch: 81\n",
            "Train:  0.18732213033465567\n",
            "Test 0.1329663465747903\n",
            "0.1347236848411087\n",
            "Epoch: 82\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-10-15 12:34:29,013]\u001b[0m Trial 20 finished with value: 0.13435053909434969 and parameters: {'layer_size1': 256, 'layer_size2': 512, 'layer_size3': 384, 'layer_size4': 64, 'layer_size5': 64, 'learning_rate': 9.74299259463374e-06, 'b1': 0.9672321649511412}. Best is trial 3 with value: 0.12057808925100155.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:  0.18592375590578541\n",
            "Test 0.132857962201039\n",
            "0.13435054030971919\n",
            "Epoch: 0\n",
            "Train:  0.6930263872111674\n",
            "Test 0.6920397962842669\n",
            "0.6920397962842668\n",
            "Epoch: 1\n",
            "Train:  1.0378006187987414\n",
            "Test 0.6908952766285711\n",
            "0.6914039520311026\n",
            "Epoch: 2\n",
            "Train:  1.0355536516332802\n",
            "Test 0.6888073604185503\n",
            "0.6903397751407123\n",
            "Epoch: 3\n",
            "Train:  1.031657168498406\n",
            "Test 0.6853319332276508\n",
            "0.6886433517284286\n",
            "Epoch: 4\n",
            "Train:  1.0249107405816242\n",
            "Test 0.6782589563519963\n",
            "0.6855542288772767\n",
            "Epoch: 5\n",
            "Train:  1.0119067368271586\n",
            "Test 0.6643411148162115\n",
            "0.6798042955404021\n",
            "Epoch: 6\n",
            "Train:  0.9853465788530342\n",
            "Test 0.6348409117796482\n",
            "0.6684252626244825\n",
            "Epoch: 7\n",
            "Train:  0.929254025657535\n",
            "Test 0.5745721854569711\n",
            "0.6458706032736222\n",
            "Epoch: 8\n",
            "Train:  0.8270590346811455\n",
            "Test 0.47939193969244487\n",
            "0.6074132060814613\n",
            "Epoch: 9\n",
            "Train:  0.6837215712873927\n",
            "Test 0.37708542886234464\n",
            "0.5558064134752608\n",
            "Epoch: 10\n",
            "Train:  0.5506106040307454\n",
            "Test 0.30220907844684936\n",
            "0.5003207656100056\n",
            "Epoch: 11\n",
            "Train:  0.44940468704416636\n",
            "Test 0.2483563278511767\n",
            "0.44620937135991845\n",
            "Epoch: 12\n",
            "Train:  0.38203016223706604\n",
            "Test 0.21189985590758342\n",
            "0.3966213372651647\n",
            "Epoch: 13\n",
            "Train:  0.3353377734839698\n",
            "Test 0.19272521847770327\n",
            "0.3539661170847228\n",
            "Epoch: 14\n",
            "Train:  0.311500133175553\n",
            "Test 0.1801571941528565\n",
            "0.31793665862577064\n",
            "Epoch: 15\n",
            "Train:  0.2876334814525349\n",
            "Test 0.16884144811785265\n",
            "0.28725397578025075\n",
            "Epoch: 16\n",
            "Train:  0.2737792626009647\n",
            "Test 0.16400809321320536\n",
            "0.26203696261128595\n",
            "Epoch: 17\n",
            "Train:  0.2680663631976524\n",
            "Test 0.15976516308856534\n",
            "0.24120737012693874\n",
            "Epoch: 18\n",
            "Train:  0.259067532132233\n",
            "Test 0.1565628469317824\n",
            "0.22403092685261208\n",
            "Epoch: 19\n",
            "Train:  0.2540308680562746\n",
            "Test 0.15407298606284808\n",
            "0.20987614517274192\n",
            "Epoch: 20\n",
            "Train:  0.24891617966495155\n",
            "Test 0.15397072482458402\n",
            "0.19859097376875165\n",
            "Epoch: 21\n",
            "Train:  0.24809942582806388\n",
            "Test 0.15298683390075907\n",
            "0.18940234568690745\n",
            "Epoch: 22\n",
            "Train:  0.24331062424914304\n",
            "Test 0.15187513115969334\n",
            "0.1818523353869825\n",
            "Epoch: 23\n",
            "Train:  0.23973885892238808\n",
            "Test 0.14844590556490553\n",
            "0.17513934823705035\n",
            "Epoch: 24\n",
            "Train:  0.2374834418023899\n",
            "Test 0.14822661617409177\n",
            "0.1697363900254452\n",
            "Epoch: 25\n",
            "Train:  0.23192176797287367\n",
            "Test 0.14678869652988275\n",
            "0.16513293824704706\n",
            "Epoch: 26\n",
            "Train:  0.22831126816925548\n",
            "Test 0.15784477153213033\n",
            "0.16367177202090863\n",
            "Epoch: 27\n",
            "Train:  0.23433050550111048\n",
            "Test 0.14434705131035638\n",
            "0.15979933750107692\n",
            "Epoch: 28\n",
            "Train:  0.223451903107791\n",
            "Test 0.14423358253452367\n",
            "0.15668136167386876\n",
            "Epoch: 29\n",
            "Train:  0.22231282596049945\n",
            "Test 0.14273288869213707\n",
            "0.1538882093223907\n",
            "Epoch: 30\n",
            "Train:  0.2173651067724267\n",
            "Test 0.14222351224212856\n",
            "0.15155295718463974\n",
            "Epoch: 31\n",
            "Train:  0.21905803110027489\n",
            "Test 0.1421794091989269\n",
            "0.14967676111182351\n",
            "Epoch: 32\n",
            "Train:  0.22037073065127646\n",
            "Test 0.1456242192795862\n",
            "0.14886573869885175\n",
            "Epoch: 33\n",
            "Train:  0.21638405803359034\n",
            "Test 0.14099391658991683\n",
            "0.14729057557447273\n",
            "Epoch: 34\n",
            "Train:  0.20847540555160232\n",
            "Test 0.14529956604316557\n",
            "0.14689221207277703\n",
            "Epoch: 35\n",
            "Train:  0.211010319791434\n",
            "Test 0.14511549878087673\n",
            "0.14653675406167732\n",
            "Epoch: 36\n",
            "Train:  0.20799075704299924\n",
            "Test 0.13883418183186988\n",
            "0.1449958395714425\n",
            "Epoch: 37\n",
            "Train:  0.20273107121060618\n",
            "Test 0.13766781503382403\n",
            "0.14352993020645516\n",
            "Epoch: 38\n",
            "Train:  0.1987201187643649\n",
            "Test 0.13708961813031753\n",
            "0.1422416537395844\n",
            "Epoch: 39\n",
            "Train:  0.19747021565411663\n",
            "Test 0.13826333678876743\n",
            "0.1414458845735556\n",
            "Epoch: 40\n",
            "Train:  0.19409188356987395\n",
            "Test 0.1357503609643096\n",
            "0.14030665870843334\n",
            "Epoch: 41\n",
            "Train:  0.1926581301136222\n",
            "Test 0.14886921758493987\n",
            "0.14201931618051924\n",
            "Epoch: 42\n",
            "Train:  0.19694132582820106\n",
            "Test 0.13541489719471214\n",
            "0.1406983424825465\n",
            "Epoch: 43\n",
            "Train:  0.18829778896392266\n",
            "Test 0.14069324578312073\n",
            "0.14069732308716018\n",
            "Epoch: 44\n",
            "Train:  0.190108265117111\n",
            "Test 0.13853644700413878\n",
            "0.14026512904585045\n",
            "Epoch: 45\n",
            "Train:  0.18767996035830115\n",
            "Test 0.14787174363521646\n",
            "0.14178650497593767\n",
            "Epoch: 46\n",
            "Train:  0.19180733082481685\n",
            "Test 0.14257818151729337\n",
            "0.14194484469807603\n",
            "Epoch: 47\n",
            "Train:  0.1833302786645408\n",
            "Test 0.13325956537500844\n",
            "0.1402077500949584\n",
            "Epoch: 48\n",
            "Train:  0.1786373428021295\n",
            "Test 0.15100179376565057\n",
            "0.14236659734421878\n",
            "Epoch: 49\n",
            "Train:  0.193743844342592\n",
            "Test 0.13966978816724904\n",
            "0.1418272278106856\n",
            "Epoch: 50\n",
            "Train:  0.17681818850075778\n",
            "Test 0.13678862370086678\n",
            "0.1408194954824527\n",
            "Epoch: 51\n",
            "Train:  0.1779986225177735\n",
            "Test 0.13248067818438777\n",
            "0.13915171678870664\n",
            "Epoch: 52\n",
            "Train:  0.16879726309012008\n",
            "Test 0.1300657713929048\n",
            "0.13733451443032516\n",
            "Epoch: 53\n",
            "Train:  0.1644774574424812\n",
            "Test 0.1294646537675089\n",
            "0.1357605330962567\n",
            "Epoch: 54\n",
            "Train:  0.163451751100493\n",
            "Test 0.13146435561497788\n",
            "0.1349012935815051\n",
            "Epoch: 55\n",
            "Train:  0.16480497754905576\n",
            "Test 0.13346740134033092\n",
            "0.13461451406030067\n",
            "Epoch: 56\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-10-15 12:34:54,999]\u001b[0m Trial 21 finished with value: 0.1356202868543831 and parameters: {'layer_size1': 384, 'layer_size2': 256, 'layer_size3': 384, 'layer_size4': 64, 'layer_size5': 128, 'learning_rate': 1.8834030227743224e-05, 'b1': 0.9419821124509784}. Best is trial 3 with value: 0.12057808925100155.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:  0.16328138547980195\n",
            "Test 0.1396453926414797\n",
            "0.13562069278818573\n",
            "Epoch: 0\n",
            "Train:  0.692221401811956\n",
            "Test 0.6908708974555299\n",
            "0.6908708974555299\n",
            "Epoch: 1\n",
            "Train:  1.0274780070607041\n",
            "Test 0.6638574399354257\n",
            "0.675863421055472\n",
            "Epoch: 2\n",
            "Train:  0.9173891631674854\n",
            "Test 0.42633637469330116\n",
            "0.5735982381201561\n",
            "Epoch: 3\n",
            "Train:  0.5419089422994481\n",
            "Test 0.20957516248409563\n",
            "0.4502841881079404\n",
            "Epoch: 4\n",
            "Train:  0.32080748604931236\n",
            "Test 0.15368680077376384\n",
            "0.36205317093332817\n",
            "Epoch: 5\n",
            "Train:  0.26233751670672345\n",
            "Test 0.1487780187156174\n",
            "0.30424374681325306\n",
            "Epoch: 6\n",
            "Train:  0.24278012777750307\n",
            "Test 0.15061598089643013\n",
            "0.26536465767555917\n",
            "Epoch: 7\n",
            "Train:  0.23592043251153968\n",
            "Test 0.14740908184112647\n",
            "0.23701771464744978\n",
            "Epoch: 8\n",
            "Train:  0.22796623482481465\n",
            "Test 0.15463801231849325\n",
            "0.21798759472165014\n",
            "Epoch: 9\n",
            "Train:  0.22249537155769028\n",
            "Test 0.1362740961568696\n",
            "0.19967902758105738\n",
            "Epoch: 10\n",
            "Train:  0.2067669914052873\n",
            "Test 0.13789023202417533\n",
            "0.18615999217043955\n",
            "Epoch: 11\n",
            "Train:  0.21277780896359746\n",
            "Test 0.1385669295229154\n",
            "0.17593899828973056\n",
            "Epoch: 12\n",
            "Train:  0.22066199506083742\n",
            "Test 0.15237941311829256\n",
            "0.170952971535827\n",
            "Epoch: 13\n",
            "Train:  0.20224675891627542\n",
            "Test 0.1295047626445145\n",
            "0.1622819753106031\n",
            "Epoch: 14\n",
            "Train:  0.17919599782034154\n",
            "Test 0.12754781724332453\n",
            "0.15508181041640912\n",
            "Epoch: 15\n",
            "Train:  0.1723495365389974\n",
            "Test 0.12912675758120995\n",
            "0.14974045403300712\n",
            "Epoch: 16\n",
            "Train:  0.175439800592924\n",
            "Test 0.12317483460073506\n",
            "0.14430493309622544\n",
            "Epoch: 17\n",
            "Train:  0.159800777614335\n",
            "Test 0.14295609882135532\n",
            "0.14403021740328192\n",
            "Epoch: 18\n",
            "Train:  0.16444244575533237\n",
            "Test 0.11847165577632167\n",
            "0.13884376035458787\n",
            "Epoch: 19\n",
            "Train:  0.14616189458349468\n",
            "Test 0.13082725098765977\n",
            "0.13722175806803538\n",
            "Epoch: 20\n",
            "Train:  0.1511179371540786\n",
            "Test 0.13624429971580104\n",
            "0.1370244465197717\n",
            "Epoch: 21\n",
            "Train:  0.1401069909265954\n",
            "Test 0.12302568264223718\n",
            "0.13420388164893857\n",
            "Epoch: 22\n",
            "Train:  0.13792330659960053\n",
            "Test 0.11971445325011518\n",
            "0.13128878829523896\n",
            "Epoch: 23\n",
            "Train:  0.12664090085692786\n",
            "Test 0.12952361788068498\n",
            "0.13093407914572933\n",
            "Epoch: 24\n",
            "Train:  0.12617483448182598\n",
            "Test 0.126524293078826\n",
            "0.13004877735675227\n",
            "Epoch: 25\n",
            "Train:  0.11840828868386509\n",
            "Test 0.1216214615783412\n",
            "0.12835820475891138\n",
            "Epoch: 26\n",
            "Train:  0.1138033417118338\n",
            "Test 0.12052103301899118\n",
            "0.1267869714017792\n",
            "Epoch: 27\n",
            "Train:  0.1010689726645202\n",
            "Test 0.14023086996305556\n",
            "0.12948096204979795\n",
            "Epoch: 28\n",
            "Train:  0.10905178490345581\n",
            "Test 0.13513924310754835\n",
            "0.13061437212849472\n",
            "Epoch: 29\n",
            "Train:  0.10870306983747052\n",
            "Test 0.12062942264294559\n",
            "0.12861490701346184\n",
            "Epoch: 30\n",
            "Train:  0.09258402623543209\n",
            "Test 0.12136734512910902\n",
            "0.12716395768597732\n",
            "Epoch: 31\n",
            "Train:  0.08860137084142507\n",
            "Test 0.12463552297362478\n",
            "0.1266578697793577\n",
            "Epoch: 32\n",
            "Train:  0.08679895119949657\n",
            "Test 0.13257647655058258\n",
            "0.1278423418819886\n",
            "Epoch: 33\n",
            "Train:  0.08649162036595327\n",
            "Test 0.12837904227431438\n",
            "0.12794973641595195\n",
            "Epoch: 34\n",
            "Train:  0.09588866644544695\n",
            "Test 0.12970398464700678\n",
            "0.12830072844144347\n",
            "Epoch: 35\n",
            "Train:  0.08216174830590467\n",
            "Test 0.1302093595484674\n",
            "0.12868257858030305\n",
            "Epoch: 36\n",
            "Train:  0.07862863615430267\n",
            "Test 0.136116550444291\n",
            "0.13016975904722394\n",
            "Epoch: 37\n",
            "Train:  0.08035466033004177\n",
            "Test 0.13680310040230917\n",
            "0.13149670291369978\n",
            "Epoch: 38\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-10-15 12:35:12,780]\u001b[0m Trial 22 finished with value: 0.1331892785803397 and parameters: {'layer_size1': 384, 'layer_size2': 256, 'layer_size3': 384, 'layer_size4': 64, 'layer_size5': 128, 'learning_rate': 7.322124813791914e-05, 'b1': 0.932165832352316}. Best is trial 3 with value: 0.12057808925100155.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:  0.0798515806721601\n",
            "Test 0.1400688244336909\n",
            "0.13321141212263363\n",
            "Epoch: 0\n",
            "Train:  0.693232190041315\n",
            "Test 0.6910421365783328\n",
            "0.6910421365783327\n",
            "Epoch: 1\n",
            "Train:  1.035661945740382\n",
            "Test 0.6879427354414385\n",
            "0.689320247057836\n",
            "Epoch: 2\n",
            "Train:  1.02828383685905\n",
            "Test 0.6796455579799611\n",
            "0.6853552105505102\n",
            "Epoch: 3\n",
            "Train:  1.009463131864429\n",
            "Test 0.6549519147628393\n",
            "0.6750559911102424\n",
            "Epoch: 4\n",
            "Train:  0.9599177269708543\n",
            "Test 0.5922469481443747\n",
            "0.6504221729980733\n",
            "Epoch: 5\n",
            "Train:  0.8382844634545155\n",
            "Test 0.4593930115629902\n",
            "0.5986426492332512\n",
            "Epoch: 6\n",
            "Train:  0.6484222606424883\n",
            "Test 0.3259247913683727\n",
            "0.5296250348580592\n",
            "Epoch: 7\n",
            "Train:  0.4735075626726989\n",
            "Test 0.23651411736404504\n",
            "0.4591849694322224\n",
            "Epoch: 8\n",
            "Train:  0.36401112164769855\n",
            "Test 0.1890384744811844\n",
            "0.3967797888948603\n",
            "Epoch: 9\n",
            "Train:  0.298938835414993\n",
            "Test 0.18123908571544148\n",
            "0.3484861592620221\n",
            "Epoch: 10\n",
            "Train:  0.27686980177030895\n",
            "Test 0.1522242516524844\n",
            "0.3055451753050494\n",
            "Epoch: 11\n",
            "Train:  0.2474457264669758\n",
            "Test 0.14733906193967267\n",
            "0.2715691370623751\n",
            "Epoch: 12\n",
            "Train:  0.23984043144590253\n",
            "Test 0.1484550119551656\n",
            "0.24551391083062613\n",
            "Epoch: 13\n",
            "Train:  0.23717223113614233\n",
            "Test 0.14675232899057997\n",
            "0.22485291422211706\n",
            "Epoch: 14\n",
            "Train:  0.23380918478791093\n",
            "Test 0.14431653998710298\n",
            "0.2081582480278358\n",
            "Epoch: 15\n",
            "Train:  0.23044086897220367\n",
            "Test 0.1516924466078098\n",
            "0.19653800703762134\n",
            "Epoch: 16\n",
            "Train:  0.22619380234935127\n",
            "Test 0.14062611881520723\n",
            "0.18509802387356467\n",
            "Epoch: 17\n",
            "Train:  0.21766620954232557\n",
            "Test 0.13942519636081033\n",
            "0.1757958859514955\n",
            "Epoch: 18\n",
            "Train:  0.21547995104144016\n",
            "Test 0.15251567985712391\n",
            "0.17107176294506465\n",
            "Epoch: 19\n",
            "Train:  0.21955746883055666\n",
            "Test 0.15642409153528267\n",
            "0.1681080594886262\n",
            "Epoch: 20\n",
            "Train:  0.22175547033002524\n",
            "Test 0.13773367795138022\n",
            "0.1619766307326431\n",
            "Epoch: 21\n",
            "Train:  0.20396729731154475\n",
            "Test 0.13654977963357182\n",
            "0.15685345817159724\n",
            "Epoch: 22\n",
            "Train:  0.19873093923506063\n",
            "Test 0.13404002923504774\n",
            "0.15226367911078667\n",
            "Epoch: 23\n",
            "Train:  0.1933130185518946\n",
            "Test 0.14266752882864012\n",
            "0.15033534274332797\n",
            "Epoch: 24\n",
            "Train:  0.19439212102511208\n",
            "Test 0.13167801379284141\n",
            "0.14658972641482473\n",
            "Epoch: 25\n",
            "Train:  0.1882465063652276\n",
            "Test 0.13419531465886714\n",
            "0.14410332938972958\n",
            "Epoch: 26\n",
            "Train:  0.18395086279609701\n",
            "Test 0.131114281359173\n",
            "0.1414992234417833\n",
            "Epoch: 27\n",
            "Train:  0.17847276582713528\n",
            "Test 0.1320087563147557\n",
            "0.139597451454364\n",
            "Epoch: 28\n",
            "Train:  0.17725538116054193\n",
            "Test 0.13577796962289584\n",
            "0.13883237118369499\n",
            "Epoch: 29\n",
            "Train:  0.1773679971271928\n",
            "Test 0.13013678727050623\n",
            "0.13709109881026685\n",
            "Epoch: 30\n",
            "Train:  0.1703263461050806\n",
            "Test 0.12881520438014835\n",
            "0.13543427908946692\n",
            "Epoch: 31\n",
            "Train:  0.16806443451328934\n",
            "Test 0.12636521864245773\n",
            "0.13361902881062415\n",
            "Epoch: 32\n",
            "Train:  0.16302412102381006\n",
            "Test 0.1284595633901301\n",
            "0.13258648127177164\n",
            "Epoch: 33\n",
            "Train:  0.16067709464702631\n",
            "Test 0.12748468272565378\n",
            "0.13156560391623107\n",
            "Epoch: 34\n",
            "Train:  0.16456995679802455\n",
            "Test 0.15032364619723537\n",
            "0.13531873482319892\n",
            "Epoch: 35\n",
            "Train:  0.17186370197553086\n",
            "Test 0.12435174438310957\n",
            "0.1331246247057392\n",
            "Epoch: 36\n",
            "Train:  0.14956117786924208\n",
            "Test 0.12496341642115143\n",
            "0.1314919591846188\n",
            "Epoch: 37\n",
            "Train:  0.14646674071749052\n",
            "Test 0.1267016099376993\n",
            "0.13053369031057635\n",
            "Epoch: 38\n",
            "Train:  0.14963559355013645\n",
            "Test 0.14325438443257477\n",
            "0.13307825192279252\n",
            "Epoch: 39\n",
            "Train:  0.15462400757745182\n",
            "Test 0.12356720545121055\n",
            "0.13117578974787775\n",
            "Epoch: 40\n",
            "Train:  0.13837066055838387\n",
            "Test 0.12467610524905907\n",
            "0.1298757146004114\n",
            "Epoch: 41\n",
            "Train:  0.13846361244117822\n",
            "Test 0.127178491799386\n",
            "0.12933622414543408\n",
            "Epoch: 42\n",
            "Train:  0.1362605301472239\n",
            "Test 0.12315032520116521\n",
            "0.12809896015275632\n",
            "Epoch: 43\n",
            "Train:  0.12987602499804898\n",
            "Test 0.12393503518768283\n",
            "0.1272661298161451\n",
            "Epoch: 44\n",
            "Train:  0.1273104469308923\n",
            "Test 0.12699491571252927\n",
            "0.127211884632711\n",
            "Epoch: 45\n",
            "Train:  0.12752068281385215\n",
            "Test 0.12550765797222926\n",
            "0.12687102742347436\n",
            "Epoch: 46\n",
            "Train:  0.12395077715917821\n",
            "Test 0.12639047264679243\n",
            "0.12677491378888087\n",
            "Epoch: 47\n",
            "Train:  0.12344019057253894\n",
            "Test 0.12602236098865724\n",
            "0.12662439987226365\n",
            "Epoch: 48\n",
            "Train:  0.12146345651094484\n",
            "Test 0.1320135727927307\n",
            "0.12770225368591168\n",
            "Epoch: 49\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-10-15 12:35:35,559]\u001b[0m Trial 23 finished with value: 0.1277650796572228 and parameters: {'layer_size1': 384, 'layer_size2': 256, 'layer_size3': 384, 'layer_size4': 64, 'layer_size5': 128, 'learning_rate': 3.2960678614434696e-05, 'b1': 0.9515242132423588}. Best is trial 3 with value: 0.12057808925100155.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:  0.12156236786975255\n",
            "Test 0.1280254966798136\n",
            "0.1277669032074009\n",
            "Epoch: 0\n",
            "Train:  0.6938300381649981\n",
            "Test 0.6924083427195147\n",
            "0.6924083427195147\n",
            "Epoch: 1\n",
            "Train:  1.0392112715558692\n",
            "Test 0.6919353036653428\n",
            "0.6921455432449748\n",
            "Epoch: 2\n",
            "Train:  1.0381807627040387\n",
            "Test 0.6913225292722821\n",
            "0.6918082424364941\n",
            "Epoch: 3\n",
            "Train:  1.0368257481536585\n",
            "Test 0.6905733346939087\n",
            "0.6913899132554014\n",
            "Epoch: 4\n",
            "Train:  1.0352576837871537\n",
            "Test 0.6892558681222546\n",
            "0.6907550830753839\n",
            "Epoch: 5\n",
            "Train:  1.0329458977713253\n",
            "Test 0.6875051578759274\n",
            "0.6898741726539855\n",
            "Epoch: 6\n",
            "Train:  1.029893969004844\n",
            "Test 0.6850538943713401\n",
            "0.6886542888139711\n",
            "Epoch: 7\n",
            "Train:  1.0254166490865715\n",
            "Test 0.681260517665318\n",
            "0.6868774265670525\n",
            "Epoch: 8\n",
            "Train:  1.0190308779587238\n",
            "Test 0.6760311021909609\n",
            "0.6843718718272827\n",
            "Epoch: 9\n",
            "Train:  1.0100831968007071\n",
            "Test 0.6684101383328002\n",
            "0.6807955169471609\n",
            "Epoch: 10\n",
            "Train:  0.997528361095177\n",
            "Test 0.6579506283714658\n",
            "0.6757971858610318\n",
            "Epoch: 11\n",
            "Train:  0.9799321507796263\n",
            "Test 0.6426831566807114\n",
            "0.6686856811418607\n",
            "Epoch: 12\n",
            "Train:  0.95640245112744\n",
            "Test 0.6236724246552575\n",
            "0.6591593121718917\n",
            "Epoch: 13\n",
            "Train:  0.924816268485981\n",
            "Test 0.595449964205424\n",
            "0.645831269042759\n",
            "Epoch: 14\n",
            "Train:  0.8802574294390696\n",
            "Test 0.557104868329925\n",
            "0.6274388636658007\n",
            "Epoch: 15\n",
            "Train:  0.8203699073512039\n",
            "Test 0.5077675796035446\n",
            "0.6028114055329097\n",
            "Epoch: 16\n",
            "Train:  0.7461489105508441\n",
            "Test 0.45002885495786704\n",
            "0.5715509730576664\n",
            "Epoch: 17\n",
            "Train:  0.6628126317000651\n",
            "Test 0.390929985723216\n",
            "0.5347640818730518\n",
            "Epoch: 18\n",
            "Train:  0.5819749313068914\n",
            "Test 0.3383035265700721\n",
            "0.49489743183564633\n",
            "Epoch: 19\n",
            "Train:  0.5121433786747657\n",
            "Test 0.2963607053616981\n",
            "0.45472695244546363\n",
            "Epoch: 20\n",
            "Train:  0.4578015646000048\n",
            "Test 0.26582890639811646\n",
            "0.4165956439918747\n",
            "Epoch: 21\n",
            "Train:  0.4175093141230908\n",
            "Test 0.24228078356155983\n",
            "0.3814735163458073\n",
            "Epoch: 22\n",
            "Train:  0.38446304207538073\n",
            "Test 0.22354822979741917\n",
            "0.3497009066522671\n",
            "Epoch: 23\n",
            "Train:  0.35827995918609284\n",
            "Test 0.20952156333477942\n",
            "0.3215320141549808\n",
            "Epoch: 24\n",
            "Train:  0.3364143697715504\n",
            "Test 0.19431031612686187\n",
            "0.29599118402122243\n",
            "Epoch: 25\n",
            "Train:  0.31491631809826737\n",
            "Test 0.1851700321658627\n",
            "0.2737597633038707\n",
            "Epoch: 26\n",
            "Train:  0.30450411179126835\n",
            "Test 0.18078178134593334\n",
            "0.25511909654560544\n",
            "Epoch: 27\n",
            "Train:  0.29081774123640725\n",
            "Test 0.16903383855199638\n",
            "0.23786867778426002\n",
            "Epoch: 28\n",
            "Train:  0.2796694212507852\n",
            "Test 0.16486156794614407\n",
            "0.2232446261928849\n",
            "Epoch: 29\n",
            "Train:  0.2735438654165128\n",
            "Test 0.16126384676157773\n",
            "0.21083310558831864\n",
            "Epoch: 30\n",
            "Train:  0.264442510056845\n",
            "Test 0.15848340361546248\n",
            "0.20035278598794112\n",
            "Epoch: 31\n",
            "Train:  0.26080743357157093\n",
            "Test 0.15659092383070305\n",
            "0.19159347371433025\n",
            "Epoch: 32\n",
            "Train:  0.25495468571290864\n",
            "Test 0.15487838319533473\n",
            "0.18424579846806305\n",
            "Epoch: 33\n",
            "Train:  0.2529965454828499\n",
            "Test 0.15455507053123727\n",
            "0.17830464035563898\n",
            "Epoch: 34\n",
            "Train:  0.251000856782818\n",
            "Test 0.15355853351931542\n",
            "0.17335341053094735\n",
            "Epoch: 35\n",
            "Train:  0.24864777094503734\n",
            "Test 0.15079647182544945\n",
            "0.1688405582855642\n",
            "Epoch: 36\n",
            "Train:  0.24299084545273483\n",
            "Test 0.15010222885757685\n",
            "0.1650919191976187\n",
            "Epoch: 37\n",
            "Train:  0.2413145395715622\n",
            "Test 0.14892068234760136\n",
            "0.1618569999611757\n",
            "Epoch: 38\n",
            "Train:  0.24002138403629808\n",
            "Test 0.1545490042098385\n",
            "0.16039515792073752\n",
            "Epoch: 39\n",
            "Train:  0.23953620403418283\n",
            "Test 0.1489082457490893\n",
            "0.15809747007130634\n",
            "Epoch: 40\n",
            "Train:  0.23667148380598305\n",
            "Test 0.15085158527115763\n",
            "0.15664813899196092\n",
            "Epoch: 41\n",
            "Train:  0.23464382252904958\n",
            "Test 0.1461425489940486\n",
            "0.15454684223381987\n",
            "Epoch: 42\n",
            "Train:  0.2329225564859944\n",
            "Test 0.1449945452230754\n",
            "0.15263625280369228\n",
            "Epoch: 43\n",
            "Train:  0.23031216825703124\n",
            "Test 0.1447691784509809\n",
            "0.1510627522636319\n",
            "Epoch: 44\n",
            "Train:  0.2282064950755446\n",
            "Test 0.14514242874069527\n",
            "0.1498786359835066\n",
            "Epoch: 45\n",
            "Train:  0.22773246839642525\n",
            "Test 0.14463179008591742\n",
            "0.1488292302375354\n",
            "Epoch: 46\n",
            "Train:  0.22804287591123537\n",
            "Test 0.1430786231757848\n",
            "0.14767907676358583\n",
            "Epoch: 47\n",
            "Train:  0.22235969878091807\n",
            "Test 0.14344542299912416\n",
            "0.14683232712754563\n",
            "Epoch: 48\n",
            "Train:  0.22215234681165644\n",
            "Test 0.14282918186523977\n",
            "0.14603168379113005\n",
            "Epoch: 49\n",
            "Train:  0.2233350651522914\n",
            "Test 0.14379334749292322\n",
            "0.14558401014207686\n",
            "Epoch: 50\n",
            "Train:  0.21858976680048547\n",
            "Test 0.14129042026378733\n",
            "0.14472528236148102\n",
            "Epoch: 51\n",
            "Train:  0.2168981656909753\n",
            "Test 0.14056605444504663\n",
            "0.14389342917972672\n",
            "Epoch: 52\n",
            "Train:  0.2146045095781922\n",
            "Test 0.1409340732604702\n",
            "0.1433015536707403\n",
            "Epoch: 53\n",
            "Train:  0.2149421255728537\n",
            "Test 0.14295632460396804\n",
            "0.14323250745374122\n",
            "Epoch: 54\n",
            "Train:  0.21589019203442575\n",
            "Test 0.14809653433142128\n",
            "0.14420531737891978\n",
            "Epoch: 55\n",
            "Train:  0.21601254396113284\n",
            "Test 0.1403708982080112\n",
            "0.14343843067547427\n",
            "Epoch: 56\n",
            "Train:  0.21181011031426134\n",
            "Test 0.13755592310821618\n",
            "0.1422619256405603\n",
            "Epoch: 57\n",
            "Train:  0.2067914407277282\n",
            "Test 0.13720380729780748\n",
            "0.1412502995496465\n",
            "Epoch: 58\n",
            "Train:  0.20582470169202202\n",
            "Test 0.13745377134982045\n",
            "0.14049099245513785\n",
            "Epoch: 59\n",
            "Train:  0.20503388094841998\n",
            "Test 0.13995886017182918\n",
            "0.1403845658353778\n",
            "Epoch: 60\n",
            "Train:  0.20486010647389097\n",
            "Test 0.1363485731430106\n",
            "0.13957736630728063\n",
            "Epoch: 61\n",
            "Train:  0.20480877212879858\n",
            "Test 0.14418946282985884\n",
            "0.14049978651650338\n",
            "Epoch: 62\n",
            "Train:  0.2064130248385908\n",
            "Test 0.13479500326699825\n",
            "0.13935882897136403\n",
            "Epoch: 63\n",
            "Train:  0.20045050475814621\n",
            "Test 0.13651827318873597\n",
            "0.13879071745822902\n",
            "Epoch: 64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-10-15 12:36:05,524]\u001b[0m Trial 24 finished with value: 0.14098598432610146 and parameters: {'layer_size1': 384, 'layer_size2': 256, 'layer_size3': 384, 'layer_size4': 128, 'layer_size5': 192, 'learning_rate': 9.519443231031128e-06, 'b1': 0.9467302337340799}. Best is trial 3 with value: 0.12057808925100155.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:  0.19802745292474935\n",
            "Test 0.1497674002789725\n",
            "0.14098605512480636\n",
            "Epoch: 0\n",
            "Train:  0.6929769219059647\n",
            "Test 0.692495577064626\n",
            "0.6924955770646258\n",
            "Epoch: 1\n",
            "Train:  1.0381441376148126\n",
            "Test 0.691814457103883\n",
            "0.6921171770864355\n",
            "Epoch: 2\n",
            "Train:  1.036521742413769\n",
            "Test 0.6904338694317437\n",
            "0.6914272969000863\n",
            "Epoch: 3\n",
            "Train:  1.0335005925688552\n",
            "Test 0.6874587310976161\n",
            "0.6900829317908485\n",
            "Epoch: 4\n",
            "Train:  1.02729192507136\n",
            "Test 0.6809650214163812\n",
            "0.6873705595947314\n",
            "Epoch: 5\n",
            "Train:  1.0140961340932182\n",
            "Test 0.6666750462500604\n",
            "0.6817609248300426\n",
            "Epoch: 6\n",
            "Train:  0.9876442562529456\n",
            "Test 0.6385629081027412\n",
            "0.6708286592145831\n",
            "Epoch: 7\n",
            "Train:  0.9332384659257127\n",
            "Test 0.5822771547478197\n",
            "0.6495480674798093\n",
            "Epoch: 8\n",
            "Train:  0.8334165438190921\n",
            "Test 0.4907978743642241\n",
            "0.6128759853063399\n",
            "Epoch: 9\n",
            "Train:  0.6947069993931732\n",
            "Test 0.3917912619236188\n",
            "0.5633401733180309\n",
            "Epoch: 10\n",
            "Train:  0.5575769595501624\n",
            "Test 0.30607608408281656\n",
            "0.5070522605839263\n",
            "Epoch: 11\n",
            "Train:  0.44737489166713895\n",
            "Test 0.24983250876486082\n",
            "0.45181224527306196\n",
            "Epoch: 12\n",
            "Train:  0.3743295600781074\n",
            "Test 0.21192667663315715\n",
            "0.40104412459477545\n",
            "Epoch: 13\n",
            "Train:  0.3269215609346117\n",
            "Test 0.1917808420219264\n",
            "0.357266089745905\n",
            "Epoch: 14\n",
            "Train:  0.2999317896289703\n",
            "Test 0.17668140330266602\n",
            "0.31983205961225014\n",
            "Epoch: 15\n",
            "Train:  0.2809613235840649\n",
            "Test 0.17158310655709152\n",
            "0.28932353024181656\n",
            "Epoch: 16\n",
            "Train:  0.27313387841532083\n",
            "Test 0.16260728725801893\n",
            "0.2633964558317982\n",
            "Epoch: 17\n",
            "Train:  0.2590106642999492\n",
            "Test 0.15622063412334455\n",
            "0.24156806618010157\n",
            "Epoch: 18\n",
            "Train:  0.2524885980637519\n",
            "Test 0.15849347880635506\n",
            "0.22471020126811747\n",
            "Epoch: 19\n",
            "Train:  0.24902499253578456\n",
            "Test 0.15311925903290183\n",
            "0.21022500993521384\n",
            "Epoch: 20\n",
            "Train:  0.24367645764279933\n",
            "Test 0.1501410384167791\n",
            "0.19809634847456628\n",
            "Epoch: 21\n",
            "Train:  0.24260969547684486\n",
            "Test 0.14991819926779784\n",
            "0.18838909172081492\n",
            "Epoch: 22\n",
            "Train:  0.23587340937975126\n",
            "Test 0.14836610471590972\n",
            "0.18033696294100196\n",
            "Epoch: 23\n",
            "Train:  0.23094053641507478\n",
            "Test 0.1462127712620047\n",
            "0.17347974229626414\n",
            "Epoch: 24\n",
            "Train:  0.2279272593093879\n",
            "Test 0.15320422613631673\n",
            "0.1694092612215576\n",
            "Epoch: 25\n",
            "Train:  0.23108632917833197\n",
            "Test 0.14474399913197908\n",
            "0.16446125437054737\n",
            "Epoch: 26\n",
            "Train:  0.22092229960957072\n",
            "Test 0.1525065494981004\n",
            "0.16206451844416958\n",
            "Epoch: 27\n",
            "Train:  0.22976704233841144\n",
            "Test 0.15008091892460326\n",
            "0.15966315362516514\n",
            "Epoch: 28\n",
            "Train:  0.21953010713961316\n",
            "Test 0.14135116829976932\n",
            "0.1559950804918375\n",
            "Epoch: 29\n",
            "Train:  0.2130973551681627\n",
            "Test 0.140173539628476\n",
            "0.15282685024008288\n",
            "Epoch: 30\n",
            "Train:  0.20978762949015195\n",
            "Test 0.1488348731955329\n",
            "0.15202766335481757\n",
            "Epoch: 31\n",
            "Train:  0.21318756767135838\n",
            "Test 0.1413358269129699\n",
            "0.14988760053399847\n",
            "Epoch: 32\n",
            "Train:  0.2042277127490703\n",
            "Test 0.14154937134325613\n",
            "0.14821889702935034\n",
            "Epoch: 33\n",
            "Train:  0.20752285334755813\n",
            "Test 0.1384943888075786\n",
            "0.14627300870239374\n",
            "Epoch: 34\n",
            "Train:  0.1985041698553487\n",
            "Test 0.1462202169301309\n",
            "0.1462624460632257\n",
            "Epoch: 35\n",
            "Train:  0.2029709884753594\n",
            "Test 0.13999397216890103\n",
            "0.14500834430507206\n",
            "Epoch: 36\n",
            "Train:  0.1951009942245953\n",
            "Test 0.13560623830122934\n",
            "0.14312743479227577\n",
            "Epoch: 37\n",
            "Train:  0.1919433867077824\n",
            "Test 0.14126609107513569\n",
            "0.1427550887155932\n",
            "Epoch: 38\n",
            "Train:  0.1948696501798682\n",
            "Test 0.1529573567873447\n",
            "0.1447958814147922\n",
            "Epoch: 39\n",
            "Train:  0.20080668124755768\n",
            "Test 0.13843034464702175\n",
            "0.14352260481374765\n",
            "Epoch: 40\n",
            "Train:  0.1867824656012103\n",
            "Test 0.1336263384356167\n",
            "0.14154314104542887\n",
            "Epoch: 41\n",
            "Train:  0.1815195140452721\n",
            "Test 0.1341285540725722\n",
            "0.1400600974874645\n",
            "Epoch: 42\n",
            "Train:  0.17845755855078663\n",
            "Test 0.13248987064693438\n",
            "0.1385459490717571\n",
            "Epoch: 43\n",
            "Train:  0.17351813854533674\n",
            "Test 0.13948119371692777\n",
            "0.1387330081852581\n",
            "Epoch: 44\n",
            "Train:  0.1789485378422853\n",
            "Test 0.13134381637632192\n",
            "0.13725510545172812\n",
            "Epoch: 45\n",
            "Train:  0.17283163313846012\n",
            "Test 0.13057520702453979\n",
            "0.13591907921257051\n",
            "Epoch: 46\n",
            "Train:  0.17041469761426306\n",
            "Test 0.1302054327922863\n",
            "0.13477631807298243\n",
            "Epoch: 47\n",
            "Train:  0.16524069938440245\n",
            "Test 0.13616627703110376\n",
            "0.13505431606416907\n",
            "Epoch: 48\n",
            "Train:  0.16793877265037416\n",
            "Test 0.13567786605093943\n",
            "0.13517902828646355\n",
            "Epoch: 49\n",
            "Train:  0.16413438042810002\n",
            "Test 0.13073182919304885\n",
            "0.13428957577309011\n",
            "Epoch: 50\n",
            "Train:  0.1611371145962359\n",
            "Test 0.12861023666917076\n",
            "0.13315369498284035\n",
            "Epoch: 51\n",
            "Train:  0.1567532848345027\n",
            "Test 0.13172511931085762\n",
            "0.13286797723858787\n",
            "Epoch: 52\n",
            "Train:  0.15751768146460746\n",
            "Test 0.1396323212698757\n",
            "0.13422085593101757\n",
            "Epoch: 53\n",
            "Train:  0.15822910201384416\n",
            "Test 0.12943164042910157\n",
            "0.13326300723104456\n",
            "Epoch: 54\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-10-15 12:36:30,269]\u001b[0m Trial 25 finished with value: 0.13658735514122575 and parameters: {'layer_size1': 256, 'layer_size2': 256, 'layer_size3': 256, 'layer_size4': 64, 'layer_size5': 128, 'learning_rate': 2.2518473567111453e-05, 'b1': 0.9115222727407118}. Best is trial 3 with value: 0.12057808925100155.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:  0.15119263275625397\n",
            "Test 0.14988786300760268\n",
            "0.13658799393667143\n",
            "Epoch: 0\n",
            "Train:  0.6932055196919285\n",
            "Test 0.69528561655855\n",
            "0.69528561655855\n",
            "Epoch: 1\n",
            "Train:  1.039962276543453\n",
            "Test 0.6941724188161857\n",
            "0.6946671733683477\n",
            "Epoch: 2\n",
            "Train:  1.038399188182293\n",
            "Test 0.6928810138842125\n",
            "0.6939351407928824\n",
            "Epoch: 3\n",
            "Train:  1.0364337107200763\n",
            "Test 0.6909536269558219\n",
            "0.692925142880599\n",
            "Epoch: 4\n",
            "Train:  1.0333848804126293\n",
            "Test 0.6880505443055988\n",
            "0.6914750600108345\n",
            "Epoch: 5\n",
            "Train:  1.0284828838411268\n",
            "Test 0.6841905946696635\n",
            "0.6895005648949392\n",
            "Epoch: 6\n",
            "Train:  1.0216788894090898\n",
            "Test 0.677530777541709\n",
            "0.6864713310407057\n",
            "Epoch: 7\n",
            "Train:  1.0104060091160156\n",
            "Test 0.6667372235011705\n",
            "0.6817288538989809\n",
            "Epoch: 8\n",
            "Train:  0.9913210470379491\n",
            "Test 0.6480293479157891\n",
            "0.6739441008327524\n",
            "Epoch: 9\n",
            "Train:  0.9591441333512247\n",
            "Test 0.6161809705552601\n",
            "0.6610018065054832\n",
            "Epoch: 10\n",
            "Train:  0.9046207576880961\n",
            "Test 0.5637726595986894\n",
            "0.6397286247234069\n",
            "Epoch: 11\n",
            "Train:  0.823176730246771\n",
            "Test 0.4972191177881681\n",
            "0.6091235592516704\n",
            "Epoch: 12\n",
            "Train:  0.7297942984453488\n",
            "Test 0.4311673165241004\n",
            "0.5714618355495267\n",
            "Epoch: 13\n",
            "Train:  0.6396206032225501\n",
            "Test 0.3708796005545955\n",
            "0.529499882331023\n",
            "Epoch: 14\n",
            "Train:  0.5628276464048323\n",
            "Test 0.32820571866227594\n",
            "0.4877729123596617\n",
            "Epoch: 15\n",
            "Train:  0.506515268768583\n",
            "Test 0.2933737570112878\n",
            "0.44776701539844205\n",
            "Epoch: 16\n",
            "Train:  0.46345114686113575\n",
            "Test 0.2656460679494418\n",
            "0.41050373134781704\n",
            "Epoch: 17\n",
            "Train:  0.4290572325170258\n",
            "Test 0.24535896495366707\n",
            "0.37686886620448234\n",
            "Epoch: 18\n",
            "Train:  0.4039638941159178\n",
            "Test 0.22916209752306396\n",
            "0.3468955514793112\n",
            "Epoch: 19\n",
            "Train:  0.37675084785009044\n",
            "Test 0.22108795545695029\n",
            "0.3214405561598038\n",
            "Epoch: 20\n",
            "Train:  0.3602219539738837\n",
            "Test 0.20832628808615408\n",
            "0.2986071010941162\n",
            "Epoch: 21\n",
            "Train:  0.33784652580490043\n",
            "Test 0.19444800160088382\n",
            "0.27762042687213734\n",
            "Epoch: 22\n",
            "Train:  0.32172417976371537\n",
            "Test 0.18677402884040997\n",
            "0.2593432579031155\n",
            "Epoch: 23\n",
            "Train:  0.3082726247294809\n",
            "Test 0.1795403045284879\n",
            "0.24330693784785243\n",
            "Epoch: 24\n",
            "Train:  0.29437773811184004\n",
            "Test 0.17322098084421822\n",
            "0.2292365901765293\n",
            "Epoch: 25\n",
            "Train:  0.2862113941010538\n",
            "Test 0.16988025087139982\n",
            "0.21732933484447425\n",
            "Epoch: 26\n",
            "Train:  0.2779968092729757\n",
            "Test 0.16664758553871742\n",
            "0.20716841739240532\n",
            "Epoch: 27\n",
            "Train:  0.2729650949274664\n",
            "Test 0.16325518003436346\n",
            "0.19836874888645956\n",
            "Epoch: 28\n",
            "Train:  0.2695704819208127\n",
            "Test 0.16230713906305613\n",
            "0.19114524909726288\n",
            "Epoch: 29\n",
            "Train:  0.2643152442470793\n",
            "Test 0.16509053700572843\n",
            "0.18592784784904978\n",
            "Epoch: 30\n",
            "Train:  0.2619790801089325\n",
            "Test 0.15647875203754438\n",
            "0.1800321899099321\n",
            "Epoch: 31\n",
            "Train:  0.259467968246439\n",
            "Test 0.15639428941758124\n",
            "0.1753008612667154\n",
            "Epoch: 32\n",
            "Train:  0.25320618328785066\n",
            "Test 0.16165589415655904\n",
            "0.17257013704258323\n",
            "Epoch: 33\n",
            "Train:  0.25880399528522413\n",
            "Test 0.15365591863572817\n",
            "0.16878537425848622\n",
            "Epoch: 34\n",
            "Train:  0.2480909998627591\n",
            "Test 0.15401366536570338\n",
            "0.16582983357019282\n",
            "Epoch: 35\n",
            "Train:  0.24723749609507156\n",
            "Test 0.1535536787735346\n",
            "0.16337380558421147\n",
            "Epoch: 36\n",
            "Train:  0.24383095234646138\n",
            "Test 0.15839984980258312\n",
            "0.16237875609826977\n",
            "Epoch: 37\n",
            "Train:  0.24648038041351478\n",
            "Test 0.15231653133700618\n",
            "0.16036589309072624\n",
            "Epoch: 38\n",
            "Train:  0.2397436128567645\n",
            "Test 0.14970403795058912\n",
            "0.1582331677029122\n",
            "Epoch: 39\n",
            "Train:  0.23698247900921784\n",
            "Test 0.14914240554357186\n",
            "0.15641477356500455\n",
            "Epoch: 40\n",
            "Train:  0.2373875040328983\n",
            "Test 0.15704373859769696\n",
            "0.15654057994957252\n",
            "Epoch: 41\n",
            "Train:  0.23593034899551354\n",
            "Test 0.14744130595699773\n",
            "0.1547205703217616\n",
            "Epoch: 42\n",
            "Train:  0.23155028654105497\n",
            "Test 0.1483659789566592\n",
            "0.15344956554863862\n",
            "Epoch: 43\n",
            "Train:  0.23040129181557087\n",
            "Test 0.14643421646330382\n",
            "0.1520464193370254\n",
            "Epoch: 44\n",
            "Train:  0.22634438137377139\n",
            "Test 0.14657119300980598\n",
            "0.15095132637355585\n",
            "Epoch: 45\n",
            "Train:  0.22497554518957877\n",
            "Test 0.1460340889000194\n",
            "0.14996784460951068\n",
            "Epoch: 46\n",
            "Train:  0.22373650285787197\n",
            "Test 0.14567689548481952\n",
            "0.14910963086106477\n",
            "Epoch: 47\n",
            "Train:  0.223333865185797\n",
            "Test 0.1496421035392817\n",
            "0.14921612777166862\n",
            "Epoch: 48\n",
            "Train:  0.22311066590495163\n",
            "Test 0.14811647877151712\n",
            "0.14899619404788958\n",
            "Epoch: 49\n",
            "Train:  0.21974114162144642\n",
            "Test 0.14537445573143035\n",
            "0.14827183604621486\n",
            "Epoch: 50\n",
            "Train:  0.21636636833568196\n",
            "Test 0.14465387705918198\n",
            "0.14754823598675615\n",
            "Epoch: 51\n",
            "Train:  0.21512531882131491\n",
            "Test 0.14580089212719338\n",
            "0.14719876402263204\n",
            "Epoch: 52\n",
            "Train:  0.21537558449903033\n",
            "Test 0.14245647819705934\n",
            "0.14625029992660835\n",
            "Epoch: 53\n",
            "Train:  0.21122533714419212\n",
            "Test 0.15262515164038418\n",
            "0.14752527772289206\n",
            "Epoch: 54\n",
            "Train:  0.21567341925801484\n",
            "Test 0.14247068937444862\n",
            "0.1465143553253162\n",
            "Epoch: 55\n",
            "Train:  0.20718707031000666\n",
            "Test 0.14200870370690202\n",
            "0.14561322163009197\n",
            "Epoch: 56\n",
            "Train:  0.205419564640129\n",
            "Test 0.14584151100735743\n",
            "0.14565887964220658\n",
            "Epoch: 57\n",
            "Train:  0.21106620797812392\n",
            "Test 0.1409853675535747\n",
            "0.1447241749863072\n",
            "Epoch: 58\n",
            "Train:  0.2016137445945934\n",
            "Test 0.1404804419794362\n",
            "0.1438754267590544\n",
            "Epoch: 59\n",
            "Train:  0.2016701742515459\n",
            "Test 0.14039216806213184\n",
            "0.14317877395205258\n",
            "Epoch: 60\n",
            "Train:  0.1990466347459325\n",
            "Test 0.14377366956118698\n",
            "0.14329775321974764\n",
            "Epoch: 61\n",
            "Train:  0.19854133275948166\n",
            "Test 0.1405389065079855\n",
            "0.14274598333622088\n",
            "Epoch: 62\n",
            "Train:  0.19964782580487675\n",
            "Test 0.13894884531887677\n",
            "0.14198655513687605\n",
            "Epoch: 63\n",
            "Train:  0.19309868960003385\n",
            "Test 0.140912366382805\n",
            "0.1417717172512059\n",
            "Epoch: 64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-10-15 12:37:03,528]\u001b[0m Trial 26 finished with value: 0.14189224866032552 and parameters: {'layer_size1': 384, 'layer_size2': 384, 'layer_size3': 512, 'layer_size4': 128, 'layer_size5': 64, 'learning_rate': 1.0475735852365639e-05, 'b1': 0.9328703342192955}. Best is trial 3 with value: 0.12057808925100155.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:  0.19385427097370336\n",
            "Test 0.14237473026300088\n",
            "0.14189231991412773\n",
            "Epoch: 0\n",
            "Train:  0.6953733753372024\n",
            "Test 0.6928478806883425\n",
            "0.6928478806883425\n",
            "Epoch: 1\n",
            "Train:  1.041462996940473\n",
            "Test 0.6926680624266683\n",
            "0.6927479816540791\n",
            "Epoch: 2\n",
            "Train:  1.0410694851106777\n",
            "Test 0.692515105118245\n",
            "0.6926525404508684\n",
            "Epoch: 3\n",
            "Train:  1.0407557976551545\n",
            "Test 0.6923528750300844\n",
            "0.692551027774451\n",
            "Epoch: 4\n",
            "Train:  1.0404075374315074\n",
            "Test 0.6922005048164954\n",
            "0.692446755119181\n",
            "Epoch: 5\n",
            "Train:  1.0400662756228185\n",
            "Test 0.6920458827263269\n",
            "0.6923380964126438\n",
            "Epoch: 6\n",
            "Train:  1.0397552473422809\n",
            "Test 0.6918787244475368\n",
            "0.692221841623204\n",
            "Epoch: 7\n",
            "Train:  1.0393951465358664\n",
            "Test 0.6917014694039202\n",
            "0.6920967863933084\n",
            "Epoch: 8\n",
            "Train:  1.039016992836208\n",
            "Test 0.6915102996232309\n",
            "0.6919613050398447\n",
            "Epoch: 9\n",
            "Train:  1.0386287286168052\n",
            "Test 0.6913085562405569\n",
            "0.6918150514167885\n",
            "Epoch: 10\n",
            "Train:  1.0382050285627553\n",
            "Test 0.6910952491201324\n",
            "0.6916575627871844\n",
            "Epoch: 11\n",
            "Train:  1.0377857276808211\n",
            "Test 0.6908736783506233\n",
            "0.6914892172850549\n",
            "Epoch: 12\n",
            "Train:  1.0373340856024633\n",
            "Test 0.6906291117598286\n",
            "0.6913071890732356\n",
            "Epoch: 13\n",
            "Train:  1.036864012479782\n",
            "Test 0.6903516490817506\n",
            "0.6911072893940735\n",
            "Epoch: 14\n",
            "Train:  1.03639737088165\n",
            "Test 0.6900764570568071\n",
            "0.6908936045599051\n",
            "Epoch: 15\n",
            "Train:  1.0358053872655162\n",
            "Test 0.6897558628857791\n",
            "0.6906594658050221\n",
            "Epoch: 16\n",
            "Train:  1.0351805062521071\n",
            "Test 0.6894076848641421\n",
            "0.6904033422265841\n",
            "Epoch: 17\n",
            "Train:  1.0345398357936315\n",
            "Test 0.6890503753235925\n",
            "0.6901277848455108\n",
            "Epoch: 18\n",
            "Train:  1.0338611668282813\n",
            "Test 0.6886255627586728\n",
            "0.6898229472554812\n",
            "Epoch: 19\n",
            "Train:  1.0330811411469847\n",
            "Test 0.6881603238346813\n",
            "0.6894865441070812\n",
            "Epoch: 20\n",
            "Train:  1.0322713618313437\n",
            "Test 0.6876287416660742\n",
            "0.6891115246751379\n",
            "Epoch: 21\n",
            "Train:  1.03145469108344\n",
            "Test 0.6870991436989753\n",
            "0.6887060566539788\n",
            "Epoch: 22\n",
            "Train:  1.0304710797337822\n",
            "Test 0.6864958215545822\n",
            "0.688261384754507\n",
            "Epoch: 23\n",
            "Train:  1.0295726735513289\n",
            "Test 0.6858792767856584\n",
            "0.6877827026484035\n",
            "Epoch: 24\n",
            "Train:  1.0285858380925523\n",
            "Test 0.6852481033339168\n",
            "0.6872738604339712\n",
            "Epoch: 25\n",
            "Train:  1.0275701179609193\n",
            "Test 0.6845899324714045\n",
            "0.6867354475884815\n",
            "Epoch: 26\n",
            "Train:  1.0264078980182116\n",
            "Test 0.6838349261126675\n",
            "0.6861539372876847\n",
            "Epoch: 27\n",
            "Train:  1.0251650113762516\n",
            "Test 0.6830117414285849\n",
            "0.6855242801818924\n",
            "Epoch: 28\n",
            "Train:  1.0238494174384372\n",
            "Test 0.6822172222119984\n",
            "0.6848618435168247\n",
            "Epoch: 29\n",
            "Train:  1.0224253584395397\n",
            "Test 0.6813676798299992\n",
            "0.6841621445941476\n",
            "Epoch: 30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-10-15 12:37:20,527]\u001b[0m Trial 27 finished with value: 0.6827303680776506 and parameters: {'layer_size1': 512, 'layer_size2': 384, 'layer_size3': 384, 'layer_size4': 64, 'layer_size5': 192, 'learning_rate': 2.457514151953452e-06, 'b1': 0.9628076655342157}. Best is trial 3 with value: 0.12057808925100155.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:  1.021026922669603\n",
            "Test 0.6803910688602881\n",
            "0.6834071817684076\n",
            "Epoch: 0\n",
            "Train:  0.6913126615377573\n",
            "Test 0.6887525634451227\n",
            "0.6887525634451226\n",
            "Epoch: 1\n",
            "Train:  1.0187225289397188\n",
            "Test 0.6441585463045281\n",
            "0.6639781094781259\n",
            "Epoch: 2\n",
            "Train:  0.8445633632359487\n",
            "Test 0.28946695550457463\n",
            "0.510489931620113\n",
            "Epoch: 3\n",
            "Train:  0.37580558974227624\n",
            "Test 0.17015135626653174\n",
            "0.3951990863106342\n",
            "Epoch: 4\n",
            "Train:  0.2787186721196541\n",
            "Test 0.17645683906453868\n",
            "0.3301282131412817\n",
            "Epoch: 5\n",
            "Train:  0.27423165029003505\n",
            "Test 0.14795876444477737\n",
            "0.28075016411911363\n",
            "Epoch: 6\n",
            "Train:  0.23478011908384908\n",
            "Test 0.1481060723436403\n",
            "0.24718148311310836\n",
            "Epoch: 7\n",
            "Train:  0.23091991571197798\n",
            "Test 0.1418890518583221\n",
            "0.22187773185797463\n",
            "Epoch: 8\n",
            "Train:  0.2153623287494366\n",
            "Test 0.1411895997917805\n",
            "0.20323837305479645\n",
            "Epoch: 9\n",
            "Train:  0.24472613354646788\n",
            "Test 0.13570253338132585\n",
            "0.18810642451782628\n",
            "Epoch: 10\n",
            "Train:  0.19554528265836693\n",
            "Test 0.13145851466681932\n",
            "0.17571218552496165\n",
            "Epoch: 11\n",
            "Train:  0.18911591761032523\n",
            "Test 0.14106034422839137\n",
            "0.16827042325657\n",
            "Epoch: 12\n",
            "Train:  0.18915100997883566\n",
            "Test 0.13769081033955605\n",
            "0.16179871473459265\n",
            "Epoch: 13\n",
            "Train:  0.18680993496374682\n",
            "Test 0.12516352989379959\n",
            "0.15413460673181043\n",
            "Epoch: 14\n",
            "Train:  0.16751846373968182\n",
            "Test 0.12558697485416145\n",
            "0.14821686845067275\n",
            "Epoch: 15\n",
            "Train:  0.1597976807347966\n",
            "Test 0.13112989304785108\n",
            "0.14470049629298945\n",
            "Epoch: 16\n",
            "Train:  0.14646815266733096\n",
            "Test 0.13189535894991503\n",
            "0.14208047110200547\n",
            "Epoch: 17\n",
            "Train:  0.1546771269179275\n",
            "Test 0.14973318230892932\n",
            "0.14363909094231844\n",
            "Epoch: 18\n",
            "Train:  0.14542248609370037\n",
            "Test 0.12811096027773214\n",
            "0.1404880535751204\n",
            "Epoch: 19\n",
            "Train:  0.1425736775773581\n",
            "Test 0.1402603127812837\n",
            "0.14044197415683038\n",
            "Epoch: 20\n",
            "Train:  0.12809105086798742\n",
            "Test 0.12351091959319271\n",
            "0.13702424021241047\n",
            "Epoch: 21\n",
            "Train:  0.11049544764853222\n",
            "Test 0.15790715446907194\n",
            "0.14123186989087702\n",
            "Epoch: 22\n",
            "Train:  0.13039587057560628\n",
            "Test 0.14930932621570517\n",
            "0.14285695395901166\n",
            "Epoch: 23\n",
            "Train:  0.12067727531321797\n",
            "Test 0.1332206482361088\n",
            "0.14092054839771118\n",
            "Epoch: 24\n",
            "Train:  0.09921547093073882\n",
            "Test 0.13173711731102003\n",
            "0.13907689706255597\n",
            "Epoch: 25\n",
            "Train:  0.0917605688972842\n",
            "Test 0.21412618649311554\n",
            "0.15413225698199337\n",
            "Epoch: 26\n",
            "Train:  0.13804009071407983\n",
            "Test 0.14378729795409373\n",
            "0.1520582505365295\n",
            "Epoch: 27\n",
            "Train:  0.09503083596357415\n",
            "Test 0.15790647474516714\n",
            "0.1532301621850574\n",
            "Epoch: 28\n",
            "Train:  0.09611730853269101\n",
            "Test 0.14430773997931587\n",
            "0.1514429121083714\n",
            "Epoch: 29\n",
            "Train:  0.0825520407486246\n",
            "Test 0.1472454527802356\n",
            "0.15060237971403898\n",
            "Epoch: 30\n",
            "Train:  0.08349942364930363\n",
            "Test 0.16195174346544913\n",
            "0.15287450266590205\n",
            "Epoch: 31\n",
            "Train:  0.09079505148771877\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-10-15 12:37:43,998]\u001b[0m Trial 28 finished with value: 0.17100321042909944 and parameters: {'layer_size1': 256, 'layer_size2': 256, 'layer_size3': 512, 'layer_size4': 192, 'layer_size5': 256, 'learning_rate': 8.850407146076767e-05, 'b1': 0.9522436758621542}. Best is trial 3 with value: 0.12057808925100155.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test 0.24412363977896412\n",
            "0.171138800556129\n",
            "Epoch: 0\n",
            "Train:  0.6694128476219736\n",
            "Test 0.6094488102001149\n",
            "0.6094488102001149\n",
            "Epoch: 1\n",
            "Train:  0.6439275259882102\n",
            "Test 0.1548087002757268\n",
            "0.35687097135323265\n",
            "Epoch: 2\n",
            "Train:  0.2934605360454146\n",
            "Test 0.171632180584001\n",
            "0.28095343415272783\n",
            "Epoch: 3\n",
            "Train:  0.24928815291866988\n",
            "Test 0.15355090605906951\n",
            "0.23779539618062134\n",
            "Epoch: 4\n",
            "Train:  0.22604855878667518\n",
            "Test 0.19224533012935094\n",
            "0.22424528133909635\n",
            "Epoch: 5\n",
            "Train:  0.23520852679953033\n",
            "Test 0.20555910631850527\n",
            "0.21918028897728292\n",
            "Epoch: 6\n",
            "Train:  0.23739874608569092\n",
            "Test 0.13668997862782234\n",
            "0.19830419206906438\n",
            "Epoch: 7\n",
            "Train:  0.19382809904564322\n",
            "Test 0.13473878794046112\n",
            "0.18302823010927144\n",
            "Epoch: 8\n",
            "Train:  0.19437497610656115\n",
            "Test 0.1343171643332029\n",
            "0.17177573225815618\n",
            "Epoch: 9\n",
            "Train:  0.17470418341839924\n",
            "Test 0.14162038779739058\n",
            "0.16501918458360107\n",
            "Epoch: 10\n",
            "Train:  0.15295888573586286\n",
            "Test 0.13994789683352132\n",
            "0.15953373007961916\n",
            "Epoch: 11\n",
            "Train:  0.15278476649458647\n",
            "Test 0.13005002131242127\n",
            "0.15320186593542728\n",
            "Epoch: 12\n",
            "Train:  0.13264850639796136\n",
            "Test 0.14517680956767157\n",
            "0.1515034851931499\n",
            "Epoch: 13\n",
            "Train:  0.1260240710111874\n",
            "Test 0.16757062006564366\n",
            "0.15486474179641796\n",
            "Epoch: 14\n",
            "Train:  0.13645899270903386\n",
            "Test 0.14388541959144258\n",
            "0.1525887997641054\n",
            "Epoch: 15\n",
            "Train:  0.12207295094026532\n",
            "Test 0.22124465662754061\n",
            "0.16671766328998183\n",
            "Epoch: 16\n",
            "Train:  0.15849692619409098\n",
            "Test 0.1411513762869241\n",
            "0.16148661311119047\n",
            "Epoch: 17\n",
            "Train:  0.0910720974803926\n",
            "Test 0.16007373674564582\n",
            "0.16119885403134246\n",
            "Epoch: 18\n",
            "Train:  0.09244660612437942\n",
            "Test 0.17495962964448564\n",
            "0.16399125184761862\n",
            "Epoch: 19\n",
            "Train:  0.10515472169748506\n",
            "Test 0.17393488436127116\n",
            "0.16600317423622335\n",
            "Epoch: 20\n",
            "Train:  0.09805092814949003\n",
            "Test 0.20387028696339776\n",
            "0.17364709954863655\n",
            "Epoch: 21\n",
            "Train:  0.1083011636427604\n",
            "Test 0.2350076930155187\n",
            "0.18601044361960192\n",
            "Epoch: 22\n",
            "Train:  0.1405645461318797\n",
            "Test 0.23197438468351445\n",
            "0.1952578187000525\n",
            "Epoch: 23\n",
            "Train:  0.14565877348460018\n",
            "Test 0.18295684784417252\n",
            "0.19278595146589983\n",
            "Epoch: 24\n",
            "Train:  0.10114140540010519\n",
            "Test 0.1983012274528543\n",
            "0.19389318969103708\n",
            "Epoch: 25\n",
            "Train:  0.10144984224803094\n",
            "Test 0.24329528580982607\n",
            "0.20380356117471635\n",
            "Epoch: 26\n",
            "Train:  0.12264644365087995\n",
            "Test 0.2322584980887262\n",
            "0.20950834187087597\n",
            "Epoch: 27\n",
            "Train:  0.11640761816301957\n",
            "Test 0.2424064776331413\n",
            "0.21610072053818274\n",
            "Epoch: 28\n",
            "Train:  0.12138761863267712\n",
            "Test 0.250393374205565\n",
            "0.2229698807822873\n",
            "Epoch: 29\n",
            "Train:  0.12533862258955028\n",
            "Test 0.2555884169244567\n",
            "0.22950167397904778\n",
            "Epoch: 30\n",
            "Train:  0.12790434853799784\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-10-15 12:38:08,464]\u001b[0m Trial 29 finished with value: 0.23580519559443047 and parameters: {'layer_size1': 512, 'layer_size2': 256, 'layer_size3': 256, 'layer_size4': 64, 'layer_size5': 128, 'learning_rate': 0.0002522877443320814, 'b1': 0.9241513045517684}. Best is trial 3 with value: 0.12057808925100155.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test 0.262155719301168\n",
            "0.2360389572552444\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "study = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.TPESampler(),pruner=optuna.pruners.HyperbandPruner())\n",
        "study.optimize(objective, n_trials=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C57DthBtjHEL"
      },
      "outputs": [],
      "source": [
        "best_trial = study.best_trial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B41PbOc5zuNx",
        "outputId": "90cf63b3-8202-42fa-c1d8-5e7c9fa98223"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'layer_size1': 384, 'layer_size2': 256, 'layer_size3': 512, 'layer_size4': 64, 'layer_size5': 192, 'learning_rate': 1.713644852336342e-05, 'b1': 0.9308401877808863}\n"
          ]
        }
      ],
      "source": [
        "print(best_trial.params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmV1JcJfzxaO"
      },
      "outputs": [],
      "source": [
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OO2amQeZCelb"
      },
      "outputs": [],
      "source": [
        "with open('mydata.json', 'w') as f:\n",
        "    json.dump(best_trial.params, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training the Best Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zLI48yyCjmm",
        "outputId": "86c66e34-b7b6-4dc0-e25b-b8a4d9646553"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Train:  0.6929760463945158\n",
            "Test 0.694690180348826\n",
            "0.694690180348826\n",
            "Epoch: 1\n",
            "Train:  1.0394450098603636\n",
            "Test 0.6933273186177125\n",
            "0.6939330349426519\n",
            "Epoch: 2\n",
            "Train:  1.0374248870563159\n",
            "Test 0.6918217061640142\n",
            "0.6930677362628824\n",
            "Epoch: 3\n",
            "Train:  1.0343252289426195\n",
            "Test 0.6882151238647572\n",
            "0.6914238973746286\n",
            "Epoch: 4\n",
            "Train:  1.0275692784742558\n",
            "Test 0.6811952276544256\n",
            "0.6883810993855154\n",
            "Epoch: 5\n",
            "Train:  1.0133882542669554\n",
            "Test 0.6654556358690227\n",
            "0.6821670241414319\n",
            "Epoch: 6\n",
            "Train:  0.9830402219906832\n",
            "Test 0.6342650241467542\n",
            "0.6700443058518538\n",
            "Epoch: 7\n",
            "Train:  0.9238604623756129\n",
            "Test 0.5714193637117798\n",
            "0.6463428776131461\n",
            "Epoch: 8\n",
            "Train:  0.8145829250306\n",
            "Test 0.4678690219536806\n",
            "0.6051145315424459\n",
            "Epoch: 9\n",
            "Train:  0.6572714699056995\n",
            "Test 0.3601686101365875\n",
            "0.5502324260563098\n",
            "Epoch: 10\n",
            "Train:  0.5101345567094101\n",
            "Test 0.2765192502475047\n",
            "0.49034554716893286\n",
            "Epoch: 11\n",
            "Train:  0.40514286563837487\n",
            "Test 0.22872637850897654\n",
            "0.4341607216250635\n",
            "Epoch: 12\n",
            "Train:  0.3479664443067579\n",
            "Test 0.19966006498688307\n",
            "0.38453223541455883\n",
            "Epoch: 13\n",
            "Train:  0.3134904718947607\n",
            "Test 0.18052199421511902\n",
            "0.3418531407403825\n",
            "Epoch: 14\n",
            "Train:  0.28813058243648254\n",
            "Test 0.1700047536347157\n",
            "0.3062300885977219\n",
            "Epoch: 15\n",
            "Train:  0.27855653245506923\n",
            "Test 0.16277980553361523\n",
            "0.2767090897382562\n",
            "Epoch: 16\n",
            "Train:  0.2679148066393185\n",
            "Test 0.15984287709270642\n",
            "0.2527974039122676\n",
            "Epoch: 17\n",
            "Train:  0.2597488182027152\n",
            "Test 0.15832148364066204\n",
            "0.23355559015691235\n",
            "Epoch: 18\n",
            "Train:  0.2645869294229226\n",
            "Test 0.15443733372749427\n",
            "0.21750056152392816\n",
            "Epoch: 19\n",
            "Train:  0.2527908458214103\n",
            "Test 0.15183816418979632\n",
            "0.20421490891110114\n",
            "Epoch: 20\n",
            "Train:  0.24900944732921027\n",
            "Test 0.1525972476263186\n",
            "0.19379527247076664\n",
            "Epoch: 21\n",
            "Train:  0.24750666249366032\n",
            "Test 0.16502664658503655\n",
            "0.18799877670404744\n",
            "Epoch: 22\n",
            "Train:  0.2539037754247477\n",
            "Test 0.15632693273025555\n",
            "0.1816267943645019\n",
            "Epoch: 23\n",
            "Train:  0.24283443612384273\n",
            "Test 0.1479680877922601\n",
            "0.17486311246535222\n",
            "Epoch: 24\n",
            "Train:  0.2495586700283755\n",
            "Test 0.1499804865855437\n",
            "0.16986771521214478\n",
            "Epoch: 25\n",
            "Train:  0.23732336846627158\n",
            "Test 0.15263753696157165\n",
            "0.1664112329855081\n",
            "Epoch: 26\n",
            "Train:  0.23488135566600624\n",
            "Test 0.14407639193174604\n",
            "0.1619334381311269\n",
            "Epoch: 27\n",
            "Train:  0.23118322175473738\n",
            "Test 0.144048504340343\n",
            "0.15834951906529954\n",
            "Epoch: 28\n",
            "Train:  0.22793622527803695\n",
            "Test 0.14355328222634373\n",
            "0.15538568538703323\n",
            "Epoch: 29\n",
            "Train:  0.22562353806604288\n",
            "Test 0.142013906450062\n",
            "0.15270801480401225\n",
            "Epoch: 30\n",
            "Train:  0.2241948039540441\n",
            "Test 0.14080631690638842\n",
            "0.15032531551340475\n",
            "Epoch: 31\n",
            "Train:  0.22065310684397763\n",
            "Test 0.1436524242026247\n",
            "0.14898967905102173\n",
            "Epoch: 32\n",
            "Train:  0.22128682522846885\n",
            "Test 0.13857057223935704\n",
            "0.14690453607231452\n",
            "Epoch: 33\n",
            "Train:  0.21545266713469458\n",
            "Test 0.13780393383905784\n",
            "0.14508349224674377\n",
            "Epoch: 34\n",
            "Train:  0.21196893678002415\n",
            "Test 0.14767854446169984\n",
            "0.14560271331082092\n",
            "Epoch: 35\n",
            "Train:  0.21652423689182806\n",
            "Test 0.13700041181711486\n",
            "0.1438816945095475\n",
            "Epoch: 36\n",
            "Train:  0.20906017369321195\n",
            "Test 0.13542863737532507\n",
            "0.1421906440609064\n",
            "Epoch: 37\n",
            "Train:  0.20542943199257274\n",
            "Test 0.13452679074400073\n",
            "0.14065755498738206\n",
            "Epoch: 38\n",
            "Train:  0.20221970302663445\n",
            "Test 0.13327951330841678\n",
            "0.13918170143335631\n",
            "Epoch: 39\n",
            "Train:  0.20120558797658145\n",
            "Test 0.1320302641026048\n",
            "0.13775122382411742\n",
            "Epoch: 40\n",
            "Train:  0.19697548715813912\n",
            "Test 0.13240043735370421\n",
            "0.13668095271928954\n",
            "Epoch: 41\n",
            "Train:  0.19474394660913846\n",
            "Test 0.13081832953315953\n",
            "0.13550832832621254\n",
            "Epoch: 42\n",
            "Train:  0.19170217330639178\n",
            "Test 0.13038104854442262\n",
            "0.13448280257618866\n",
            "Epoch: 43\n",
            "Train:  0.1918783991038117\n",
            "Test 0.14376871228463703\n",
            "0.13634008563798655\n",
            "Epoch: 44\n",
            "Train:  0.19759059805191043\n",
            "Test 0.13925717349399577\n",
            "0.13692352862171442\n",
            "Epoch: 45\n",
            "Train:  0.19477813656786422\n",
            "Test 0.12752598444948265\n",
            "0.13504395429366153\n",
            "Epoch: 46\n",
            "Train:  0.18231957347128855\n",
            "Test 0.12849365935862173\n",
            "0.13373385878652097\n",
            "Epoch: 47\n",
            "Train:  0.19005767680233815\n",
            "Test 0.1262518109637739\n",
            "0.13223741585017892\n",
            "Epoch: 48\n",
            "Train:  0.17956900476536033\n",
            "Test 0.12641285595930976\n",
            "0.13107248308891012\n",
            "Epoch: 49\n",
            "Train:  0.17741308184579396\n",
            "Test 0.12939306112149587\n",
            "0.13073659390145662\n",
            "Epoch: 50\n",
            "Train:  0.18582234994743715\n",
            "Test 0.12893199101909175\n",
            "0.1303756692039521\n",
            "Epoch: 51\n",
            "Train:  0.18414974869007156\n",
            "Test 0.12475219402707867\n",
            "0.12925096389508584\n",
            "Epoch: 52\n",
            "Train:  0.17075627229445967\n",
            "Test 0.12579796418220132\n",
            "0.1285603589059073\n",
            "Epoch: 53\n",
            "Train:  0.17458327770260446\n",
            "Test 0.12587362318384998\n",
            "0.12802300862014254\n",
            "Epoch: 54\n",
            "Train:  0.17140785245490925\n",
            "Test 0.12243128363759471\n",
            "0.1269046583933268\n",
            "Epoch: 55\n",
            "Train:  0.165704906756918\n",
            "Test 0.12495250874386603\n",
            "0.12651422700265738\n",
            "Epoch: 56\n",
            "Train:  0.16434379233108773\n",
            "Test 0.12192949319715465\n",
            "0.1255972774969845\n",
            "Epoch: 57\n",
            "Train:  0.16421681432387766\n",
            "Test 0.12169492573583082\n",
            "0.12481680527589409\n",
            "Epoch: 58\n",
            "Train:  0.16803809858503796\n",
            "Test 0.120689420138687\n",
            "0.1239913266671498\n",
            "Epoch: 59\n",
            "Train:  0.15875948239254317\n",
            "Test 0.1240849180467727\n",
            "0.1240100449717601\n",
            "Epoch: 60\n",
            "Train:  0.16576175102042956\n",
            "Test 0.12104933911204448\n",
            "0.12341790307385311\n",
            "Epoch: 61\n",
            "Train:  0.15922079150199944\n",
            "Test 0.12021207022258923\n",
            "0.12277673587474539\n",
            "Epoch: 62\n",
            "Train:  0.1528233478925508\n",
            "Test 0.12159568663590993\n",
            "0.12254052584163899\n",
            "Epoch: 63\n",
            "Train:  0.15427776391962508\n",
            "Test 0.12023123673030309\n",
            "0.12207866772945876\n",
            "Epoch: 64\n",
            "Train:  0.1492470199098954\n",
            "Test 0.11963629867240186\n",
            "0.12159019367275127\n",
            "Epoch: 65\n",
            "Train:  0.14699246335924762\n",
            "Test 0.11922567755993688\n",
            "0.12111729026020678\n",
            "Epoch: 66\n",
            "Train:  0.1452084592903449\n",
            "Test 0.1192867779633501\n",
            "0.12075118768317461\n",
            "Epoch: 67\n",
            "Train:  0.1433051380195788\n",
            "Test 0.1190610063217935\n",
            "0.12041315132398582\n",
            "Epoch: 68\n",
            "Train:  0.14115830686884923\n",
            "Test 0.11875177837990142\n",
            "0.120080876666824\n",
            "Epoch: 69\n",
            "Train:  0.1402221569354772\n",
            "Test 0.11848022509195702\n",
            "0.11976074629917301\n",
            "Epoch: 70\n",
            "Train:  0.1386508387573159\n",
            "Test 0.11772434125507708\n",
            "0.1193534652367392\n",
            "Epoch: 71\n",
            "Train:  0.1363611912402587\n",
            "Test 0.11984187069830003\n",
            "0.1194511463393384\n",
            "0.11945113375966443\n"
          ]
        }
      ],
      "source": [
        "model = Net(768,[384,256,512,64,192],1).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=1.713644852336342e-05,betas=(0.9308401877808863,0.99))\n",
        "lossff = torch.nn.BCELoss()\n",
        "\n",
        "total_loss = 0\n",
        "weighted_loss = 0\n",
        "exp_param = 0.8\n",
        "\n",
        "wloss = []\n",
        "\n",
        "for i in range(800):\n",
        "  print(\"Epoch:\", i)\n",
        "  model.train()\n",
        "  for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data.x, data.edge_index, data.batch)\n",
        "        loss = lossff(torch.reshape(out,(-1,)), data.y.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += float(loss) * data.num_graphs\n",
        "  print(\"Train: \",total_loss / len(train_loader.dataset))\n",
        "\n",
        "  model.eval()\n",
        "  total_loss = 0\n",
        "  for data in val_loader:\n",
        "        data = data.to(device)\n",
        "        out = model(data.x, data.edge_index, data.batch)\n",
        "        loss = lossff(torch.reshape(out,(-1,)), data.y.float())\n",
        "        total_loss += float(loss) * data.num_graphs\n",
        "        \n",
        "  print(\"Test\", total_loss / len(val_loader.dataset))\n",
        "\n",
        "  weighted_loss = exp_param*(weighted_loss) + (1-exp_param)*(total_loss/ len(val_loader.dataset))\n",
        "  print(weighted_loss/(1-exp_param**(i+1)))\n",
        "  wloss.append(weighted_loss/(1-exp_param**(i+1)))\n",
        "\n",
        "  if(i-30>=0 and wloss[i-20]-weighted_loss<0.01):\n",
        "    break\n",
        "\n",
        "print(weighted_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5X38sF4P4RS"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jH_tF9pOOUv"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def val(model):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    for data in val_loader:\n",
        "        data = data.to(device)\n",
        "        out = model(data.x, data.edge_index, data.batch)\n",
        "        # print(out)\n",
        "        loss = lossff(torch.reshape(out,(-1,)), data.y.float())\n",
        "        # print(loss)\n",
        "        total_loss += float(loss) * data.num_graphs\n",
        "        all_preds.append(torch.reshape(out, (-1,)))\n",
        "        all_labels.append(data.y.float())\n",
        "    # print(all_preds)\n",
        "    accuracy, f1 = metrics(all_preds, all_labels)\n",
        "    return total_loss / len(val_loader.dataset), accuracy, f1\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(model):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    for data in test_loader:\n",
        "        data = data.to(device)\n",
        "        out = model(data.x, data.edge_index, data.batch)\n",
        "        # print(out)\n",
        "        loss = lossff(torch.reshape(out,(-1,)), data.y.float())\n",
        "        # print(loss)\n",
        "        total_loss += float(loss) * data.num_graphs\n",
        "        all_preds.append(torch.reshape(out, (-1,)))\n",
        "        all_labels.append(data.y.float())\n",
        "    # print(all_preds)\n",
        "    accuracy, f1 = metrics(all_preds, all_labels)\n",
        "    return total_loss / len(test_loader.dataset), accuracy, f1\n",
        "\n",
        "\n",
        "def metrics(preds, gts):\n",
        "    preds = torch.round(torch.cat(preds))\n",
        "    gts = torch.cat(gts)\n",
        "    acc = accuracy_score(preds.cpu().numpy(), gts.cpu().numpy())\n",
        "    f1 = f1_score(preds.cpu().numpy(), gts.cpu().numpy())\n",
        "    return acc, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wukGqhqYP7xx",
        "outputId": "20235a77-1e9e-4387-d2ee-d3f26fd82fc8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((0.11984186966122289, 0.9615384615384616, 0.9632224168126094),\n",
              " (0.07417334500195343, 0.9826007326007326, 0.9822926374650514))"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val(model),test(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_K_EyzVrss4T"
      },
      "outputs": [],
      "source": [
        "final = DataLoader(train_data_gos+val_data_gos, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0gxhFdgQR_B",
        "outputId": "19c2e9a3-ca9a-423f-9e7c-9dbba32e9169"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Train:  0.693460147168319\n",
            "Epoch: 1\n",
            "Train:  0.691132366002261\n",
            "Epoch: 2\n",
            "Train:  0.685896981548477\n",
            "Epoch: 3\n",
            "Train:  0.6707335383027464\n",
            "Epoch: 4\n",
            "Train:  0.6309554183876122\n",
            "Epoch: 5\n",
            "Train:  0.5413306132777707\n",
            "Epoch: 6\n",
            "Train:  0.42419510654040743\n",
            "Epoch: 7\n",
            "Train:  0.3464714191189907\n",
            "Epoch: 8\n",
            "Train:  0.30392695237428713\n",
            "Epoch: 9\n",
            "Train:  0.27378853857153357\n",
            "Epoch: 10\n",
            "Train:  0.2462554309921969\n",
            "Epoch: 11\n",
            "Train:  0.2232214086603769\n",
            "Epoch: 12\n",
            "Train:  0.20418780991154858\n",
            "Epoch: 13\n",
            "Train:  0.18930831100332285\n",
            "Epoch: 14\n",
            "Train:  0.17810733654560187\n",
            "Epoch: 15\n",
            "Train:  0.17367749998712131\n",
            "Epoch: 16\n",
            "Train:  0.16784529633574433\n",
            "Epoch: 17\n",
            "Train:  0.16600180734790435\n",
            "Epoch: 18\n",
            "Train:  0.16978635965540587\n",
            "Epoch: 19\n",
            "Train:  0.15758961883984207\n",
            "Epoch: 20\n",
            "Train:  0.15486823184750018\n",
            "Epoch: 21\n",
            "Train:  0.15495840323604507\n",
            "Epoch: 22\n",
            "Train:  0.1526205661969307\n",
            "Epoch: 23\n",
            "Train:  0.14916721507633998\n",
            "Epoch: 24\n",
            "Train:  0.14761962139039722\n",
            "Epoch: 25\n",
            "Train:  0.14419375558330316\n",
            "Epoch: 26\n",
            "Train:  0.1421095972155222\n",
            "Epoch: 27\n",
            "Train:  0.1434364406544356\n",
            "Epoch: 28\n",
            "Train:  0.13760364601463626\n",
            "Epoch: 29\n",
            "Train:  0.13406810075526782\n",
            "Epoch: 30\n",
            "Train:  0.13287390854041364\n",
            "Epoch: 31\n",
            "Train:  0.13527083395092188\n",
            "Epoch: 32\n",
            "Train:  0.12848853483177514\n",
            "Epoch: 33\n",
            "Train:  0.12570299160858942\n",
            "Epoch: 34\n",
            "Train:  0.1280805306811618\n",
            "Epoch: 35\n",
            "Train:  0.12990203736320374\n",
            "Epoch: 36\n",
            "Train:  0.12206194648958096\n",
            "Epoch: 37\n",
            "Train:  0.11915635520430858\n",
            "Epoch: 38\n",
            "Train:  0.11369314082239793\n",
            "Epoch: 39\n",
            "Train:  0.11709599347923846\n",
            "Epoch: 40\n",
            "Train:  0.11332918260637694\n",
            "Epoch: 41\n",
            "Train:  0.11200395283108447\n",
            "Epoch: 42\n",
            "Train:  0.11297503983890762\n",
            "Epoch: 43\n",
            "Train:  0.11078450993449405\n",
            "Epoch: 44\n",
            "Train:  0.10549782985259616\n",
            "Epoch: 45\n",
            "Train:  0.10504597169375536\n",
            "Epoch: 46\n",
            "Train:  0.10431368311159812\n",
            "Epoch: 47\n",
            "Train:  0.10094483224026886\n",
            "Epoch: 48\n",
            "Train:  0.09819758240410988\n",
            "Epoch: 49\n",
            "Train:  0.09620118141174316\n",
            "Epoch: 50\n",
            "Train:  0.09343647083520015\n",
            "Epoch: 51\n",
            "Train:  0.09271828652051378\n",
            "Epoch: 52\n",
            "Train:  0.09111449626412002\n",
            "Epoch: 53\n",
            "Train:  0.08903513489898308\n",
            "Epoch: 54\n",
            "Train:  0.08776825403064599\n",
            "Epoch: 55\n",
            "Train:  0.09478644509964665\n",
            "Epoch: 56\n",
            "Train:  0.08285337556449193\n",
            "Epoch: 57\n",
            "Train:  0.08248756967384882\n",
            "Epoch: 58\n",
            "Train:  0.08159137676073118\n",
            "Epoch: 59\n",
            "Train:  0.08110407697121011\n",
            "Epoch: 60\n",
            "Train:  0.07703207987468685\n",
            "Epoch: 61\n",
            "Train:  0.07364041387570865\n",
            "Epoch: 62\n",
            "Train:  0.07372528991419754\n",
            "Epoch: 63\n",
            "Train:  0.07453594412268008\n",
            "Epoch: 64\n",
            "Train:  0.07664724304744466\n",
            "Epoch: 65\n",
            "Train:  0.07077300883329249\n",
            "Epoch: 66\n",
            "Train:  0.07454063597798202\n",
            "Epoch: 67\n",
            "Train:  0.06628481062727279\n",
            "Epoch: 68\n",
            "Train:  0.06407099134051064\n",
            "Epoch: 69\n",
            "Train:  0.062239323161606096\n"
          ]
        }
      ],
      "source": [
        "model = Net(768,[384,256,512,64,192],1).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=1.713644852336342e-05,betas=(0.9308401877808863,0.99))\n",
        "lossff = torch.nn.BCELoss()\n",
        "\n",
        "total_loss = 0\n",
        "weighted_loss = 0\n",
        "exp_param = 0.8\n",
        "\n",
        "wloss = []\n",
        "\n",
        "for i in range(70):\n",
        "  print(\"Epoch:\", i)\n",
        "  model.train()\n",
        "  total_loss = 0\n",
        "  for data in final:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data.x, data.edge_index, data.batch)\n",
        "        loss = lossff(torch.reshape(out,(-1,)), data.y.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += float(loss) * data.num_graphs\n",
        "  print(\"Train: \",total_loss / len(final.dataset))\n",
        "\n",
        "#   model.eval()\n",
        "#   total_loss = 0\n",
        "#   for data in test_loader:\n",
        "#         data = data.to(device)\n",
        "#         out = model(data.x, data.edge_index, data.batch)\n",
        "#         loss = lossff(torch.reshape(out,(-1,)), data.y.float())\n",
        "#         total_loss += float(loss) * data.num_graphs\n",
        "        \n",
        "#   print(\"Test\", total_loss / len(test_loader.dataset))\n",
        "\n",
        "#   weighted_loss = exp_param*(weighted_loss) + (1-exp_param)*(total_loss/ len(test_loader.dataset))\n",
        "#   print(weighted_loss/(1-exp_param**(i+1)))\n",
        "#   wloss.append(weighted_loss/(1-exp_param**(i+1)))\n",
        "\n",
        "#   # if(i-30>=0 and wloss[i-20]-weighted_loss<0.001):\n",
        "#   #   break\n",
        "\n",
        "# print(weighted_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Best Metrics found after training \n",
        "**Epoch: 114 |  TestLoss: 0.0640709913405106| TestAcc: 0.9862637362637363 | TestF1: 0.9859943977591035**\n",
        "\n",
        "*Note : We choose the best epoch based on lowest Validation Loss.*\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "S0NGBxXcVj4Z"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
