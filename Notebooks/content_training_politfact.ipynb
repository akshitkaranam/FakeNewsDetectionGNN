{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LM9BLE2OzoIk"
      },
      "source": [
        "## Let's install all relevant libraries to construct our GCN!\n",
        "\n",
        "The entire thing will take about 10 minutes. Please be patient!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  \n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}+${CUDA}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}+${CUDA}.html\n",
        "!pip install torch-geometric\n",
        "#!pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLAEO36k0Ckb"
      },
      "source": [
        "Now for our dataset consisting of 314 Politifact(Political News) and 5464 Gossicop(Celebrity News) Graphs. Read more at https://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html#torch_geometric.datasets.UPFD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Q_KobTgtj-BZ"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.datasets import UPFD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBbas_ZN0_JQ"
      },
      "source": [
        "name can be politifact and gossicop depending on which graphs you would like to extract. feature refers to the embedding type- which refers to the features and transformers used to create the node vectors. We use 'content' which is an aggregation of user profiles and user activities on twitter\n",
        "\n",
        "- bert: the 768-dimensional node feature composed of Twitter user historical tweets encoded by the bert-as-service\n",
        "- content: the 310-dimensional node feature composed of a 300-dimensional “spacy” vector plus a 10-dimensional “profile” vector\n",
        "- profile: the 10-dimensional node feature composed of ten Twitter user profile attributes.\n",
        "- spacy: the 300-dimensional node feature composed of Twitter user historical tweets encoded by the spaCy word2vec encoder.\n",
        "\n",
        "Statistics:\n",
        "\n",
        "Politifact:\n",
        "- Graphs: 314\n",
        "- Nodes: 41,054\n",
        "- Edges: 40,740\n",
        "- Classes:\n",
        "    - Fake: 157\n",
        "    - Real: 157\n",
        "- Node feature size:\n",
        "    - bert: 768\n",
        "    - content: 310\n",
        "    - profile: 10\n",
        "    - spacy: 300\n",
        "    \n",
        "Gossipcop:\n",
        "- Graphs: 5,464\n",
        "- Nodes: 314,262\n",
        "- Edges: 308,798\n",
        "- Classes:\n",
        "    - Fake: 2,732\n",
        "    - Real: 2,732\n",
        "- Node feature size:\n",
        "    - bert: 768\n",
        "    - content: 310\n",
        "    - profile: 10\n",
        "    - spacy: 300"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3VsMus-oeyA",
        "outputId": "b732c119-ffc8-4abe-ccb5-2d32240fe052"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gossipcop Dataset\n",
            "Train Samples:  1092\n",
            "Validation Samples:  546\n",
            "Test Samples:  3826\n",
            "Politifact Dataset\n",
            "Train Samples:  93\n",
            "Validation Samples:  31\n",
            "Test Samples:  221\n"
          ]
        }
      ],
      "source": [
        "test_data_gos = UPFD(root=\".\", name=\"gossipcop\", feature=\"content\",split=\"test\")\n",
        "train_data_gos = UPFD(root=\".\", name=\"gossipcop\", feature=\"content\", split=\"train\")\n",
        "val_data_gos = UPFD(root=\".\", name=\"gossipcop\", feature=\"content\", split=\"val\")\n",
        "\n",
        "test_data_pol = UPFD(root=\".\", name=\"politifact\", feature=\"content\",split=\"test\")\n",
        "train_data_pol = UPFD(root=\".\", name=\"politifact\", feature=\"content\", split=\"train\")\n",
        "val_data_pol = UPFD(root=\".\", name=\"politifact\", feature=\"content\", split=\"val\")\n",
        "train_data_pol = train_data_pol + val_data_pol\n",
        "\n",
        "print(\"Gossipcop Dataset\")\n",
        "print(\"Train Samples: \", len(train_data_gos))\n",
        "print(\"Validation Samples: \", len(val_data_gos))\n",
        "print(\"Test Samples: \", len(test_data_gos))\n",
        "\n",
        "print(\"Politifact Dataset\")\n",
        "print(\"Train Samples: \", len(train_data_pol))\n",
        "print(\"Validation Samples: \", len(val_data_pol))\n",
        "print(\"Test Samples: \", len(test_data_pol))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "m08p_57bkebo"
      },
      "outputs": [],
      "source": [
        "# combing all data availbale\n",
        "def combineAllUPFDData(feature):\n",
        "  test_data_gos = UPFD(root=\".\", name=\"gossipcop\", feature=\"content\",split=\"train\")\n",
        "  train_data_gos = UPFD(root=\".\", name=\"gossipcop\", feature=\"content\", split=\"test\")\n",
        "  val_data_gos = UPFD(root=\".\", name=\"gossipcop\", feature=\"content\", split=\"val\")\n",
        "\n",
        "  test_data_pol = UPFD(root=\".\", name=\"politifact\", feature=\"content\",split=\"train\")\n",
        "  train_data_pol = UPFD(root=\".\", name=\"politifact\", feature=\"content\", split=\"test\")\n",
        "  val_data_pol = UPFD(root=\".\", name=\"politifact\", feature=\"content\", split=\"val\")\n",
        "  print(\"Gossipcop Dataset\")\n",
        "  print(\"Train Samples: \", len(train_data_gos))\n",
        "  print(\"Validation Samples: \", len(val_data_gos))\n",
        "  print(\"Test Samples: \", len(test_data_gos))\n",
        "\n",
        "  print(\"Politifact Dataset\")\n",
        "  print(\"Train Samples: \", len(train_data_pol))\n",
        "  print(\"Validation Samples: \", len(val_data_pol))\n",
        "  print(\"Test Samples: \", len(test_data_pol))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWWbaOW71z0E"
      },
      "source": [
        "train is a indexable object with each index refering to a different graph. Each graph has the attribute x, which refers to the node embeddings (node vectors) and edge-index, which specifies the directed edges in the graph as an object containing two lists- the first one specifying the source node index and the other specifying the destination node index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DcPMdUZozNv",
        "outputId": "db36ab9f-2f0c-456c-ea25-9b469da21a85"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  7,\n",
              "          7, 12, 14, 16, 30, 32, 33, 35],\n",
              "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
              "         19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
              "         37, 38, 39, 40, 41, 42, 43, 44]])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data_pol[0].edge_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_z4dvppo1fT",
        "outputId": "a77fdf9b-db44-41eb-9a1f-7798e8e5dd4f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.5780, 0.5658, 0.3858,  ..., 0.5833, 0.1750, 0.3777],\n",
              "        [0.6087, 0.6196, 0.2900,  ..., 0.4122, 0.1538, 0.2703],\n",
              "        [0.5888, 0.5631, 0.2753,  ..., 0.2230, 0.1538, 0.0000],\n",
              "        ...,\n",
              "        [0.5958, 0.5722, 0.4397,  ..., 0.7095, 0.2308, 0.1081],\n",
              "        [0.5987, 0.5378, 0.4844,  ..., 0.6419, 0.0769, 0.0811],\n",
              "        [0.5906, 0.5376, 0.3346,  ..., 0.9324, 0.1538, 0.3784]])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data_pol[0].x # what do you mean by node vectors?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MafoKOINzhJd"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "train_loader = DataLoader(train_data_pol, batch_size=256, shuffle=True)\n",
        "test_loader = DataLoader(test_data_pol, batch_size=256, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VG3L1fy6Ua5X",
        "outputId": "9ba9bfb6-aed0-431a-c0c2-3840a0c1317d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "310"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data_pol.num_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHYdr_JY2qMl"
      },
      "source": [
        "Let's build our model! Remember the architecture given by the paper https://arxiv.org/pdf/1902.06673.pdf Page 6."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "1clhMrboqQR5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import LeakyReLU, Softmax, Linear, SELU,Dropout\n",
        "from torch_geometric.nn import SAGEConv, global_max_pool, GATv2Conv, TopKPooling, global_mean_pool\n",
        "from torch_geometric.transforms import ToUndirected\n",
        "from torch.nn import LeakyReLU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "oBU_JkWBpjjj"
      },
      "outputs": [],
      "source": [
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels[0])\n",
        "        self.conv2 = SAGEConv(hidden_channels[0], hidden_channels[1])\n",
        "        self.conv3 = SAGEConv(hidden_channels[1], hidden_channels[2])\n",
        "        \n",
        "        self.full1 = Linear(hidden_channels[2],hidden_channels[3])\n",
        "        self.full2 = Linear(hidden_channels[3],hidden_channels[4])\n",
        "        self.full3 = Linear(hidden_channels[4],hidden_channels[5])\n",
        "\n",
        "        self.softmax = Linear(hidden_channels[5],out_channels)\n",
        "\n",
        "        #droupouts\n",
        "        self.dp1 = Dropout(0.2)\n",
        "        self.dp2 = Dropout(0.2)\n",
        "        self.dp3 = Dropout(0.2)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        h = self.conv1(x, edge_index).relu()\n",
        "        h = self.conv2(h, edge_index).relu()\n",
        "        h = self.conv3(h, edge_index).relu()\n",
        "\n",
        "        h = global_max_pool(h,batch)\n",
        "\n",
        "        h = self.full1(h).relu()\n",
        "        h = self.dp1(h)\n",
        "        h = self.full2(h).relu()\n",
        "        h = self.dp2(h)\n",
        "        h = self.full3(h).relu()\n",
        "        h = self.dp3(h)\n",
        "        \n",
        "        h = self.softmax(h)\n",
        "\n",
        "        return torch.sigmoid(h)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "YmMxppph-NWK"
      },
      "outputs": [],
      "source": [
        "from torch.autograd import Variable\n",
        "from sklearn.metrics import accuracy_score, f1_score "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EFKDXt0qdK_",
        "outputId": "fc7ceb3c-4466-4808-8b1d-24e46409efa1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = Net(test_data_pol.num_features,[512,512,512,256,256,256],1).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "lossff = torch.nn.BCELoss()\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfZjTdshMx2o",
        "outputId": "06c14dcc-dbfe-4406-ac18-ff2a83c57858"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of Parameters of the model : 1630721\n",
            "Net(\n",
            "  (conv1): SAGEConv(310, 512, aggr=mean)\n",
            "  (conv2): SAGEConv(512, 512, aggr=mean)\n",
            "  (conv3): SAGEConv(512, 512, aggr=mean)\n",
            "  (full1): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (full2): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (full3): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (softmax): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (dp1): Dropout(p=0.2, inplace=False)\n",
            "  (dp2): Dropout(p=0.2, inplace=False)\n",
            "  (dp3): Dropout(p=0.2, inplace=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of Parameters of the model :\",sum([param.nelement() for param in model.parameters()]))\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wE-4i3CyBFk"
      },
      "outputs": [],
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data.x, data.edge_index, data.batch)\n",
        "        # print(out)\n",
        "\n",
        "        loss = lossff(torch.reshape(out,(-1,)), data.y.float())\n",
        "        # print(loss)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += float(loss) * data.num_graphs\n",
        "    return total_loss / len(train_loader.dataset)\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(epoch):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    for data in test_loader:\n",
        "        data = data.to(device)\n",
        "        out = model(data.x, data.edge_index, data.batch)\n",
        "        # print(out)\n",
        "        loss = lossff(torch.reshape(out,(-1,)), data.y.float())\n",
        "        # print(loss)\n",
        "        total_loss += float(loss) * data.num_graphs\n",
        "        all_preds.append(torch.reshape(out, (-1,)))\n",
        "        all_labels.append(data.y.float())\n",
        "    # print(all_preds)\n",
        "    accuracy, f1 = metrics(all_preds, all_labels)\n",
        "    return total_loss / len(test_loader.dataset), accuracy, f1\n",
        "\n",
        "\n",
        "def metrics(preds, gts):\n",
        "    preds = torch.round(torch.cat(preds))\n",
        "    gts = torch.cat(gts)\n",
        "    # print(preds.cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(preds.cpu().numpy(), gts.cpu().numpy())\n",
        "    f1 = f1_score(preds.cpu().numpy(), gts.cpu().numpy())\n",
        "    return acc, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oRomTbeV2aZK",
        "outputId": "10041d06-cb5d-485e-fdc6-f234a03799b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 00 |  TrainLoss: 0.69337 | TestLoss: 0.69332 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 01 |  TrainLoss: 0.69281 | TestLoss: 0.69417 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 02 |  TrainLoss: 0.69244 | TestLoss: 0.69496 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 03 |  TrainLoss: 0.69215 | TestLoss: 0.69570 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 04 |  TrainLoss: 0.69184 | TestLoss: 0.69635 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 05 |  TrainLoss: 0.69155 | TestLoss: 0.69688 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 06 |  TrainLoss: 0.69126 | TestLoss: 0.69733 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 07 |  TrainLoss: 0.69094 | TestLoss: 0.69779 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 08 |  TrainLoss: 0.69061 | TestLoss: 0.69826 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 09 |  TrainLoss: 0.69026 | TestLoss: 0.69865 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 10 |  TrainLoss: 0.68989 | TestLoss: 0.69883 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 11 |  TrainLoss: 0.68947 | TestLoss: 0.69892 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 12 |  TrainLoss: 0.68899 | TestLoss: 0.69929 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 13 |  TrainLoss: 0.68848 | TestLoss: 0.69967 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 14 |  TrainLoss: 0.68792 | TestLoss: 0.69971 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 15 |  TrainLoss: 0.68728 | TestLoss: 0.69954 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 16 |  TrainLoss: 0.68657 | TestLoss: 0.69962 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 17 |  TrainLoss: 0.68577 | TestLoss: 0.69944 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 18 |  TrainLoss: 0.68486 | TestLoss: 0.69910 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 19 |  TrainLoss: 0.68390 | TestLoss: 0.69884 | TestAcc: 0.43548 | TestF1: 0.60\n",
            "Epoch: 20 |  TrainLoss: 0.68278 | TestLoss: 0.69814 | TestAcc: 0.53226 | TestF1: 0.64\n",
            "Epoch: 21 |  TrainLoss: 0.68155 | TestLoss: 0.69832 | TestAcc: 0.54839 | TestF1: 0.65\n",
            "Epoch: 22 |  TrainLoss: 0.68022 | TestLoss: 0.69684 | TestAcc: 0.53226 | TestF1: 0.62\n",
            "Epoch: 23 |  TrainLoss: 0.67878 | TestLoss: 0.69758 | TestAcc: 0.53226 | TestF1: 0.62\n",
            "Epoch: 24 |  TrainLoss: 0.67718 | TestLoss: 0.69565 | TestAcc: 0.53226 | TestF1: 0.60\n",
            "Epoch: 25 |  TrainLoss: 0.67550 | TestLoss: 0.69616 | TestAcc: 0.53226 | TestF1: 0.62\n",
            "Epoch: 26 |  TrainLoss: 0.67365 | TestLoss: 0.69384 | TestAcc: 0.51613 | TestF1: 0.58\n",
            "Epoch: 27 |  TrainLoss: 0.67162 | TestLoss: 0.69450 | TestAcc: 0.54839 | TestF1: 0.62\n",
            "Epoch: 28 |  TrainLoss: 0.66938 | TestLoss: 0.69065 | TestAcc: 0.50000 | TestF1: 0.56\n",
            "Epoch: 29 |  TrainLoss: 0.66700 | TestLoss: 0.69292 | TestAcc: 0.53226 | TestF1: 0.62\n",
            "Epoch: 30 |  TrainLoss: 0.66440 | TestLoss: 0.68651 | TestAcc: 0.50000 | TestF1: 0.56\n",
            "Epoch: 31 |  TrainLoss: 0.66163 | TestLoss: 0.68786 | TestAcc: 0.53226 | TestF1: 0.60\n",
            "Epoch: 32 |  TrainLoss: 0.65815 | TestLoss: 0.68596 | TestAcc: 0.54839 | TestF1: 0.62\n",
            "Epoch: 33 |  TrainLoss: 0.65474 | TestLoss: 0.67886 | TestAcc: 0.53226 | TestF1: 0.58\n",
            "Epoch: 34 |  TrainLoss: 0.65145 | TestLoss: 0.68396 | TestAcc: 0.53226 | TestF1: 0.62\n",
            "Epoch: 35 |  TrainLoss: 0.64775 | TestLoss: 0.67231 | TestAcc: 0.56452 | TestF1: 0.61\n",
            "Epoch: 36 |  TrainLoss: 0.64347 | TestLoss: 0.67352 | TestAcc: 0.56452 | TestF1: 0.63\n",
            "Epoch: 37 |  TrainLoss: 0.63812 | TestLoss: 0.67277 | TestAcc: 0.54839 | TestF1: 0.63\n",
            "Epoch: 38 |  TrainLoss: 0.63365 | TestLoss: 0.65867 | TestAcc: 0.64516 | TestF1: 0.66\n",
            "Epoch: 39 |  TrainLoss: 0.63013 | TestLoss: 0.66765 | TestAcc: 0.56452 | TestF1: 0.64\n",
            "Epoch: 40 |  TrainLoss: 0.62380 | TestLoss: 0.65406 | TestAcc: 0.64516 | TestF1: 0.68\n",
            "Epoch: 41 |  TrainLoss: 0.61661 | TestLoss: 0.64692 | TestAcc: 0.67742 | TestF1: 0.70\n",
            "Epoch: 42 |  TrainLoss: 0.61057 | TestLoss: 0.65489 | TestAcc: 0.61290 | TestF1: 0.68\n",
            "Epoch: 43 |  TrainLoss: 0.60564 | TestLoss: 0.63017 | TestAcc: 0.75806 | TestF1: 0.75\n",
            "Epoch: 44 |  TrainLoss: 0.60066 | TestLoss: 0.63897 | TestAcc: 0.62903 | TestF1: 0.68\n",
            "Epoch: 45 |  TrainLoss: 0.59006 | TestLoss: 0.62880 | TestAcc: 0.64516 | TestF1: 0.69\n",
            "Epoch: 46 |  TrainLoss: 0.58157 | TestLoss: 0.60968 | TestAcc: 0.75806 | TestF1: 0.75\n",
            "Epoch: 47 |  TrainLoss: 0.57699 | TestLoss: 0.62915 | TestAcc: 0.66129 | TestF1: 0.71\n",
            "Epoch: 48 |  TrainLoss: 0.57013 | TestLoss: 0.59448 | TestAcc: 0.75806 | TestF1: 0.75\n",
            "Epoch: 49 |  TrainLoss: 0.55903 | TestLoss: 0.59295 | TestAcc: 0.70968 | TestF1: 0.72\n",
            "Epoch: 50 |  TrainLoss: 0.54715 | TestLoss: 0.59990 | TestAcc: 0.67742 | TestF1: 0.72\n",
            "Epoch: 51 |  TrainLoss: 0.54139 | TestLoss: 0.56478 | TestAcc: 0.79032 | TestF1: 0.75\n",
            "Epoch: 52 |  TrainLoss: 0.53883 | TestLoss: 0.58551 | TestAcc: 0.72581 | TestF1: 0.75\n",
            "Epoch: 53 |  TrainLoss: 0.52391 | TestLoss: 0.55421 | TestAcc: 0.74194 | TestF1: 0.74\n",
            "Epoch: 54 |  TrainLoss: 0.50852 | TestLoss: 0.53584 | TestAcc: 0.80645 | TestF1: 0.79\n",
            "Epoch: 55 |  TrainLoss: 0.50253 | TestLoss: 0.56562 | TestAcc: 0.75806 | TestF1: 0.78\n",
            "Epoch: 56 |  TrainLoss: 0.49857 | TestLoss: 0.51285 | TestAcc: 0.82258 | TestF1: 0.79\n",
            "Epoch: 57 |  TrainLoss: 0.48737 | TestLoss: 0.51894 | TestAcc: 0.75806 | TestF1: 0.76\n",
            "Epoch: 58 |  TrainLoss: 0.46800 | TestLoss: 0.51156 | TestAcc: 0.79032 | TestF1: 0.80\n",
            "Epoch: 59 |  TrainLoss: 0.45845 | TestLoss: 0.47855 | TestAcc: 0.85484 | TestF1: 0.82\n",
            "Epoch: 60 |  TrainLoss: 0.45824 | TestLoss: 0.52310 | TestAcc: 0.75806 | TestF1: 0.78\n",
            "Epoch: 61 |  TrainLoss: 0.45341 | TestLoss: 0.45513 | TestAcc: 0.85484 | TestF1: 0.82\n",
            "Epoch: 62 |  TrainLoss: 0.43373 | TestLoss: 0.45262 | TestAcc: 0.80645 | TestF1: 0.79\n",
            "Epoch: 63 |  TrainLoss: 0.41426 | TestLoss: 0.46894 | TestAcc: 0.80645 | TestF1: 0.81\n",
            "Epoch: 64 |  TrainLoss: 0.41303 | TestLoss: 0.42581 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 65 |  TrainLoss: 0.41817 | TestLoss: 0.46532 | TestAcc: 0.79032 | TestF1: 0.80\n",
            "Epoch: 66 |  TrainLoss: 0.40370 | TestLoss: 0.40321 | TestAcc: 0.79032 | TestF1: 0.76\n",
            "Epoch: 67 |  TrainLoss: 0.37825 | TestLoss: 0.39148 | TestAcc: 0.82258 | TestF1: 0.79\n",
            "Epoch: 68 |  TrainLoss: 0.37295 | TestLoss: 0.44099 | TestAcc: 0.80645 | TestF1: 0.81\n",
            "Epoch: 69 |  TrainLoss: 0.38139 | TestLoss: 0.37777 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 70 |  TrainLoss: 0.37551 | TestLoss: 0.39226 | TestAcc: 0.85484 | TestF1: 0.85\n",
            "Epoch: 71 |  TrainLoss: 0.35033 | TestLoss: 0.37131 | TestAcc: 0.83871 | TestF1: 0.83\n",
            "Epoch: 72 |  TrainLoss: 0.33868 | TestLoss: 0.35012 | TestAcc: 0.88710 | TestF1: 0.86\n",
            "Epoch: 73 |  TrainLoss: 0.34730 | TestLoss: 0.40882 | TestAcc: 0.83871 | TestF1: 0.84\n",
            "Epoch: 74 |  TrainLoss: 0.35217 | TestLoss: 0.33517 | TestAcc: 0.87097 | TestF1: 0.84\n",
            "Epoch: 75 |  TrainLoss: 0.33282 | TestLoss: 0.33705 | TestAcc: 0.82258 | TestF1: 0.81\n",
            "Epoch: 76 |  TrainLoss: 0.31277 | TestLoss: 0.35242 | TestAcc: 0.85484 | TestF1: 0.85\n",
            "Epoch: 77 |  TrainLoss: 0.31522 | TestLoss: 0.32109 | TestAcc: 0.91935 | TestF1: 0.89\n",
            "Epoch: 78 |  TrainLoss: 0.32598 | TestLoss: 0.36981 | TestAcc: 0.85484 | TestF1: 0.85\n",
            "Epoch: 79 |  TrainLoss: 0.32135 | TestLoss: 0.30433 | TestAcc: 0.82258 | TestF1: 0.79\n",
            "Epoch: 80 |  TrainLoss: 0.29888 | TestLoss: 0.30209 | TestAcc: 0.83871 | TestF1: 0.81\n",
            "Epoch: 81 |  TrainLoss: 0.28901 | TestLoss: 0.33621 | TestAcc: 0.85484 | TestF1: 0.85\n",
            "Epoch: 82 |  TrainLoss: 0.29776 | TestLoss: 0.29775 | TestAcc: 0.88710 | TestF1: 0.86\n",
            "Epoch: 83 |  TrainLoss: 0.30486 | TestLoss: 0.33594 | TestAcc: 0.85484 | TestF1: 0.85\n",
            "Epoch: 84 |  TrainLoss: 0.29486 | TestLoss: 0.28327 | TestAcc: 0.83871 | TestF1: 0.81\n",
            "Epoch: 85 |  TrainLoss: 0.27569 | TestLoss: 0.28037 | TestAcc: 0.83871 | TestF1: 0.81\n",
            "Epoch: 86 |  TrainLoss: 0.27097 | TestLoss: 0.31653 | TestAcc: 0.85484 | TestF1: 0.85\n",
            "Epoch: 87 |  TrainLoss: 0.27991 | TestLoss: 0.27912 | TestAcc: 0.88710 | TestF1: 0.86\n",
            "Epoch: 88 |  TrainLoss: 0.28562 | TestLoss: 0.31728 | TestAcc: 0.85484 | TestF1: 0.85\n",
            "Epoch: 89 |  TrainLoss: 0.27792 | TestLoss: 0.26697 | TestAcc: 0.85484 | TestF1: 0.83\n",
            "Epoch: 90 |  TrainLoss: 0.26117 | TestLoss: 0.26722 | TestAcc: 0.85484 | TestF1: 0.84\n",
            "Epoch: 91 |  TrainLoss: 0.25440 | TestLoss: 0.29122 | TestAcc: 0.87097 | TestF1: 0.86\n",
            "Epoch: 92 |  TrainLoss: 0.25983 | TestLoss: 0.26382 | TestAcc: 0.88710 | TestF1: 0.86\n",
            "Epoch: 93 |  TrainLoss: 0.26664 | TestLoss: 0.30644 | TestAcc: 0.85484 | TestF1: 0.85\n",
            "Epoch: 94 |  TrainLoss: 0.26604 | TestLoss: 0.25621 | TestAcc: 0.88710 | TestF1: 0.86\n",
            "Epoch: 95 |  TrainLoss: 0.25361 | TestLoss: 0.26444 | TestAcc: 0.85484 | TestF1: 0.84\n",
            "Epoch: 96 |  TrainLoss: 0.24235 | TestLoss: 0.26356 | TestAcc: 0.85484 | TestF1: 0.84\n",
            "Epoch: 97 |  TrainLoss: 0.24039 | TestLoss: 0.25035 | TestAcc: 0.88710 | TestF1: 0.86\n",
            "Epoch: 98 |  TrainLoss: 0.24552 | TestLoss: 0.29032 | TestAcc: 0.85484 | TestF1: 0.85\n",
            "Epoch: 99 |  TrainLoss: 0.25135 | TestLoss: 0.25110 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 100 |  TrainLoss: 0.25013 | TestLoss: 0.27899 | TestAcc: 0.87097 | TestF1: 0.86\n",
            "Epoch: 101 |  TrainLoss: 0.24274 | TestLoss: 0.24323 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 102 |  TrainLoss: 0.23199 | TestLoss: 0.24648 | TestAcc: 0.85484 | TestF1: 0.84\n",
            "Epoch: 103 |  TrainLoss: 0.22628 | TestLoss: 0.25505 | TestAcc: 0.85484 | TestF1: 0.84\n",
            "Epoch: 104 |  TrainLoss: 0.22708 | TestLoss: 0.24011 | TestAcc: 0.88710 | TestF1: 0.86\n",
            "Epoch: 105 |  TrainLoss: 0.23133 | TestLoss: 0.27657 | TestAcc: 0.87097 | TestF1: 0.86\n",
            "Epoch: 106 |  TrainLoss: 0.23631 | TestLoss: 0.24241 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 107 |  TrainLoss: 0.23706 | TestLoss: 0.27577 | TestAcc: 0.87097 | TestF1: 0.86\n",
            "Epoch: 108 |  TrainLoss: 0.23391 | TestLoss: 0.23572 | TestAcc: 0.88710 | TestF1: 0.86\n",
            "Epoch: 109 |  TrainLoss: 0.22460 | TestLoss: 0.24674 | TestAcc: 0.85484 | TestF1: 0.84\n",
            "Epoch: 110 |  TrainLoss: 0.21588 | TestLoss: 0.23567 | TestAcc: 0.88710 | TestF1: 0.87\n",
            "Epoch: 111 |  TrainLoss: 0.21130 | TestLoss: 0.23108 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 112 |  TrainLoss: 0.21136 | TestLoss: 0.25305 | TestAcc: 0.85484 | TestF1: 0.84\n",
            "Epoch: 113 |  TrainLoss: 0.21499 | TestLoss: 0.23375 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 114 |  TrainLoss: 0.22108 | TestLoss: 0.28020 | TestAcc: 0.87097 | TestF1: 0.86\n",
            "Epoch: 115 |  TrainLoss: 0.22986 | TestLoss: 0.24294 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 116 |  TrainLoss: 0.23393 | TestLoss: 0.28449 | TestAcc: 0.85484 | TestF1: 0.85\n",
            "Epoch: 117 |  TrainLoss: 0.23105 | TestLoss: 0.23010 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 118 |  TrainLoss: 0.21326 | TestLoss: 0.23404 | TestAcc: 0.88710 | TestF1: 0.87\n",
            "Epoch: 119 |  TrainLoss: 0.19896 | TestLoss: 0.23595 | TestAcc: 0.87097 | TestF1: 0.86\n",
            "Epoch: 120 |  TrainLoss: 0.19857 | TestLoss: 0.22739 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 121 |  TrainLoss: 0.20761 | TestLoss: 0.26648 | TestAcc: 0.87097 | TestF1: 0.86\n",
            "Epoch: 122 |  TrainLoss: 0.21465 | TestLoss: 0.22832 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 123 |  TrainLoss: 0.20845 | TestLoss: 0.24025 | TestAcc: 0.87097 | TestF1: 0.86\n",
            "Epoch: 124 |  TrainLoss: 0.19653 | TestLoss: 0.22278 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 125 |  TrainLoss: 0.18879 | TestLoss: 0.22007 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 126 |  TrainLoss: 0.19090 | TestLoss: 0.24690 | TestAcc: 0.85484 | TestF1: 0.84\n",
            "Epoch: 127 |  TrainLoss: 0.19750 | TestLoss: 0.22419 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 128 |  TrainLoss: 0.19969 | TestLoss: 0.24765 | TestAcc: 0.85484 | TestF1: 0.84\n",
            "Epoch: 129 |  TrainLoss: 0.19606 | TestLoss: 0.21802 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 130 |  TrainLoss: 0.18714 | TestLoss: 0.22241 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 131 |  TrainLoss: 0.18065 | TestLoss: 0.22297 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 132 |  TrainLoss: 0.17963 | TestLoss: 0.21601 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 133 |  TrainLoss: 0.18254 | TestLoss: 0.23964 | TestAcc: 0.87097 | TestF1: 0.86\n",
            "Epoch: 134 |  TrainLoss: 0.18635 | TestLoss: 0.21853 | TestAcc: 0.91935 | TestF1: 0.90\n",
            "Epoch: 135 |  TrainLoss: 0.18737 | TestLoss: 0.24242 | TestAcc: 0.87097 | TestF1: 0.86\n",
            "Epoch: 136 |  TrainLoss: 0.18616 | TestLoss: 0.21553 | TestAcc: 0.91935 | TestF1: 0.90\n",
            "Epoch: 137 |  TrainLoss: 0.18098 | TestLoss: 0.22777 | TestAcc: 0.88710 | TestF1: 0.87\n",
            "Epoch: 138 |  TrainLoss: 0.17531 | TestLoss: 0.21213 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 139 |  TrainLoss: 0.17022 | TestLoss: 0.21410 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 140 |  TrainLoss: 0.16740 | TestLoss: 0.21572 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 141 |  TrainLoss: 0.16660 | TestLoss: 0.21016 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 142 |  TrainLoss: 0.16783 | TestLoss: 0.22984 | TestAcc: 0.88710 | TestF1: 0.87\n",
            "Epoch: 143 |  TrainLoss: 0.17214 | TestLoss: 0.21837 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 144 |  TrainLoss: 0.18116 | TestLoss: 0.27408 | TestAcc: 0.87097 | TestF1: 0.86\n",
            "Epoch: 145 |  TrainLoss: 0.20068 | TestLoss: 0.25167 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 146 |  TrainLoss: 0.22162 | TestLoss: 0.32655 | TestAcc: 0.85484 | TestF1: 0.85\n",
            "Epoch: 147 |  TrainLoss: 0.23883 | TestLoss: 0.23599 | TestAcc: 0.88710 | TestF1: 0.86\n",
            "Epoch: 148 |  TrainLoss: 0.20155 | TestLoss: 0.22049 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 149 |  TrainLoss: 0.16062 | TestLoss: 0.22811 | TestAcc: 0.88710 | TestF1: 0.87\n",
            "Epoch: 150 |  TrainLoss: 0.16445 | TestLoss: 0.22908 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 151 |  TrainLoss: 0.19133 | TestLoss: 0.26539 | TestAcc: 0.87097 | TestF1: 0.86\n",
            "Epoch: 152 |  TrainLoss: 0.18906 | TestLoss: 0.20618 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 153 |  TrainLoss: 0.15653 | TestLoss: 0.20700 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 154 |  TrainLoss: 0.15795 | TestLoss: 0.25579 | TestAcc: 0.87097 | TestF1: 0.86\n",
            "Epoch: 155 |  TrainLoss: 0.17966 | TestLoss: 0.21489 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 156 |  TrainLoss: 0.16900 | TestLoss: 0.21113 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 157 |  TrainLoss: 0.14899 | TestLoss: 0.22186 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 158 |  TrainLoss: 0.15381 | TestLoss: 0.21376 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 159 |  TrainLoss: 0.16506 | TestLoss: 0.23054 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 160 |  TrainLoss: 0.15773 | TestLoss: 0.20422 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 161 |  TrainLoss: 0.14400 | TestLoss: 0.20470 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 162 |  TrainLoss: 0.14832 | TestLoss: 0.23318 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 163 |  TrainLoss: 0.15701 | TestLoss: 0.20616 | TestAcc: 0.91935 | TestF1: 0.90\n",
            "Epoch: 164 |  TrainLoss: 0.14984 | TestLoss: 0.20743 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 165 |  TrainLoss: 0.13987 | TestLoss: 0.21197 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 166 |  TrainLoss: 0.14105 | TestLoss: 0.20547 | TestAcc: 0.91935 | TestF1: 0.90\n",
            "Epoch: 167 |  TrainLoss: 0.14689 | TestLoss: 0.22262 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 168 |  TrainLoss: 0.14581 | TestLoss: 0.20167 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 169 |  TrainLoss: 0.13780 | TestLoss: 0.20233 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 170 |  TrainLoss: 0.13406 | TestLoss: 0.21290 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 171 |  TrainLoss: 0.13691 | TestLoss: 0.20306 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 172 |  TrainLoss: 0.13930 | TestLoss: 0.21668 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 173 |  TrainLoss: 0.13716 | TestLoss: 0.20071 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 174 |  TrainLoss: 0.13178 | TestLoss: 0.20265 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 175 |  TrainLoss: 0.12850 | TestLoss: 0.20701 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 176 |  TrainLoss: 0.12884 | TestLoss: 0.20073 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 177 |  TrainLoss: 0.13066 | TestLoss: 0.21552 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 178 |  TrainLoss: 0.13159 | TestLoss: 0.20104 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 179 |  TrainLoss: 0.13012 | TestLoss: 0.21178 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 180 |  TrainLoss: 0.12743 | TestLoss: 0.19934 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 181 |  TrainLoss: 0.12406 | TestLoss: 0.20362 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 182 |  TrainLoss: 0.12137 | TestLoss: 0.20047 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 183 |  TrainLoss: 0.11968 | TestLoss: 0.19909 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 184 |  TrainLoss: 0.11893 | TestLoss: 0.20499 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 185 |  TrainLoss: 0.11886 | TestLoss: 0.19864 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 186 |  TrainLoss: 0.11941 | TestLoss: 0.21318 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 187 |  TrainLoss: 0.12118 | TestLoss: 0.20215 | TestAcc: 0.91935 | TestF1: 0.90\n",
            "Epoch: 188 |  TrainLoss: 0.12459 | TestLoss: 0.23298 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 189 |  TrainLoss: 0.13256 | TestLoss: 0.21786 | TestAcc: 0.88710 | TestF1: 0.86\n",
            "Epoch: 190 |  TrainLoss: 0.14507 | TestLoss: 0.28414 | TestAcc: 0.87097 | TestF1: 0.86\n",
            "Epoch: 191 |  TrainLoss: 0.16980 | TestLoss: 0.25439 | TestAcc: 0.91935 | TestF1: 0.89\n",
            "Epoch: 192 |  TrainLoss: 0.18887 | TestLoss: 0.32816 | TestAcc: 0.85484 | TestF1: 0.85\n",
            "Epoch: 193 |  TrainLoss: 0.20298 | TestLoss: 0.23009 | TestAcc: 0.88710 | TestF1: 0.86\n",
            "Epoch: 194 |  TrainLoss: 0.15901 | TestLoss: 0.21199 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 195 |  TrainLoss: 0.11419 | TestLoss: 0.21674 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 196 |  TrainLoss: 0.11669 | TestLoss: 0.22067 | TestAcc: 0.88710 | TestF1: 0.86\n",
            "Epoch: 197 |  TrainLoss: 0.14624 | TestLoss: 0.26186 | TestAcc: 0.88710 | TestF1: 0.88\n",
            "Epoch: 198 |  TrainLoss: 0.14841 | TestLoss: 0.19760 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 199 |  TrainLoss: 0.11325 | TestLoss: 0.19563 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 200 |  TrainLoss: 0.10848 | TestLoss: 0.24200 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 201 |  TrainLoss: 0.13160 | TestLoss: 0.20899 | TestAcc: 0.91935 | TestF1: 0.90\n",
            "Epoch: 202 |  TrainLoss: 0.12762 | TestLoss: 0.20802 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 203 |  TrainLoss: 0.10654 | TestLoss: 0.20390 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 204 |  TrainLoss: 0.10339 | TestLoss: 0.20377 | TestAcc: 0.91935 | TestF1: 0.90\n",
            "Epoch: 205 |  TrainLoss: 0.11761 | TestLoss: 0.23084 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 206 |  TrainLoss: 0.11965 | TestLoss: 0.19607 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 207 |  TrainLoss: 0.10327 | TestLoss: 0.19522 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 208 |  TrainLoss: 0.09808 | TestLoss: 0.21751 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 209 |  TrainLoss: 0.10749 | TestLoss: 0.20126 | TestAcc: 0.91935 | TestF1: 0.90\n",
            "Epoch: 210 |  TrainLoss: 0.10951 | TestLoss: 0.21016 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 211 |  TrainLoss: 0.10086 | TestLoss: 0.19670 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 212 |  TrainLoss: 0.09376 | TestLoss: 0.19586 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 213 |  TrainLoss: 0.09749 | TestLoss: 0.21753 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 214 |  TrainLoss: 0.10284 | TestLoss: 0.19729 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 215 |  TrainLoss: 0.09899 | TestLoss: 0.20269 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 216 |  TrainLoss: 0.09206 | TestLoss: 0.19920 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 217 |  TrainLoss: 0.08983 | TestLoss: 0.19536 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 218 |  TrainLoss: 0.09290 | TestLoss: 0.21278 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 219 |  TrainLoss: 0.09530 | TestLoss: 0.19554 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 220 |  TrainLoss: 0.09241 | TestLoss: 0.20254 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 221 |  TrainLoss: 0.08777 | TestLoss: 0.19678 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 222 |  TrainLoss: 0.08509 | TestLoss: 0.19464 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 223 |  TrainLoss: 0.08574 | TestLoss: 0.20710 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 224 |  TrainLoss: 0.08756 | TestLoss: 0.19501 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 225 |  TrainLoss: 0.08764 | TestLoss: 0.20740 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 226 |  TrainLoss: 0.08601 | TestLoss: 0.19410 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 227 |  TrainLoss: 0.08293 | TestLoss: 0.19916 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 228 |  TrainLoss: 0.08031 | TestLoss: 0.19656 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 229 |  TrainLoss: 0.07889 | TestLoss: 0.19454 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 230 |  TrainLoss: 0.07862 | TestLoss: 0.20266 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 231 |  TrainLoss: 0.07903 | TestLoss: 0.19411 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 232 |  TrainLoss: 0.07956 | TestLoss: 0.20851 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 233 |  TrainLoss: 0.08031 | TestLoss: 0.19517 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 234 |  TrainLoss: 0.08067 | TestLoss: 0.21388 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 235 |  TrainLoss: 0.08159 | TestLoss: 0.19697 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 236 |  TrainLoss: 0.08212 | TestLoss: 0.22055 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 237 |  TrainLoss: 0.08393 | TestLoss: 0.19975 | TestAcc: 0.93548 | TestF1: 0.92\n",
            "Epoch: 238 |  TrainLoss: 0.08518 | TestLoss: 0.23024 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 239 |  TrainLoss: 0.08870 | TestLoss: 0.20449 | TestAcc: 0.93548 | TestF1: 0.92\n",
            "Epoch: 240 |  TrainLoss: 0.09077 | TestLoss: 0.24314 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 241 |  TrainLoss: 0.09602 | TestLoss: 0.21001 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 242 |  TrainLoss: 0.09748 | TestLoss: 0.25262 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 243 |  TrainLoss: 0.10112 | TestLoss: 0.20936 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 244 |  TrainLoss: 0.09549 | TestLoss: 0.23730 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 245 |  TrainLoss: 0.08852 | TestLoss: 0.19717 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 246 |  TrainLoss: 0.07489 | TestLoss: 0.20231 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 247 |  TrainLoss: 0.06605 | TestLoss: 0.20165 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 248 |  TrainLoss: 0.06503 | TestLoss: 0.19608 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 249 |  TrainLoss: 0.07005 | TestLoss: 0.22522 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 250 |  TrainLoss: 0.07674 | TestLoss: 0.20210 | TestAcc: 0.93548 | TestF1: 0.92\n",
            "Epoch: 251 |  TrainLoss: 0.07916 | TestLoss: 0.23168 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 252 |  TrainLoss: 0.07953 | TestLoss: 0.19960 | TestAcc: 0.93548 | TestF1: 0.92\n",
            "Epoch: 253 |  TrainLoss: 0.07345 | TestLoss: 0.21436 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 254 |  TrainLoss: 0.06681 | TestLoss: 0.19562 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 255 |  TrainLoss: 0.06062 | TestLoss: 0.19735 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 256 |  TrainLoss: 0.05851 | TestLoss: 0.20642 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 257 |  TrainLoss: 0.06027 | TestLoss: 0.19686 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 258 |  TrainLoss: 0.06333 | TestLoss: 0.22045 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 259 |  TrainLoss: 0.06662 | TestLoss: 0.20012 | TestAcc: 0.93548 | TestF1: 0.92\n",
            "Epoch: 260 |  TrainLoss: 0.06761 | TestLoss: 0.22564 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 261 |  TrainLoss: 0.06797 | TestLoss: 0.19943 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 262 |  TrainLoss: 0.06466 | TestLoss: 0.21639 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 263 |  TrainLoss: 0.06078 | TestLoss: 0.19668 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 264 |  TrainLoss: 0.05590 | TestLoss: 0.20159 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 265 |  TrainLoss: 0.05292 | TestLoss: 0.20222 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 266 |  TrainLoss: 0.05238 | TestLoss: 0.19679 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 267 |  TrainLoss: 0.05360 | TestLoss: 0.21296 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 268 |  TrainLoss: 0.05546 | TestLoss: 0.19802 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 269 |  TrainLoss: 0.05642 | TestLoss: 0.21855 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 270 |  TrainLoss: 0.05723 | TestLoss: 0.19910 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 271 |  TrainLoss: 0.05663 | TestLoss: 0.21973 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 272 |  TrainLoss: 0.05619 | TestLoss: 0.19913 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 273 |  TrainLoss: 0.05437 | TestLoss: 0.21620 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 274 |  TrainLoss: 0.05256 | TestLoss: 0.19826 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 275 |  TrainLoss: 0.04982 | TestLoss: 0.20804 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 276 |  TrainLoss: 0.04742 | TestLoss: 0.19950 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 277 |  TrainLoss: 0.04552 | TestLoss: 0.20102 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 278 |  TrainLoss: 0.04459 | TestLoss: 0.20489 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 279 |  TrainLoss: 0.04446 | TestLoss: 0.19893 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 280 |  TrainLoss: 0.04481 | TestLoss: 0.21147 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 281 |  TrainLoss: 0.04544 | TestLoss: 0.19929 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 282 |  TrainLoss: 0.04600 | TestLoss: 0.21796 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 283 |  TrainLoss: 0.04707 | TestLoss: 0.20060 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 284 |  TrainLoss: 0.04812 | TestLoss: 0.22764 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 285 |  TrainLoss: 0.05056 | TestLoss: 0.20369 | TestAcc: 0.93548 | TestF1: 0.92\n",
            "Epoch: 286 |  TrainLoss: 0.05301 | TestLoss: 0.24510 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 287 |  TrainLoss: 0.05900 | TestLoss: 0.21214 | TestAcc: 0.95161 | TestF1: 0.94\n",
            "Epoch: 288 |  TrainLoss: 0.06610 | TestLoss: 0.29032 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 289 |  TrainLoss: 0.08693 | TestLoss: 0.25963 | TestAcc: 0.91935 | TestF1: 0.89\n",
            "Epoch: 290 |  TrainLoss: 0.12888 | TestLoss: 0.59394 | TestAcc: 0.77419 | TestF1: 0.78\n",
            "Epoch: 291 |  TrainLoss: 0.31670 | TestLoss: 1.11095 | TestAcc: 0.70968 | TestF1: 0.47\n",
            "Epoch: 292 |  TrainLoss: 1.14517 | TestLoss: 2.34409 | TestAcc: 0.54839 | TestF1: 0.65\n",
            "Epoch: 293 |  TrainLoss: 1.73364 | TestLoss: 0.24441 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 294 |  TrainLoss: 0.06012 | TestLoss: 1.41337 | TestAcc: 0.66129 | TestF1: 0.32\n",
            "Epoch: 295 |  TrainLoss: 1.48654 | TestLoss: 0.27560 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 296 |  TrainLoss: 0.08819 | TestLoss: 1.56415 | TestAcc: 0.61290 | TestF1: 0.68\n",
            "Epoch: 297 |  TrainLoss: 1.12585 | TestLoss: 0.19851 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 298 |  TrainLoss: 0.06422 | TestLoss: 0.98729 | TestAcc: 0.70968 | TestF1: 0.47\n",
            "Epoch: 299 |  TrainLoss: 1.00952 | TestLoss: 0.19960 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 300 |  TrainLoss: 0.05894 | TestLoss: 1.09111 | TestAcc: 0.69355 | TestF1: 0.73\n",
            "Epoch: 301 |  TrainLoss: 0.74873 | TestLoss: 0.31374 | TestAcc: 0.87097 | TestF1: 0.86\n",
            "Epoch: 302 |  TrainLoss: 0.13399 | TestLoss: 0.47793 | TestAcc: 0.83871 | TestF1: 0.76\n",
            "Epoch: 303 |  TrainLoss: 0.42937 | TestLoss: 0.30747 | TestAcc: 0.91935 | TestF1: 0.89\n",
            "Epoch: 304 |  TrainLoss: 0.22678 | TestLoss: 0.37173 | TestAcc: 0.87097 | TestF1: 0.86\n",
            "Epoch: 305 |  TrainLoss: 0.18048 | TestLoss: 0.61660 | TestAcc: 0.77419 | TestF1: 0.79\n",
            "Epoch: 306 |  TrainLoss: 0.36954 | TestLoss: 0.19122 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 307 |  TrainLoss: 0.06734 | TestLoss: 0.38691 | TestAcc: 0.88710 | TestF1: 0.84\n",
            "Epoch: 308 |  TrainLoss: 0.32494 | TestLoss: 0.22049 | TestAcc: 0.91935 | TestF1: 0.89\n",
            "Epoch: 309 |  TrainLoss: 0.12430 | TestLoss: 0.31391 | TestAcc: 0.87097 | TestF1: 0.86\n",
            "Epoch: 310 |  TrainLoss: 0.14490 | TestLoss: 0.44069 | TestAcc: 0.80645 | TestF1: 0.81\n",
            "Epoch: 311 |  TrainLoss: 0.23792 | TestLoss: 0.19484 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 312 |  TrainLoss: 0.07062 | TestLoss: 0.27010 | TestAcc: 0.91935 | TestF1: 0.89\n",
            "Epoch: 313 |  TrainLoss: 0.18855 | TestLoss: 0.22619 | TestAcc: 0.91935 | TestF1: 0.89\n",
            "Epoch: 314 |  TrainLoss: 0.13558 | TestLoss: 0.21799 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 315 |  TrainLoss: 0.08347 | TestLoss: 0.35331 | TestAcc: 0.87097 | TestF1: 0.86\n",
            "Epoch: 316 |  TrainLoss: 0.17476 | TestLoss: 0.22810 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 317 |  TrainLoss: 0.08948 | TestLoss: 0.19776 | TestAcc: 0.91935 | TestF1: 0.90\n",
            "Epoch: 318 |  TrainLoss: 0.09878 | TestLoss: 0.22917 | TestAcc: 0.91935 | TestF1: 0.89\n",
            "Epoch: 319 |  TrainLoss: 0.13995 | TestLoss: 0.18395 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 320 |  TrainLoss: 0.06969 | TestLoss: 0.25962 | TestAcc: 0.87097 | TestF1: 0.86\n",
            "Epoch: 321 |  TrainLoss: 0.10855 | TestLoss: 0.25971 | TestAcc: 0.87097 | TestF1: 0.86\n",
            "Epoch: 322 |  TrainLoss: 0.10801 | TestLoss: 0.18543 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 323 |  TrainLoss: 0.06701 | TestLoss: 0.20285 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 324 |  TrainLoss: 0.10467 | TestLoss: 0.19010 | TestAcc: 0.93548 | TestF1: 0.92\n",
            "Epoch: 325 |  TrainLoss: 0.08525 | TestLoss: 0.19898 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 326 |  TrainLoss: 0.06905 | TestLoss: 0.24630 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 327 |  TrainLoss: 0.09598 | TestLoss: 0.20862 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 328 |  TrainLoss: 0.07266 | TestLoss: 0.18403 | TestAcc: 0.93548 | TestF1: 0.92\n",
            "Epoch: 329 |  TrainLoss: 0.06975 | TestLoss: 0.19254 | TestAcc: 0.93548 | TestF1: 0.92\n",
            "Epoch: 330 |  TrainLoss: 0.08570 | TestLoss: 0.18438 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 331 |  TrainLoss: 0.06423 | TestLoss: 0.21071 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 332 |  TrainLoss: 0.07097 | TestLoss: 0.22105 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 333 |  TrainLoss: 0.07628 | TestLoss: 0.19063 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 334 |  TrainLoss: 0.06069 | TestLoss: 0.18690 | TestAcc: 0.91935 | TestF1: 0.90\n",
            "Epoch: 335 |  TrainLoss: 0.07018 | TestLoss: 0.18634 | TestAcc: 0.91935 | TestF1: 0.90\n",
            "Epoch: 336 |  TrainLoss: 0.06788 | TestLoss: 0.19180 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 337 |  TrainLoss: 0.05919 | TestLoss: 0.21203 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 338 |  TrainLoss: 0.06781 | TestLoss: 0.20133 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 339 |  TrainLoss: 0.06163 | TestLoss: 0.18604 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 340 |  TrainLoss: 0.05854 | TestLoss: 0.18578 | TestAcc: 0.93548 | TestF1: 0.92\n",
            "Epoch: 341 |  TrainLoss: 0.06407 | TestLoss: 0.18614 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 342 |  TrainLoss: 0.05716 | TestLoss: 0.19890 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 343 |  TrainLoss: 0.05827 | TestLoss: 0.20438 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 344 |  TrainLoss: 0.06016 | TestLoss: 0.19092 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 345 |  TrainLoss: 0.05469 | TestLoss: 0.18517 | TestAcc: 0.93548 | TestF1: 0.92\n",
            "Epoch: 346 |  TrainLoss: 0.05727 | TestLoss: 0.18534 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 347 |  TrainLoss: 0.05632 | TestLoss: 0.19154 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 348 |  TrainLoss: 0.05320 | TestLoss: 0.20119 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 349 |  TrainLoss: 0.05567 | TestLoss: 0.19628 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 350 |  TrainLoss: 0.05321 | TestLoss: 0.18795 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 351 |  TrainLoss: 0.05223 | TestLoss: 0.18649 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 352 |  TrainLoss: 0.05352 | TestLoss: 0.18955 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 353 |  TrainLoss: 0.05086 | TestLoss: 0.19745 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 354 |  TrainLoss: 0.05130 | TestLoss: 0.19858 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 355 |  TrainLoss: 0.05112 | TestLoss: 0.19156 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 356 |  TrainLoss: 0.04921 | TestLoss: 0.18800 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 357 |  TrainLoss: 0.05000 | TestLoss: 0.18919 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 358 |  TrainLoss: 0.04885 | TestLoss: 0.19479 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 359 |  TrainLoss: 0.04804 | TestLoss: 0.19851 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 360 |  TrainLoss: 0.04839 | TestLoss: 0.19443 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 361 |  TrainLoss: 0.04698 | TestLoss: 0.19007 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 362 |  TrainLoss: 0.04688 | TestLoss: 0.18987 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 363 |  TrainLoss: 0.04653 | TestLoss: 0.19375 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 364 |  TrainLoss: 0.04546 | TestLoss: 0.19797 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 365 |  TrainLoss: 0.04558 | TestLoss: 0.19634 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 366 |  TrainLoss: 0.04478 | TestLoss: 0.19223 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 367 |  TrainLoss: 0.04427 | TestLoss: 0.19120 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 368 |  TrainLoss: 0.04416 | TestLoss: 0.19392 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 369 |  TrainLoss: 0.04333 | TestLoss: 0.19782 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 370 |  TrainLoss: 0.04316 | TestLoss: 0.19775 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 371 |  TrainLoss: 0.04269 | TestLoss: 0.19431 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 372 |  TrainLoss: 0.04207 | TestLoss: 0.19261 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 373 |  TrainLoss: 0.04189 | TestLoss: 0.19430 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 374 |  TrainLoss: 0.04123 | TestLoss: 0.19763 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 375 |  TrainLoss: 0.04083 | TestLoss: 0.19846 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 376 |  TrainLoss: 0.04042 | TestLoss: 0.19608 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 377 |  TrainLoss: 0.03979 | TestLoss: 0.19436 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 378 |  TrainLoss: 0.03949 | TestLoss: 0.19545 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 379 |  TrainLoss: 0.03894 | TestLoss: 0.19816 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 380 |  TrainLoss: 0.03851 | TestLoss: 0.19910 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 381 |  TrainLoss: 0.03813 | TestLoss: 0.19723 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 382 |  TrainLoss: 0.03759 | TestLoss: 0.19554 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 383 |  TrainLoss: 0.03725 | TestLoss: 0.19604 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 384 |  TrainLoss: 0.03685 | TestLoss: 0.19769 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 385 |  TrainLoss: 0.03655 | TestLoss: 0.19796 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 386 |  TrainLoss: 0.03630 | TestLoss: 0.19617 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 387 |  TrainLoss: 0.03595 | TestLoss: 0.19464 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 388 |  TrainLoss: 0.03571 | TestLoss: 0.19512 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 389 |  TrainLoss: 0.03538 | TestLoss: 0.19670 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 390 |  TrainLoss: 0.03508 | TestLoss: 0.19710 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 391 |  TrainLoss: 0.03478 | TestLoss: 0.19591 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 392 |  TrainLoss: 0.03442 | TestLoss: 0.19520 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 393 |  TrainLoss: 0.03412 | TestLoss: 0.19612 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 394 |  TrainLoss: 0.03376 | TestLoss: 0.19769 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 395 |  TrainLoss: 0.03343 | TestLoss: 0.19799 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 396 |  TrainLoss: 0.03308 | TestLoss: 0.19715 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 397 |  TrainLoss: 0.03273 | TestLoss: 0.19704 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 398 |  TrainLoss: 0.03240 | TestLoss: 0.19822 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 399 |  TrainLoss: 0.03204 | TestLoss: 0.19952 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 400 |  TrainLoss: 0.03173 | TestLoss: 0.19954 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 401 |  TrainLoss: 0.03142 | TestLoss: 0.19888 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 402 |  TrainLoss: 0.03111 | TestLoss: 0.19885 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 403 |  TrainLoss: 0.03083 | TestLoss: 0.19979 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 404 |  TrainLoss: 0.03055 | TestLoss: 0.20057 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 405 |  TrainLoss: 0.03027 | TestLoss: 0.20024 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 406 |  TrainLoss: 0.02998 | TestLoss: 0.19961 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 407 |  TrainLoss: 0.02970 | TestLoss: 0.19976 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 408 |  TrainLoss: 0.02940 | TestLoss: 0.20047 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 409 |  TrainLoss: 0.02911 | TestLoss: 0.20066 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 410 |  TrainLoss: 0.02882 | TestLoss: 0.20007 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 411 |  TrainLoss: 0.02853 | TestLoss: 0.19968 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 412 |  TrainLoss: 0.02826 | TestLoss: 0.20006 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 413 |  TrainLoss: 0.02798 | TestLoss: 0.20059 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 414 |  TrainLoss: 0.02771 | TestLoss: 0.20039 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 415 |  TrainLoss: 0.02744 | TestLoss: 0.19989 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 416 |  TrainLoss: 0.02717 | TestLoss: 0.20000 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 417 |  TrainLoss: 0.02691 | TestLoss: 0.20060 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 418 |  TrainLoss: 0.02664 | TestLoss: 0.20076 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 419 |  TrainLoss: 0.02637 | TestLoss: 0.20047 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 420 |  TrainLoss: 0.02610 | TestLoss: 0.20051 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 421 |  TrainLoss: 0.02584 | TestLoss: 0.20109 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 422 |  TrainLoss: 0.02558 | TestLoss: 0.20141 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 423 |  TrainLoss: 0.02532 | TestLoss: 0.20122 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 424 |  TrainLoss: 0.02506 | TestLoss: 0.20114 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 425 |  TrainLoss: 0.02481 | TestLoss: 0.20154 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 426 |  TrainLoss: 0.02456 | TestLoss: 0.20189 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 427 |  TrainLoss: 0.02431 | TestLoss: 0.20176 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 428 |  TrainLoss: 0.02406 | TestLoss: 0.20165 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 429 |  TrainLoss: 0.02382 | TestLoss: 0.20208 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 430 |  TrainLoss: 0.02358 | TestLoss: 0.20237 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 431 |  TrainLoss: 0.02333 | TestLoss: 0.20211 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 432 |  TrainLoss: 0.02310 | TestLoss: 0.20210 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 433 |  TrainLoss: 0.02286 | TestLoss: 0.20253 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 434 |  TrainLoss: 0.02262 | TestLoss: 0.20269 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 435 |  TrainLoss: 0.02239 | TestLoss: 0.20242 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 436 |  TrainLoss: 0.02216 | TestLoss: 0.20254 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 437 |  TrainLoss: 0.02192 | TestLoss: 0.20307 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 438 |  TrainLoss: 0.02169 | TestLoss: 0.20314 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 439 |  TrainLoss: 0.02146 | TestLoss: 0.20286 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 440 |  TrainLoss: 0.02124 | TestLoss: 0.20305 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 441 |  TrainLoss: 0.02101 | TestLoss: 0.20365 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 442 |  TrainLoss: 0.02079 | TestLoss: 0.20351 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 443 |  TrainLoss: 0.02056 | TestLoss: 0.20334 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 444 |  TrainLoss: 0.02034 | TestLoss: 0.20373 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 445 |  TrainLoss: 0.02012 | TestLoss: 0.20418 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 446 |  TrainLoss: 0.01990 | TestLoss: 0.20392 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 447 |  TrainLoss: 0.01967 | TestLoss: 0.20391 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 448 |  TrainLoss: 0.01943 | TestLoss: 0.20420 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 449 |  TrainLoss: 0.01917 | TestLoss: 0.20433 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 450 |  TrainLoss: 0.01891 | TestLoss: 0.20466 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 451 |  TrainLoss: 0.01870 | TestLoss: 0.20542 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 452 |  TrainLoss: 0.01850 | TestLoss: 0.20524 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 453 |  TrainLoss: 0.01829 | TestLoss: 0.20509 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 454 |  TrainLoss: 0.01808 | TestLoss: 0.20536 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 455 |  TrainLoss: 0.01787 | TestLoss: 0.20556 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 456 |  TrainLoss: 0.01767 | TestLoss: 0.20523 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 457 |  TrainLoss: 0.01745 | TestLoss: 0.20504 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 458 |  TrainLoss: 0.01726 | TestLoss: 0.20525 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 459 |  TrainLoss: 0.01706 | TestLoss: 0.20553 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 460 |  TrainLoss: 0.01685 | TestLoss: 0.20569 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 461 |  TrainLoss: 0.01665 | TestLoss: 0.20608 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 462 |  TrainLoss: 0.01646 | TestLoss: 0.20648 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 463 |  TrainLoss: 0.01626 | TestLoss: 0.20611 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 464 |  TrainLoss: 0.01606 | TestLoss: 0.20612 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 465 |  TrainLoss: 0.01586 | TestLoss: 0.20676 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 466 |  TrainLoss: 0.01566 | TestLoss: 0.20722 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 467 |  TrainLoss: 0.01547 | TestLoss: 0.20700 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 468 |  TrainLoss: 0.01527 | TestLoss: 0.20753 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 469 |  TrainLoss: 0.01508 | TestLoss: 0.20824 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 470 |  TrainLoss: 0.01490 | TestLoss: 0.20823 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 471 |  TrainLoss: 0.01471 | TestLoss: 0.20808 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 472 |  TrainLoss: 0.01452 | TestLoss: 0.20860 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 473 |  TrainLoss: 0.01434 | TestLoss: 0.20872 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 474 |  TrainLoss: 0.01416 | TestLoss: 0.20858 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 475 |  TrainLoss: 0.01398 | TestLoss: 0.20885 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 476 |  TrainLoss: 0.01379 | TestLoss: 0.20933 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 477 |  TrainLoss: 0.01361 | TestLoss: 0.20921 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 478 |  TrainLoss: 0.01343 | TestLoss: 0.20945 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 479 |  TrainLoss: 0.01326 | TestLoss: 0.21037 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 480 |  TrainLoss: 0.01308 | TestLoss: 0.20995 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 481 |  TrainLoss: 0.01291 | TestLoss: 0.20992 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 482 |  TrainLoss: 0.01273 | TestLoss: 0.21084 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 483 |  TrainLoss: 0.01256 | TestLoss: 0.21080 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 484 |  TrainLoss: 0.01239 | TestLoss: 0.21074 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 485 |  TrainLoss: 0.01222 | TestLoss: 0.21135 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 486 |  TrainLoss: 0.01206 | TestLoss: 0.21151 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 487 |  TrainLoss: 0.01189 | TestLoss: 0.21148 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 488 |  TrainLoss: 0.01173 | TestLoss: 0.21193 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 489 |  TrainLoss: 0.01156 | TestLoss: 0.21208 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 490 |  TrainLoss: 0.01141 | TestLoss: 0.21219 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 491 |  TrainLoss: 0.01125 | TestLoss: 0.21268 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 492 |  TrainLoss: 0.01109 | TestLoss: 0.21270 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 493 |  TrainLoss: 0.01094 | TestLoss: 0.21327 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 494 |  TrainLoss: 0.01079 | TestLoss: 0.21329 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 495 |  TrainLoss: 0.01064 | TestLoss: 0.21342 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 496 |  TrainLoss: 0.01049 | TestLoss: 0.21374 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 497 |  TrainLoss: 0.01034 | TestLoss: 0.21446 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 498 |  TrainLoss: 0.01019 | TestLoss: 0.21431 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 499 |  TrainLoss: 0.01005 | TestLoss: 0.21423 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 500 |  TrainLoss: 0.00991 | TestLoss: 0.21502 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 501 |  TrainLoss: 0.00977 | TestLoss: 0.21530 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 502 |  TrainLoss: 0.00963 | TestLoss: 0.21550 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 503 |  TrainLoss: 0.00949 | TestLoss: 0.21592 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 504 |  TrainLoss: 0.00935 | TestLoss: 0.21634 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 505 |  TrainLoss: 0.00921 | TestLoss: 0.21639 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 506 |  TrainLoss: 0.00907 | TestLoss: 0.21690 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 507 |  TrainLoss: 0.00893 | TestLoss: 0.21747 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 508 |  TrainLoss: 0.00880 | TestLoss: 0.21745 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 509 |  TrainLoss: 0.00867 | TestLoss: 0.21754 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 510 |  TrainLoss: 0.00855 | TestLoss: 0.21831 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 511 |  TrainLoss: 0.00843 | TestLoss: 0.21839 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 512 |  TrainLoss: 0.00831 | TestLoss: 0.21830 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 513 |  TrainLoss: 0.00819 | TestLoss: 0.21871 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 514 |  TrainLoss: 0.00807 | TestLoss: 0.21989 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 515 |  TrainLoss: 0.00795 | TestLoss: 0.21969 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 516 |  TrainLoss: 0.00783 | TestLoss: 0.21938 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 517 |  TrainLoss: 0.00772 | TestLoss: 0.22029 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 518 |  TrainLoss: 0.00761 | TestLoss: 0.22025 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 519 |  TrainLoss: 0.00750 | TestLoss: 0.22056 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 520 |  TrainLoss: 0.00739 | TestLoss: 0.22128 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 521 |  TrainLoss: 0.00728 | TestLoss: 0.22129 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 522 |  TrainLoss: 0.00717 | TestLoss: 0.22122 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 523 |  TrainLoss: 0.00706 | TestLoss: 0.22171 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 524 |  TrainLoss: 0.00695 | TestLoss: 0.22231 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 525 |  TrainLoss: 0.00685 | TestLoss: 0.22238 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 526 |  TrainLoss: 0.00675 | TestLoss: 0.22259 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 527 |  TrainLoss: 0.00664 | TestLoss: 0.22325 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 528 |  TrainLoss: 0.00654 | TestLoss: 0.22318 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 529 |  TrainLoss: 0.00644 | TestLoss: 0.22338 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 530 |  TrainLoss: 0.00635 | TestLoss: 0.22413 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 531 |  TrainLoss: 0.00625 | TestLoss: 0.22416 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 532 |  TrainLoss: 0.00616 | TestLoss: 0.22409 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 533 |  TrainLoss: 0.00607 | TestLoss: 0.22491 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 534 |  TrainLoss: 0.00598 | TestLoss: 0.22500 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 535 |  TrainLoss: 0.00590 | TestLoss: 0.22516 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 536 |  TrainLoss: 0.00581 | TestLoss: 0.22566 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 537 |  TrainLoss: 0.00573 | TestLoss: 0.22612 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 538 |  TrainLoss: 0.00565 | TestLoss: 0.22608 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 539 |  TrainLoss: 0.00557 | TestLoss: 0.22631 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 540 |  TrainLoss: 0.00549 | TestLoss: 0.22674 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 541 |  TrainLoss: 0.00541 | TestLoss: 0.22713 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 542 |  TrainLoss: 0.00533 | TestLoss: 0.22715 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 543 |  TrainLoss: 0.00526 | TestLoss: 0.22737 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 544 |  TrainLoss: 0.00518 | TestLoss: 0.22802 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 545 |  TrainLoss: 0.00511 | TestLoss: 0.22819 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 546 |  TrainLoss: 0.00503 | TestLoss: 0.22822 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 547 |  TrainLoss: 0.00496 | TestLoss: 0.22883 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 548 |  TrainLoss: 0.00489 | TestLoss: 0.22883 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 549 |  TrainLoss: 0.00482 | TestLoss: 0.22879 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 550 |  TrainLoss: 0.00476 | TestLoss: 0.22946 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 551 |  TrainLoss: 0.00469 | TestLoss: 0.22985 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 552 |  TrainLoss: 0.00463 | TestLoss: 0.22990 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 553 |  TrainLoss: 0.00456 | TestLoss: 0.23005 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 554 |  TrainLoss: 0.00450 | TestLoss: 0.23098 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 555 |  TrainLoss: 0.00444 | TestLoss: 0.23080 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 556 |  TrainLoss: 0.00438 | TestLoss: 0.23082 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 557 |  TrainLoss: 0.00432 | TestLoss: 0.23112 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 558 |  TrainLoss: 0.00426 | TestLoss: 0.23165 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 559 |  TrainLoss: 0.00420 | TestLoss: 0.23171 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 560 |  TrainLoss: 0.00415 | TestLoss: 0.23212 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 561 |  TrainLoss: 0.00409 | TestLoss: 0.23275 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 562 |  TrainLoss: 0.00404 | TestLoss: 0.23274 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 563 |  TrainLoss: 0.00398 | TestLoss: 0.23266 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 564 |  TrainLoss: 0.00393 | TestLoss: 0.23331 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 565 |  TrainLoss: 0.00388 | TestLoss: 0.23431 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 566 |  TrainLoss: 0.00383 | TestLoss: 0.23372 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 567 |  TrainLoss: 0.00378 | TestLoss: 0.23371 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 568 |  TrainLoss: 0.00373 | TestLoss: 0.23474 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 569 |  TrainLoss: 0.00368 | TestLoss: 0.23468 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 570 |  TrainLoss: 0.00363 | TestLoss: 0.23426 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 571 |  TrainLoss: 0.00359 | TestLoss: 0.23552 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 572 |  TrainLoss: 0.00354 | TestLoss: 0.23603 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 573 |  TrainLoss: 0.00349 | TestLoss: 0.23553 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 574 |  TrainLoss: 0.00345 | TestLoss: 0.23569 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 575 |  TrainLoss: 0.00341 | TestLoss: 0.23639 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 576 |  TrainLoss: 0.00336 | TestLoss: 0.23665 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 577 |  TrainLoss: 0.00332 | TestLoss: 0.23647 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 578 |  TrainLoss: 0.00328 | TestLoss: 0.23722 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 579 |  TrainLoss: 0.00324 | TestLoss: 0.23766 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 580 |  TrainLoss: 0.00320 | TestLoss: 0.23734 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 581 |  TrainLoss: 0.00316 | TestLoss: 0.23743 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 582 |  TrainLoss: 0.00312 | TestLoss: 0.23821 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 583 |  TrainLoss: 0.00308 | TestLoss: 0.23854 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 584 |  TrainLoss: 0.00305 | TestLoss: 0.23839 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 585 |  TrainLoss: 0.00301 | TestLoss: 0.23908 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 586 |  TrainLoss: 0.00297 | TestLoss: 0.23955 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 587 |  TrainLoss: 0.00294 | TestLoss: 0.23944 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 588 |  TrainLoss: 0.00290 | TestLoss: 0.23958 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 589 |  TrainLoss: 0.00287 | TestLoss: 0.24031 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 590 |  TrainLoss: 0.00283 | TestLoss: 0.24065 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 591 |  TrainLoss: 0.00280 | TestLoss: 0.24045 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 592 |  TrainLoss: 0.00277 | TestLoss: 0.24076 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 593 |  TrainLoss: 0.00274 | TestLoss: 0.24144 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 594 |  TrainLoss: 0.00270 | TestLoss: 0.24147 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 595 |  TrainLoss: 0.00267 | TestLoss: 0.24127 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 596 |  TrainLoss: 0.00264 | TestLoss: 0.24204 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 597 |  TrainLoss: 0.00261 | TestLoss: 0.24283 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 598 |  TrainLoss: 0.00258 | TestLoss: 0.24260 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 599 |  TrainLoss: 0.00255 | TestLoss: 0.24251 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 600 |  TrainLoss: 0.00252 | TestLoss: 0.24319 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 601 |  TrainLoss: 0.00249 | TestLoss: 0.24356 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 602 |  TrainLoss: 0.00246 | TestLoss: 0.24375 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 603 |  TrainLoss: 0.00244 | TestLoss: 0.24418 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 604 |  TrainLoss: 0.00241 | TestLoss: 0.24441 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 605 |  TrainLoss: 0.00238 | TestLoss: 0.24468 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 606 |  TrainLoss: 0.00235 | TestLoss: 0.24495 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 607 |  TrainLoss: 0.00233 | TestLoss: 0.24500 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 608 |  TrainLoss: 0.00230 | TestLoss: 0.24524 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 609 |  TrainLoss: 0.00228 | TestLoss: 0.24591 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 610 |  TrainLoss: 0.00225 | TestLoss: 0.24620 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 611 |  TrainLoss: 0.00223 | TestLoss: 0.24599 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 612 |  TrainLoss: 0.00220 | TestLoss: 0.24622 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 613 |  TrainLoss: 0.00218 | TestLoss: 0.24688 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 614 |  TrainLoss: 0.00215 | TestLoss: 0.24755 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 615 |  TrainLoss: 0.00213 | TestLoss: 0.24787 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 616 |  TrainLoss: 0.00210 | TestLoss: 0.24817 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 617 |  TrainLoss: 0.00208 | TestLoss: 0.24873 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 618 |  TrainLoss: 0.00206 | TestLoss: 0.24909 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 619 |  TrainLoss: 0.00203 | TestLoss: 0.24958 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 620 |  TrainLoss: 0.00201 | TestLoss: 0.25030 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 621 |  TrainLoss: 0.00199 | TestLoss: 0.25030 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 622 |  TrainLoss: 0.00197 | TestLoss: 0.25069 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 623 |  TrainLoss: 0.00195 | TestLoss: 0.25158 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 624 |  TrainLoss: 0.00192 | TestLoss: 0.25191 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 625 |  TrainLoss: 0.00190 | TestLoss: 0.25186 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 626 |  TrainLoss: 0.00188 | TestLoss: 0.25232 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 627 |  TrainLoss: 0.00186 | TestLoss: 0.25301 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 628 |  TrainLoss: 0.00184 | TestLoss: 0.25328 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 629 |  TrainLoss: 0.00182 | TestLoss: 0.25315 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 630 |  TrainLoss: 0.00180 | TestLoss: 0.25339 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 631 |  TrainLoss: 0.00178 | TestLoss: 0.25372 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 632 |  TrainLoss: 0.00177 | TestLoss: 0.25400 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 633 |  TrainLoss: 0.00175 | TestLoss: 0.25419 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 634 |  TrainLoss: 0.00173 | TestLoss: 0.25442 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 635 |  TrainLoss: 0.00171 | TestLoss: 0.25489 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 636 |  TrainLoss: 0.00169 | TestLoss: 0.25508 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 637 |  TrainLoss: 0.00167 | TestLoss: 0.25516 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 638 |  TrainLoss: 0.00166 | TestLoss: 0.25545 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 639 |  TrainLoss: 0.00164 | TestLoss: 0.25561 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 640 |  TrainLoss: 0.00162 | TestLoss: 0.25596 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 641 |  TrainLoss: 0.00161 | TestLoss: 0.25633 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 642 |  TrainLoss: 0.00159 | TestLoss: 0.25660 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 643 |  TrainLoss: 0.00157 | TestLoss: 0.25673 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 644 |  TrainLoss: 0.00156 | TestLoss: 0.25685 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 645 |  TrainLoss: 0.00154 | TestLoss: 0.25742 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 646 |  TrainLoss: 0.00153 | TestLoss: 0.25766 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 647 |  TrainLoss: 0.00151 | TestLoss: 0.25780 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 648 |  TrainLoss: 0.00150 | TestLoss: 0.25833 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 649 |  TrainLoss: 0.00148 | TestLoss: 0.25884 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 650 |  TrainLoss: 0.00147 | TestLoss: 0.25901 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 651 |  TrainLoss: 0.00145 | TestLoss: 0.25909 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 652 |  TrainLoss: 0.00144 | TestLoss: 0.25943 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 653 |  TrainLoss: 0.00142 | TestLoss: 0.25980 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 654 |  TrainLoss: 0.00141 | TestLoss: 0.26012 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 655 |  TrainLoss: 0.00139 | TestLoss: 0.26064 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 656 |  TrainLoss: 0.00138 | TestLoss: 0.26105 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 657 |  TrainLoss: 0.00136 | TestLoss: 0.26121 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 658 |  TrainLoss: 0.00135 | TestLoss: 0.26137 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 659 |  TrainLoss: 0.00134 | TestLoss: 0.26163 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 660 |  TrainLoss: 0.00132 | TestLoss: 0.26222 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 661 |  TrainLoss: 0.00131 | TestLoss: 0.26261 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 662 |  TrainLoss: 0.00130 | TestLoss: 0.26248 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 663 |  TrainLoss: 0.00128 | TestLoss: 0.26280 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 664 |  TrainLoss: 0.00127 | TestLoss: 0.26342 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 665 |  TrainLoss: 0.00126 | TestLoss: 0.26359 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 666 |  TrainLoss: 0.00125 | TestLoss: 0.26341 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 667 |  TrainLoss: 0.00124 | TestLoss: 0.26393 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 668 |  TrainLoss: 0.00122 | TestLoss: 0.26469 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 669 |  TrainLoss: 0.00121 | TestLoss: 0.26465 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 670 |  TrainLoss: 0.00120 | TestLoss: 0.26457 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 671 |  TrainLoss: 0.00119 | TestLoss: 0.26511 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 672 |  TrainLoss: 0.00118 | TestLoss: 0.26565 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 673 |  TrainLoss: 0.00117 | TestLoss: 0.26564 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 674 |  TrainLoss: 0.00115 | TestLoss: 0.26568 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 675 |  TrainLoss: 0.00114 | TestLoss: 0.26636 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 676 |  TrainLoss: 0.00113 | TestLoss: 0.26685 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 677 |  TrainLoss: 0.00112 | TestLoss: 0.26680 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 678 |  TrainLoss: 0.00111 | TestLoss: 0.26690 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 679 |  TrainLoss: 0.00110 | TestLoss: 0.26727 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 680 |  TrainLoss: 0.00109 | TestLoss: 0.26775 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 681 |  TrainLoss: 0.00108 | TestLoss: 0.26813 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 682 |  TrainLoss: 0.00107 | TestLoss: 0.26824 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 683 |  TrainLoss: 0.00106 | TestLoss: 0.26845 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 684 |  TrainLoss: 0.00105 | TestLoss: 0.26874 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 685 |  TrainLoss: 0.00104 | TestLoss: 0.26912 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 686 |  TrainLoss: 0.00103 | TestLoss: 0.26951 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 687 |  TrainLoss: 0.00102 | TestLoss: 0.26976 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 688 |  TrainLoss: 0.00101 | TestLoss: 0.26988 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 689 |  TrainLoss: 0.00100 | TestLoss: 0.27004 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 690 |  TrainLoss: 0.00099 | TestLoss: 0.27055 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 691 |  TrainLoss: 0.00098 | TestLoss: 0.27105 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 692 |  TrainLoss: 0.00098 | TestLoss: 0.27110 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 693 |  TrainLoss: 0.00097 | TestLoss: 0.27134 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 694 |  TrainLoss: 0.00096 | TestLoss: 0.27180 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 695 |  TrainLoss: 0.00095 | TestLoss: 0.27219 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 696 |  TrainLoss: 0.00094 | TestLoss: 0.27222 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 697 |  TrainLoss: 0.00093 | TestLoss: 0.27237 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 698 |  TrainLoss: 0.00093 | TestLoss: 0.27299 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 699 |  TrainLoss: 0.00092 | TestLoss: 0.27346 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 700 |  TrainLoss: 0.00091 | TestLoss: 0.27349 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 701 |  TrainLoss: 0.00090 | TestLoss: 0.27357 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 702 |  TrainLoss: 0.00089 | TestLoss: 0.27393 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 703 |  TrainLoss: 0.00089 | TestLoss: 0.27441 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 704 |  TrainLoss: 0.00088 | TestLoss: 0.27467 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 705 |  TrainLoss: 0.00087 | TestLoss: 0.27473 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 706 |  TrainLoss: 0.00086 | TestLoss: 0.27499 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 707 |  TrainLoss: 0.00086 | TestLoss: 0.27531 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 708 |  TrainLoss: 0.00085 | TestLoss: 0.27559 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 709 |  TrainLoss: 0.00084 | TestLoss: 0.27594 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 710 |  TrainLoss: 0.00083 | TestLoss: 0.27623 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 711 |  TrainLoss: 0.00083 | TestLoss: 0.27649 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 712 |  TrainLoss: 0.00082 | TestLoss: 0.27665 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 713 |  TrainLoss: 0.00081 | TestLoss: 0.27683 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 714 |  TrainLoss: 0.00081 | TestLoss: 0.27728 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 715 |  TrainLoss: 0.00080 | TestLoss: 0.27768 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 716 |  TrainLoss: 0.00079 | TestLoss: 0.27774 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 717 |  TrainLoss: 0.00079 | TestLoss: 0.27771 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 718 |  TrainLoss: 0.00078 | TestLoss: 0.27828 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 719 |  TrainLoss: 0.00077 | TestLoss: 0.27868 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 720 |  TrainLoss: 0.00077 | TestLoss: 0.27884 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 721 |  TrainLoss: 0.00076 | TestLoss: 0.27902 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 722 |  TrainLoss: 0.00076 | TestLoss: 0.27927 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 723 |  TrainLoss: 0.00075 | TestLoss: 0.27942 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 724 |  TrainLoss: 0.00074 | TestLoss: 0.27969 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 725 |  TrainLoss: 0.00074 | TestLoss: 0.28007 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 726 |  TrainLoss: 0.00073 | TestLoss: 0.28046 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 727 |  TrainLoss: 0.00073 | TestLoss: 0.28080 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 728 |  TrainLoss: 0.00072 | TestLoss: 0.28107 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 729 |  TrainLoss: 0.00071 | TestLoss: 0.28130 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 730 |  TrainLoss: 0.00071 | TestLoss: 0.28139 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 731 |  TrainLoss: 0.00070 | TestLoss: 0.28149 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 732 |  TrainLoss: 0.00070 | TestLoss: 0.28191 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 733 |  TrainLoss: 0.00069 | TestLoss: 0.28234 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 734 |  TrainLoss: 0.00069 | TestLoss: 0.28246 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 735 |  TrainLoss: 0.00068 | TestLoss: 0.28232 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 736 |  TrainLoss: 0.00068 | TestLoss: 0.28260 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 737 |  TrainLoss: 0.00067 | TestLoss: 0.28314 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 738 |  TrainLoss: 0.00067 | TestLoss: 0.28341 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 739 |  TrainLoss: 0.00066 | TestLoss: 0.28349 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 740 |  TrainLoss: 0.00066 | TestLoss: 0.28370 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 741 |  TrainLoss: 0.00065 | TestLoss: 0.28408 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 742 |  TrainLoss: 0.00065 | TestLoss: 0.28422 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 743 |  TrainLoss: 0.00064 | TestLoss: 0.28431 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 744 |  TrainLoss: 0.00064 | TestLoss: 0.28457 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 745 |  TrainLoss: 0.00063 | TestLoss: 0.28508 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 746 |  TrainLoss: 0.00063 | TestLoss: 0.28545 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 747 |  TrainLoss: 0.00062 | TestLoss: 0.28543 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 748 |  TrainLoss: 0.00062 | TestLoss: 0.28531 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 749 |  TrainLoss: 0.00061 | TestLoss: 0.28575 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 750 |  TrainLoss: 0.00061 | TestLoss: 0.28633 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 751 |  TrainLoss: 0.00061 | TestLoss: 0.28653 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 752 |  TrainLoss: 0.00060 | TestLoss: 0.28664 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 753 |  TrainLoss: 0.00060 | TestLoss: 0.28688 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 754 |  TrainLoss: 0.00059 | TestLoss: 0.28719 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 755 |  TrainLoss: 0.00059 | TestLoss: 0.28730 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 756 |  TrainLoss: 0.00058 | TestLoss: 0.28741 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 757 |  TrainLoss: 0.00058 | TestLoss: 0.28771 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 758 |  TrainLoss: 0.00058 | TestLoss: 0.28828 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 759 |  TrainLoss: 0.00057 | TestLoss: 0.28850 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 760 |  TrainLoss: 0.00057 | TestLoss: 0.28839 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 761 |  TrainLoss: 0.00056 | TestLoss: 0.28853 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 762 |  TrainLoss: 0.00056 | TestLoss: 0.28889 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 763 |  TrainLoss: 0.00056 | TestLoss: 0.28917 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 764 |  TrainLoss: 0.00055 | TestLoss: 0.28936 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 765 |  TrainLoss: 0.00055 | TestLoss: 0.28963 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 766 |  TrainLoss: 0.00054 | TestLoss: 0.28990 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 767 |  TrainLoss: 0.00054 | TestLoss: 0.29004 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 768 |  TrainLoss: 0.00054 | TestLoss: 0.29010 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 769 |  TrainLoss: 0.00053 | TestLoss: 0.29034 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 770 |  TrainLoss: 0.00053 | TestLoss: 0.29088 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 771 |  TrainLoss: 0.00053 | TestLoss: 0.29121 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 772 |  TrainLoss: 0.00052 | TestLoss: 0.29116 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 773 |  TrainLoss: 0.00052 | TestLoss: 0.29128 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 774 |  TrainLoss: 0.00052 | TestLoss: 0.29165 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 775 |  TrainLoss: 0.00051 | TestLoss: 0.29194 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 776 |  TrainLoss: 0.00051 | TestLoss: 0.29203 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 777 |  TrainLoss: 0.00051 | TestLoss: 0.29225 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 778 |  TrainLoss: 0.00050 | TestLoss: 0.29258 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 779 |  TrainLoss: 0.00050 | TestLoss: 0.29274 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 780 |  TrainLoss: 0.00050 | TestLoss: 0.29287 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 781 |  TrainLoss: 0.00049 | TestLoss: 0.29321 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 782 |  TrainLoss: 0.00049 | TestLoss: 0.29350 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 783 |  TrainLoss: 0.00049 | TestLoss: 0.29362 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 784 |  TrainLoss: 0.00048 | TestLoss: 0.29373 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 785 |  TrainLoss: 0.00048 | TestLoss: 0.29417 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 786 |  TrainLoss: 0.00048 | TestLoss: 0.29451 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 787 |  TrainLoss: 0.00047 | TestLoss: 0.29452 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 788 |  TrainLoss: 0.00047 | TestLoss: 0.29461 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 789 |  TrainLoss: 0.00047 | TestLoss: 0.29497 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 790 |  TrainLoss: 0.00046 | TestLoss: 0.29524 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 791 |  TrainLoss: 0.00046 | TestLoss: 0.29528 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 792 |  TrainLoss: 0.00046 | TestLoss: 0.29551 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 793 |  TrainLoss: 0.00046 | TestLoss: 0.29598 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 794 |  TrainLoss: 0.00045 | TestLoss: 0.29613 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 795 |  TrainLoss: 0.00045 | TestLoss: 0.29611 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 796 |  TrainLoss: 0.00045 | TestLoss: 0.29644 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 797 |  TrainLoss: 0.00044 | TestLoss: 0.29694 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 798 |  TrainLoss: 0.00044 | TestLoss: 0.29709 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 799 |  TrainLoss: 0.00044 | TestLoss: 0.29707 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 800 |  TrainLoss: 0.00044 | TestLoss: 0.29729 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 801 |  TrainLoss: 0.00043 | TestLoss: 0.29768 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 802 |  TrainLoss: 0.00043 | TestLoss: 0.29785 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 803 |  TrainLoss: 0.00043 | TestLoss: 0.29798 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 804 |  TrainLoss: 0.00042 | TestLoss: 0.29813 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 805 |  TrainLoss: 0.00042 | TestLoss: 0.29839 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 806 |  TrainLoss: 0.00042 | TestLoss: 0.29869 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 807 |  TrainLoss: 0.00042 | TestLoss: 0.29896 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 808 |  TrainLoss: 0.00041 | TestLoss: 0.29906 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 809 |  TrainLoss: 0.00041 | TestLoss: 0.29913 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 810 |  TrainLoss: 0.00041 | TestLoss: 0.29941 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 811 |  TrainLoss: 0.00041 | TestLoss: 0.29970 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 812 |  TrainLoss: 0.00040 | TestLoss: 0.30005 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 813 |  TrainLoss: 0.00040 | TestLoss: 0.30027 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 814 |  TrainLoss: 0.00040 | TestLoss: 0.30031 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 815 |  TrainLoss: 0.00040 | TestLoss: 0.30027 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 816 |  TrainLoss: 0.00040 | TestLoss: 0.30044 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 817 |  TrainLoss: 0.00039 | TestLoss: 0.30098 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 818 |  TrainLoss: 0.00039 | TestLoss: 0.30136 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 819 |  TrainLoss: 0.00039 | TestLoss: 0.30155 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 820 |  TrainLoss: 0.00039 | TestLoss: 0.30160 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 821 |  TrainLoss: 0.00038 | TestLoss: 0.30161 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 822 |  TrainLoss: 0.00038 | TestLoss: 0.30172 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 823 |  TrainLoss: 0.00038 | TestLoss: 0.30205 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 824 |  TrainLoss: 0.00038 | TestLoss: 0.30242 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 825 |  TrainLoss: 0.00038 | TestLoss: 0.30264 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 826 |  TrainLoss: 0.00037 | TestLoss: 0.30282 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 827 |  TrainLoss: 0.00037 | TestLoss: 0.30298 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 828 |  TrainLoss: 0.00037 | TestLoss: 0.30318 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 829 |  TrainLoss: 0.00037 | TestLoss: 0.30331 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 830 |  TrainLoss: 0.00036 | TestLoss: 0.30354 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 831 |  TrainLoss: 0.00036 | TestLoss: 0.30378 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 832 |  TrainLoss: 0.00036 | TestLoss: 0.30394 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 833 |  TrainLoss: 0.00036 | TestLoss: 0.30414 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 834 |  TrainLoss: 0.00036 | TestLoss: 0.30440 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 835 |  TrainLoss: 0.00035 | TestLoss: 0.30469 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 836 |  TrainLoss: 0.00035 | TestLoss: 0.30480 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 837 |  TrainLoss: 0.00035 | TestLoss: 0.30479 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 838 |  TrainLoss: 0.00035 | TestLoss: 0.30492 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 839 |  TrainLoss: 0.00035 | TestLoss: 0.30538 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 840 |  TrainLoss: 0.00034 | TestLoss: 0.30573 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 841 |  TrainLoss: 0.00034 | TestLoss: 0.30575 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 842 |  TrainLoss: 0.00034 | TestLoss: 0.30581 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 843 |  TrainLoss: 0.00034 | TestLoss: 0.30602 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 844 |  TrainLoss: 0.00034 | TestLoss: 0.30627 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 845 |  TrainLoss: 0.00034 | TestLoss: 0.30653 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 846 |  TrainLoss: 0.00033 | TestLoss: 0.30673 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 847 |  TrainLoss: 0.00033 | TestLoss: 0.30694 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 848 |  TrainLoss: 0.00033 | TestLoss: 0.30715 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 849 |  TrainLoss: 0.00033 | TestLoss: 0.30728 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 850 |  TrainLoss: 0.00033 | TestLoss: 0.30740 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 851 |  TrainLoss: 0.00032 | TestLoss: 0.30754 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 852 |  TrainLoss: 0.00032 | TestLoss: 0.30787 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 853 |  TrainLoss: 0.00032 | TestLoss: 0.30823 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 854 |  TrainLoss: 0.00032 | TestLoss: 0.30829 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 855 |  TrainLoss: 0.00032 | TestLoss: 0.30823 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 856 |  TrainLoss: 0.00032 | TestLoss: 0.30851 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 857 |  TrainLoss: 0.00031 | TestLoss: 0.30895 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 858 |  TrainLoss: 0.00031 | TestLoss: 0.30907 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 859 |  TrainLoss: 0.00031 | TestLoss: 0.30903 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 860 |  TrainLoss: 0.00031 | TestLoss: 0.30923 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 861 |  TrainLoss: 0.00031 | TestLoss: 0.30972 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 862 |  TrainLoss: 0.00031 | TestLoss: 0.30983 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 863 |  TrainLoss: 0.00030 | TestLoss: 0.30981 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 864 |  TrainLoss: 0.00030 | TestLoss: 0.30996 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 865 |  TrainLoss: 0.00030 | TestLoss: 0.31031 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 866 |  TrainLoss: 0.00030 | TestLoss: 0.31069 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 867 |  TrainLoss: 0.00030 | TestLoss: 0.31070 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 868 |  TrainLoss: 0.00030 | TestLoss: 0.31059 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 869 |  TrainLoss: 0.00030 | TestLoss: 0.31077 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 870 |  TrainLoss: 0.00029 | TestLoss: 0.31132 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 871 |  TrainLoss: 0.00029 | TestLoss: 0.31155 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 872 |  TrainLoss: 0.00029 | TestLoss: 0.31135 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 873 |  TrainLoss: 0.00029 | TestLoss: 0.31137 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 874 |  TrainLoss: 0.00029 | TestLoss: 0.31181 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 875 |  TrainLoss: 0.00029 | TestLoss: 0.31229 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 876 |  TrainLoss: 0.00028 | TestLoss: 0.31234 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 877 |  TrainLoss: 0.00028 | TestLoss: 0.31216 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 878 |  TrainLoss: 0.00028 | TestLoss: 0.31232 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 879 |  TrainLoss: 0.00028 | TestLoss: 0.31282 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 880 |  TrainLoss: 0.00028 | TestLoss: 0.31329 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 881 |  TrainLoss: 0.00028 | TestLoss: 0.31329 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 882 |  TrainLoss: 0.00028 | TestLoss: 0.31315 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 883 |  TrainLoss: 0.00028 | TestLoss: 0.31324 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 884 |  TrainLoss: 0.00027 | TestLoss: 0.31364 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 885 |  TrainLoss: 0.00027 | TestLoss: 0.31409 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 886 |  TrainLoss: 0.00027 | TestLoss: 0.31416 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 887 |  TrainLoss: 0.00027 | TestLoss: 0.31411 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 888 |  TrainLoss: 0.00027 | TestLoss: 0.31435 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 889 |  TrainLoss: 0.00027 | TestLoss: 0.31474 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 890 |  TrainLoss: 0.00027 | TestLoss: 0.31492 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 891 |  TrainLoss: 0.00026 | TestLoss: 0.31487 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 892 |  TrainLoss: 0.00026 | TestLoss: 0.31490 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 893 |  TrainLoss: 0.00026 | TestLoss: 0.31525 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 894 |  TrainLoss: 0.00026 | TestLoss: 0.31570 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 895 |  TrainLoss: 0.00026 | TestLoss: 0.31580 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 896 |  TrainLoss: 0.00026 | TestLoss: 0.31582 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 897 |  TrainLoss: 0.00026 | TestLoss: 0.31594 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 898 |  TrainLoss: 0.00026 | TestLoss: 0.31624 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 899 |  TrainLoss: 0.00025 | TestLoss: 0.31642 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 900 |  TrainLoss: 0.00025 | TestLoss: 0.31656 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 901 |  TrainLoss: 0.00025 | TestLoss: 0.31683 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 902 |  TrainLoss: 0.00025 | TestLoss: 0.31710 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 903 |  TrainLoss: 0.00025 | TestLoss: 0.31726 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 904 |  TrainLoss: 0.00025 | TestLoss: 0.31739 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 905 |  TrainLoss: 0.00025 | TestLoss: 0.31733 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 906 |  TrainLoss: 0.00025 | TestLoss: 0.31732 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 907 |  TrainLoss: 0.00024 | TestLoss: 0.31778 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 908 |  TrainLoss: 0.00024 | TestLoss: 0.31835 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 909 |  TrainLoss: 0.00024 | TestLoss: 0.31865 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 910 |  TrainLoss: 0.00024 | TestLoss: 0.31842 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 911 |  TrainLoss: 0.00024 | TestLoss: 0.31821 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 912 |  TrainLoss: 0.00024 | TestLoss: 0.31839 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 913 |  TrainLoss: 0.00024 | TestLoss: 0.31877 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 914 |  TrainLoss: 0.00024 | TestLoss: 0.31928 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 915 |  TrainLoss: 0.00024 | TestLoss: 0.31948 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 916 |  TrainLoss: 0.00023 | TestLoss: 0.31952 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 917 |  TrainLoss: 0.00023 | TestLoss: 0.31954 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 918 |  TrainLoss: 0.00023 | TestLoss: 0.31966 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 919 |  TrainLoss: 0.00023 | TestLoss: 0.31997 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 920 |  TrainLoss: 0.00023 | TestLoss: 0.32014 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 921 |  TrainLoss: 0.00023 | TestLoss: 0.32017 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 922 |  TrainLoss: 0.00023 | TestLoss: 0.32018 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 923 |  TrainLoss: 0.00023 | TestLoss: 0.32051 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 924 |  TrainLoss: 0.00023 | TestLoss: 0.32104 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 925 |  TrainLoss: 0.00023 | TestLoss: 0.32146 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 926 |  TrainLoss: 0.00022 | TestLoss: 0.32157 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 927 |  TrainLoss: 0.00022 | TestLoss: 0.32141 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 928 |  TrainLoss: 0.00022 | TestLoss: 0.32111 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 929 |  TrainLoss: 0.00022 | TestLoss: 0.32131 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 930 |  TrainLoss: 0.00022 | TestLoss: 0.32166 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 931 |  TrainLoss: 0.00022 | TestLoss: 0.32215 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 932 |  TrainLoss: 0.00022 | TestLoss: 0.32238 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 933 |  TrainLoss: 0.00022 | TestLoss: 0.32251 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 934 |  TrainLoss: 0.00022 | TestLoss: 0.32249 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 935 |  TrainLoss: 0.00022 | TestLoss: 0.32256 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 936 |  TrainLoss: 0.00021 | TestLoss: 0.32283 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 937 |  TrainLoss: 0.00021 | TestLoss: 0.32299 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 938 |  TrainLoss: 0.00021 | TestLoss: 0.32306 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 939 |  TrainLoss: 0.00021 | TestLoss: 0.32323 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 940 |  TrainLoss: 0.00021 | TestLoss: 0.32348 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 941 |  TrainLoss: 0.00021 | TestLoss: 0.32369 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 942 |  TrainLoss: 0.00021 | TestLoss: 0.32371 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 943 |  TrainLoss: 0.00021 | TestLoss: 0.32380 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 944 |  TrainLoss: 0.00021 | TestLoss: 0.32402 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 945 |  TrainLoss: 0.00021 | TestLoss: 0.32427 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 946 |  TrainLoss: 0.00021 | TestLoss: 0.32433 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 947 |  TrainLoss: 0.00020 | TestLoss: 0.32444 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 948 |  TrainLoss: 0.00020 | TestLoss: 0.32461 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 949 |  TrainLoss: 0.00020 | TestLoss: 0.32468 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 950 |  TrainLoss: 0.00020 | TestLoss: 0.32491 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 951 |  TrainLoss: 0.00020 | TestLoss: 0.32519 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 952 |  TrainLoss: 0.00020 | TestLoss: 0.32530 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 953 |  TrainLoss: 0.00020 | TestLoss: 0.32536 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 954 |  TrainLoss: 0.00020 | TestLoss: 0.32530 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 955 |  TrainLoss: 0.00020 | TestLoss: 0.32552 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 956 |  TrainLoss: 0.00020 | TestLoss: 0.32591 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 957 |  TrainLoss: 0.00020 | TestLoss: 0.32604 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 958 |  TrainLoss: 0.00019 | TestLoss: 0.32600 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 959 |  TrainLoss: 0.00019 | TestLoss: 0.32610 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 960 |  TrainLoss: 0.00019 | TestLoss: 0.32641 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 961 |  TrainLoss: 0.00019 | TestLoss: 0.32671 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 962 |  TrainLoss: 0.00019 | TestLoss: 0.32669 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 963 |  TrainLoss: 0.00019 | TestLoss: 0.32653 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 964 |  TrainLoss: 0.00019 | TestLoss: 0.32666 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 965 |  TrainLoss: 0.00019 | TestLoss: 0.32710 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 966 |  TrainLoss: 0.00019 | TestLoss: 0.32754 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 967 |  TrainLoss: 0.00019 | TestLoss: 0.32759 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 968 |  TrainLoss: 0.00019 | TestLoss: 0.32735 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 969 |  TrainLoss: 0.00019 | TestLoss: 0.32731 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 970 |  TrainLoss: 0.00019 | TestLoss: 0.32763 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 971 |  TrainLoss: 0.00018 | TestLoss: 0.32808 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 972 |  TrainLoss: 0.00018 | TestLoss: 0.32839 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 973 |  TrainLoss: 0.00018 | TestLoss: 0.32831 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 974 |  TrainLoss: 0.00018 | TestLoss: 0.32807 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 975 |  TrainLoss: 0.00018 | TestLoss: 0.32818 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 976 |  TrainLoss: 0.00018 | TestLoss: 0.32861 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 977 |  TrainLoss: 0.00018 | TestLoss: 0.32904 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 978 |  TrainLoss: 0.00018 | TestLoss: 0.32913 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 979 |  TrainLoss: 0.00018 | TestLoss: 0.32898 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 980 |  TrainLoss: 0.00018 | TestLoss: 0.32901 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 981 |  TrainLoss: 0.00018 | TestLoss: 0.32923 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 982 |  TrainLoss: 0.00018 | TestLoss: 0.32956 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 983 |  TrainLoss: 0.00018 | TestLoss: 0.32983 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 984 |  TrainLoss: 0.00018 | TestLoss: 0.32983 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 985 |  TrainLoss: 0.00017 | TestLoss: 0.32969 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 986 |  TrainLoss: 0.00017 | TestLoss: 0.32966 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 987 |  TrainLoss: 0.00017 | TestLoss: 0.32995 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 988 |  TrainLoss: 0.00017 | TestLoss: 0.33042 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 989 |  TrainLoss: 0.00017 | TestLoss: 0.33083 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 990 |  TrainLoss: 0.00017 | TestLoss: 0.33086 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 991 |  TrainLoss: 0.00017 | TestLoss: 0.33056 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 992 |  TrainLoss: 0.00017 | TestLoss: 0.33049 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 993 |  TrainLoss: 0.00017 | TestLoss: 0.33083 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 994 |  TrainLoss: 0.00017 | TestLoss: 0.33130 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 995 |  TrainLoss: 0.00017 | TestLoss: 0.33148 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 996 |  TrainLoss: 0.00017 | TestLoss: 0.33141 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 997 |  TrainLoss: 0.00017 | TestLoss: 0.33143 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 998 |  TrainLoss: 0.00017 | TestLoss: 0.33154 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 999 |  TrainLoss: 0.00017 | TestLoss: 0.33179 | TestAcc: 0.91935 | TestF1: 0.91\n"
          ]
        }
      ],
      "source": [
        "wloss = []\n",
        "weighted_loss = 0\n",
        "exp_param = 0.8\n",
        "\n",
        "# without droupout training results\n",
        "for epoch in range(400):\n",
        "  train_loss = train(epoch)\n",
        "  test_loss, test_acc, test_f1 = test(epoch)\n",
        "  # weighted_loss = exp_param*(weighted_loss) + (1-exp_param)*(test_loss/ len(test_loader.dataset))\n",
        "\n",
        "  # wloss.append(weighted_loss/(1-exp_param**(epoch+1)))\n",
        "\n",
        "  # if(epoch-20>=0 and wloss[epoch-6]-weighted_loss<0.01):\n",
        "  #     print(\"Stopped Early at Epoch {} \".format(epoch))\n",
        "  #     break\n",
        "\n",
        "  print(f'Epoch: {epoch:02d} |  TrainLoss: {train_loss:.5f} | '\n",
        "          f'TestLoss: {test_loss:.5f} | TestAcc: {test_acc:.5f} | TestF1: {test_f1:.2f}')\n",
        "  # print(f'Epoch: {epoch:02d} |  TrainLoss: {train_loss:.7f} |')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 00 |  TrainLoss: 0.69276 | TestLoss: 0.69571 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 01 |  TrainLoss: 0.69269 | TestLoss: 0.69619 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 02 |  TrainLoss: 0.69241 | TestLoss: 0.69650 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 03 |  TrainLoss: 0.69252 | TestLoss: 0.69683 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 04 |  TrainLoss: 0.69255 | TestLoss: 0.69714 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 05 |  TrainLoss: 0.69178 | TestLoss: 0.69732 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 06 |  TrainLoss: 0.69160 | TestLoss: 0.69748 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 07 |  TrainLoss: 0.69170 | TestLoss: 0.69760 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 08 |  TrainLoss: 0.69190 | TestLoss: 0.69766 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 09 |  TrainLoss: 0.69116 | TestLoss: 0.69776 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 10 |  TrainLoss: 0.69074 | TestLoss: 0.69794 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 11 |  TrainLoss: 0.69153 | TestLoss: 0.69805 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 12 |  TrainLoss: 0.69076 | TestLoss: 0.69804 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 13 |  TrainLoss: 0.69054 | TestLoss: 0.69798 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 14 |  TrainLoss: 0.69026 | TestLoss: 0.69806 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 15 |  TrainLoss: 0.69024 | TestLoss: 0.69818 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 16 |  TrainLoss: 0.68958 | TestLoss: 0.69812 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 17 |  TrainLoss: 0.69025 | TestLoss: 0.69794 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 18 |  TrainLoss: 0.68908 | TestLoss: 0.69764 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 19 |  TrainLoss: 0.68913 | TestLoss: 0.69760 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 20 |  TrainLoss: 0.68939 | TestLoss: 0.69753 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 21 |  TrainLoss: 0.68807 | TestLoss: 0.69727 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 22 |  TrainLoss: 0.68722 | TestLoss: 0.69683 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 23 |  TrainLoss: 0.68738 | TestLoss: 0.69676 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 24 |  TrainLoss: 0.68652 | TestLoss: 0.69658 | TestAcc: 0.41935 | TestF1: 0.59\n",
            "Epoch: 25 |  TrainLoss: 0.68536 | TestLoss: 0.69625 | TestAcc: 0.45161 | TestF1: 0.60\n",
            "Epoch: 26 |  TrainLoss: 0.68465 | TestLoss: 0.69564 | TestAcc: 0.53226 | TestF1: 0.64\n",
            "Epoch: 27 |  TrainLoss: 0.68422 | TestLoss: 0.69506 | TestAcc: 0.53226 | TestF1: 0.64\n",
            "Epoch: 28 |  TrainLoss: 0.68277 | TestLoss: 0.69488 | TestAcc: 0.54839 | TestF1: 0.65\n",
            "Epoch: 29 |  TrainLoss: 0.68100 | TestLoss: 0.69454 | TestAcc: 0.54839 | TestF1: 0.64\n",
            "Epoch: 30 |  TrainLoss: 0.68194 | TestLoss: 0.69355 | TestAcc: 0.51613 | TestF1: 0.61\n",
            "Epoch: 31 |  TrainLoss: 0.68016 | TestLoss: 0.69267 | TestAcc: 0.53226 | TestF1: 0.61\n",
            "Epoch: 32 |  TrainLoss: 0.67841 | TestLoss: 0.69093 | TestAcc: 0.51613 | TestF1: 0.58\n",
            "Epoch: 33 |  TrainLoss: 0.67622 | TestLoss: 0.69116 | TestAcc: 0.53226 | TestF1: 0.61\n",
            "Epoch: 34 |  TrainLoss: 0.67545 | TestLoss: 0.68970 | TestAcc: 0.53226 | TestF1: 0.60\n",
            "Epoch: 35 |  TrainLoss: 0.67179 | TestLoss: 0.68612 | TestAcc: 0.48387 | TestF1: 0.54\n",
            "Epoch: 36 |  TrainLoss: 0.66908 | TestLoss: 0.68712 | TestAcc: 0.53226 | TestF1: 0.60\n",
            "Epoch: 37 |  TrainLoss: 0.66791 | TestLoss: 0.68422 | TestAcc: 0.51613 | TestF1: 0.58\n",
            "Epoch: 38 |  TrainLoss: 0.66386 | TestLoss: 0.67902 | TestAcc: 0.48387 | TestF1: 0.53\n",
            "Epoch: 39 |  TrainLoss: 0.66163 | TestLoss: 0.68148 | TestAcc: 0.56452 | TestF1: 0.63\n",
            "Epoch: 40 |  TrainLoss: 0.65870 | TestLoss: 0.67704 | TestAcc: 0.54839 | TestF1: 0.61\n",
            "Epoch: 41 |  TrainLoss: 0.65290 | TestLoss: 0.66758 | TestAcc: 0.59677 | TestF1: 0.59\n",
            "Epoch: 42 |  TrainLoss: 0.65045 | TestLoss: 0.67192 | TestAcc: 0.54839 | TestF1: 0.62\n",
            "Epoch: 43 |  TrainLoss: 0.64435 | TestLoss: 0.66063 | TestAcc: 0.64516 | TestF1: 0.66\n",
            "Epoch: 44 |  TrainLoss: 0.64076 | TestLoss: 0.65613 | TestAcc: 0.64516 | TestF1: 0.66\n",
            "Epoch: 45 |  TrainLoss: 0.63012 | TestLoss: 0.66029 | TestAcc: 0.58065 | TestF1: 0.64\n",
            "Epoch: 46 |  TrainLoss: 0.62927 | TestLoss: 0.63939 | TestAcc: 0.70968 | TestF1: 0.68\n",
            "Epoch: 47 |  TrainLoss: 0.62040 | TestLoss: 0.64704 | TestAcc: 0.64516 | TestF1: 0.68\n",
            "Epoch: 48 |  TrainLoss: 0.61438 | TestLoss: 0.63214 | TestAcc: 0.69355 | TestF1: 0.70\n",
            "Epoch: 49 |  TrainLoss: 0.60593 | TestLoss: 0.62014 | TestAcc: 0.72581 | TestF1: 0.71\n",
            "Epoch: 50 |  TrainLoss: 0.59759 | TestLoss: 0.63616 | TestAcc: 0.64516 | TestF1: 0.69\n",
            "Epoch: 51 |  TrainLoss: 0.59039 | TestLoss: 0.59929 | TestAcc: 0.74194 | TestF1: 0.71\n",
            "Epoch: 52 |  TrainLoss: 0.58422 | TestLoss: 0.59854 | TestAcc: 0.74194 | TestF1: 0.73\n",
            "Epoch: 53 |  TrainLoss: 0.56600 | TestLoss: 0.61562 | TestAcc: 0.66129 | TestF1: 0.70\n",
            "Epoch: 54 |  TrainLoss: 0.55712 | TestLoss: 0.56897 | TestAcc: 0.79032 | TestF1: 0.72\n",
            "Epoch: 55 |  TrainLoss: 0.55325 | TestLoss: 0.57538 | TestAcc: 0.72581 | TestF1: 0.73\n",
            "Epoch: 56 |  TrainLoss: 0.54290 | TestLoss: 0.57942 | TestAcc: 0.66129 | TestF1: 0.69\n",
            "Epoch: 57 |  TrainLoss: 0.53144 | TestLoss: 0.53791 | TestAcc: 0.82258 | TestF1: 0.78\n",
            "Epoch: 58 |  TrainLoss: 0.52979 | TestLoss: 0.54684 | TestAcc: 0.74194 | TestF1: 0.74\n",
            "Epoch: 59 |  TrainLoss: 0.50510 | TestLoss: 0.53685 | TestAcc: 0.72581 | TestF1: 0.73\n",
            "Epoch: 60 |  TrainLoss: 0.49407 | TestLoss: 0.50412 | TestAcc: 0.80645 | TestF1: 0.77\n",
            "Epoch: 61 |  TrainLoss: 0.48977 | TestLoss: 0.52786 | TestAcc: 0.70968 | TestF1: 0.72\n",
            "Epoch: 62 |  TrainLoss: 0.47865 | TestLoss: 0.48645 | TestAcc: 0.82258 | TestF1: 0.80\n",
            "Epoch: 63 |  TrainLoss: 0.45212 | TestLoss: 0.46791 | TestAcc: 0.80645 | TestF1: 0.77\n",
            "Epoch: 64 |  TrainLoss: 0.45414 | TestLoss: 0.51604 | TestAcc: 0.72581 | TestF1: 0.75\n",
            "Epoch: 65 |  TrainLoss: 0.46037 | TestLoss: 0.44672 | TestAcc: 0.85484 | TestF1: 0.81\n",
            "Epoch: 66 |  TrainLoss: 0.45284 | TestLoss: 0.46849 | TestAcc: 0.77419 | TestF1: 0.77\n",
            "Epoch: 67 |  TrainLoss: 0.42979 | TestLoss: 0.43792 | TestAcc: 0.79032 | TestF1: 0.77\n",
            "Epoch: 68 |  TrainLoss: 0.41183 | TestLoss: 0.41284 | TestAcc: 0.87097 | TestF1: 0.83\n",
            "Epoch: 69 |  TrainLoss: 0.42077 | TestLoss: 0.48140 | TestAcc: 0.75806 | TestF1: 0.78\n",
            "Epoch: 70 |  TrainLoss: 0.41525 | TestLoss: 0.39021 | TestAcc: 0.80645 | TestF1: 0.78\n",
            "Epoch: 71 |  TrainLoss: 0.37946 | TestLoss: 0.37961 | TestAcc: 0.87097 | TestF1: 0.83\n",
            "Epoch: 72 |  TrainLoss: 0.37483 | TestLoss: 0.45505 | TestAcc: 0.75806 | TestF1: 0.78\n",
            "Epoch: 73 |  TrainLoss: 0.40194 | TestLoss: 0.36191 | TestAcc: 0.88710 | TestF1: 0.86\n",
            "Epoch: 74 |  TrainLoss: 0.36942 | TestLoss: 0.35393 | TestAcc: 0.82258 | TestF1: 0.79\n",
            "Epoch: 75 |  TrainLoss: 0.35363 | TestLoss: 0.45066 | TestAcc: 0.75806 | TestF1: 0.78\n",
            "Epoch: 76 |  TrainLoss: 0.38062 | TestLoss: 0.33908 | TestAcc: 0.87097 | TestF1: 0.84\n",
            "Epoch: 77 |  TrainLoss: 0.34914 | TestLoss: 0.33242 | TestAcc: 0.87097 | TestF1: 0.84\n",
            "Epoch: 78 |  TrainLoss: 0.34036 | TestLoss: 0.40707 | TestAcc: 0.85484 | TestF1: 0.85\n",
            "Epoch: 79 |  TrainLoss: 0.36349 | TestLoss: 0.32189 | TestAcc: 0.82258 | TestF1: 0.79\n",
            "Epoch: 80 |  TrainLoss: 0.32313 | TestLoss: 0.31404 | TestAcc: 0.87097 | TestF1: 0.84\n",
            "Epoch: 81 |  TrainLoss: 0.31509 | TestLoss: 0.36039 | TestAcc: 0.83871 | TestF1: 0.83\n",
            "Epoch: 82 |  TrainLoss: 0.32426 | TestLoss: 0.30990 | TestAcc: 0.80645 | TestF1: 0.79\n",
            "Epoch: 83 |  TrainLoss: 0.30011 | TestLoss: 0.29781 | TestAcc: 0.87097 | TestF1: 0.84\n",
            "Epoch: 84 |  TrainLoss: 0.30976 | TestLoss: 0.35258 | TestAcc: 0.83871 | TestF1: 0.83\n",
            "Epoch: 85 |  TrainLoss: 0.32835 | TestLoss: 0.28932 | TestAcc: 0.87097 | TestF1: 0.84\n",
            "Epoch: 86 |  TrainLoss: 0.29241 | TestLoss: 0.30939 | TestAcc: 0.82258 | TestF1: 0.81\n",
            "Epoch: 87 |  TrainLoss: 0.29706 | TestLoss: 0.28598 | TestAcc: 0.83871 | TestF1: 0.81\n",
            "Epoch: 88 |  TrainLoss: 0.29572 | TestLoss: 0.27790 | TestAcc: 0.87097 | TestF1: 0.85\n",
            "Epoch: 89 |  TrainLoss: 0.27772 | TestLoss: 0.30466 | TestAcc: 0.83871 | TestF1: 0.83\n",
            "Epoch: 90 |  TrainLoss: 0.28735 | TestLoss: 0.27035 | TestAcc: 0.87097 | TestF1: 0.85\n",
            "Epoch: 91 |  TrainLoss: 0.30673 | TestLoss: 0.27278 | TestAcc: 0.83871 | TestF1: 0.81\n",
            "Epoch: 92 |  TrainLoss: 0.26619 | TestLoss: 0.28783 | TestAcc: 0.83871 | TestF1: 0.82\n",
            "Epoch: 93 |  TrainLoss: 0.25356 | TestLoss: 0.26109 | TestAcc: 0.87097 | TestF1: 0.85\n",
            "Epoch: 94 |  TrainLoss: 0.28011 | TestLoss: 0.27962 | TestAcc: 0.83871 | TestF1: 0.82\n",
            "Epoch: 95 |  TrainLoss: 0.25237 | TestLoss: 0.25853 | TestAcc: 0.87097 | TestF1: 0.85\n",
            "Epoch: 96 |  TrainLoss: 0.26054 | TestLoss: 0.26246 | TestAcc: 0.85484 | TestF1: 0.84\n",
            "Epoch: 97 |  TrainLoss: 0.26183 | TestLoss: 0.26573 | TestAcc: 0.85484 | TestF1: 0.84\n",
            "Epoch: 98 |  TrainLoss: 0.25453 | TestLoss: 0.24934 | TestAcc: 0.87097 | TestF1: 0.85\n",
            "Epoch: 99 |  TrainLoss: 0.25486 | TestLoss: 0.27856 | TestAcc: 0.85484 | TestF1: 0.84\n",
            "Epoch: 100 |  TrainLoss: 0.24227 | TestLoss: 0.27196 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 101 |  TrainLoss: 0.29852 | TestLoss: 0.52357 | TestAcc: 0.74194 | TestF1: 0.76\n",
            "Epoch: 102 |  TrainLoss: 0.42428 | TestLoss: 0.27327 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 103 |  TrainLoss: 0.28725 | TestLoss: 0.24760 | TestAcc: 0.88710 | TestF1: 0.86\n",
            "Epoch: 104 |  TrainLoss: 0.25137 | TestLoss: 0.42258 | TestAcc: 0.82258 | TestF1: 0.83\n",
            "Epoch: 105 |  TrainLoss: 0.33494 | TestLoss: 0.24572 | TestAcc: 0.87097 | TestF1: 0.85\n",
            "Epoch: 106 |  TrainLoss: 0.21955 | TestLoss: 0.29941 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 107 |  TrainLoss: 0.32315 | TestLoss: 0.31303 | TestAcc: 0.83871 | TestF1: 0.83\n",
            "Epoch: 108 |  TrainLoss: 0.28139 | TestLoss: 0.29780 | TestAcc: 0.83871 | TestF1: 0.83\n",
            "Epoch: 109 |  TrainLoss: 0.24083 | TestLoss: 0.25282 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 110 |  TrainLoss: 0.24906 | TestLoss: 0.23987 | TestAcc: 0.88710 | TestF1: 0.86\n",
            "Epoch: 111 |  TrainLoss: 0.24078 | TestLoss: 0.31021 | TestAcc: 0.83871 | TestF1: 0.83\n",
            "Epoch: 112 |  TrainLoss: 0.27350 | TestLoss: 0.24982 | TestAcc: 0.85484 | TestF1: 0.84\n",
            "Epoch: 113 |  TrainLoss: 0.22050 | TestLoss: 0.25931 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 114 |  TrainLoss: 0.26104 | TestLoss: 0.23845 | TestAcc: 0.88710 | TestF1: 0.87\n",
            "Epoch: 115 |  TrainLoss: 0.21705 | TestLoss: 0.30510 | TestAcc: 0.83871 | TestF1: 0.83\n",
            "Epoch: 116 |  TrainLoss: 0.23256 | TestLoss: 0.23984 | TestAcc: 0.87097 | TestF1: 0.85\n",
            "Epoch: 117 |  TrainLoss: 0.20757 | TestLoss: 0.24424 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 118 |  TrainLoss: 0.22204 | TestLoss: 0.24726 | TestAcc: 0.88710 | TestF1: 0.87\n",
            "Epoch: 119 |  TrainLoss: 0.20943 | TestLoss: 0.26748 | TestAcc: 0.87097 | TestF1: 0.86\n",
            "Epoch: 120 |  TrainLoss: 0.23101 | TestLoss: 0.23302 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 121 |  TrainLoss: 0.21113 | TestLoss: 0.23135 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 122 |  TrainLoss: 0.19824 | TestLoss: 0.25791 | TestAcc: 0.87097 | TestF1: 0.86\n",
            "Epoch: 123 |  TrainLoss: 0.21059 | TestLoss: 0.23560 | TestAcc: 0.88710 | TestF1: 0.87\n",
            "Epoch: 124 |  TrainLoss: 0.21772 | TestLoss: 0.23527 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 125 |  TrainLoss: 0.23172 | TestLoss: 0.24329 | TestAcc: 0.88710 | TestF1: 0.87\n",
            "Epoch: 126 |  TrainLoss: 0.21667 | TestLoss: 0.24824 | TestAcc: 0.88710 | TestF1: 0.87\n",
            "Epoch: 127 |  TrainLoss: 0.21250 | TestLoss: 0.22868 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 128 |  TrainLoss: 0.20023 | TestLoss: 0.22975 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 129 |  TrainLoss: 0.19878 | TestLoss: 0.23377 | TestAcc: 0.87097 | TestF1: 0.85\n",
            "Epoch: 130 |  TrainLoss: 0.20277 | TestLoss: 0.23223 | TestAcc: 0.88710 | TestF1: 0.87\n",
            "Epoch: 131 |  TrainLoss: 0.19833 | TestLoss: 0.22681 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 132 |  TrainLoss: 0.19951 | TestLoss: 0.23076 | TestAcc: 0.88710 | TestF1: 0.87\n",
            "Epoch: 133 |  TrainLoss: 0.19397 | TestLoss: 0.23385 | TestAcc: 0.88710 | TestF1: 0.87\n",
            "Epoch: 134 |  TrainLoss: 0.19650 | TestLoss: 0.22587 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 135 |  TrainLoss: 0.19533 | TestLoss: 0.22543 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 136 |  TrainLoss: 0.19972 | TestLoss: 0.23498 | TestAcc: 0.88710 | TestF1: 0.87\n",
            "Epoch: 137 |  TrainLoss: 0.20265 | TestLoss: 0.22427 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 138 |  TrainLoss: 0.19946 | TestLoss: 0.22371 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 139 |  TrainLoss: 0.19740 | TestLoss: 0.23567 | TestAcc: 0.88710 | TestF1: 0.87\n",
            "Epoch: 140 |  TrainLoss: 0.18324 | TestLoss: 0.22413 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 141 |  TrainLoss: 0.19772 | TestLoss: 0.22270 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 142 |  TrainLoss: 0.19376 | TestLoss: 0.22957 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 143 |  TrainLoss: 0.19444 | TestLoss: 0.22529 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 144 |  TrainLoss: 0.18387 | TestLoss: 0.22142 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 145 |  TrainLoss: 0.17923 | TestLoss: 0.23208 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 146 |  TrainLoss: 0.18052 | TestLoss: 0.22015 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 147 |  TrainLoss: 0.17323 | TestLoss: 0.22246 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 148 |  TrainLoss: 0.17384 | TestLoss: 0.23321 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 149 |  TrainLoss: 0.17648 | TestLoss: 0.21927 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 150 |  TrainLoss: 0.17919 | TestLoss: 0.22172 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 151 |  TrainLoss: 0.16645 | TestLoss: 0.22556 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 152 |  TrainLoss: 0.17767 | TestLoss: 0.21940 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 153 |  TrainLoss: 0.17297 | TestLoss: 0.22115 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 154 |  TrainLoss: 0.18081 | TestLoss: 0.21891 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 155 |  TrainLoss: 0.15447 | TestLoss: 0.22146 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 156 |  TrainLoss: 0.16178 | TestLoss: 0.21764 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 157 |  TrainLoss: 0.16602 | TestLoss: 0.23716 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 158 |  TrainLoss: 0.16959 | TestLoss: 0.21694 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 159 |  TrainLoss: 0.16850 | TestLoss: 0.21655 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 160 |  TrainLoss: 0.15534 | TestLoss: 0.24241 | TestAcc: 0.88710 | TestF1: 0.87\n",
            "Epoch: 161 |  TrainLoss: 0.17215 | TestLoss: 0.22989 | TestAcc: 0.91935 | TestF1: 0.90\n",
            "Epoch: 162 |  TrainLoss: 0.18149 | TestLoss: 0.23026 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 163 |  TrainLoss: 0.15785 | TestLoss: 0.22328 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 164 |  TrainLoss: 0.15158 | TestLoss: 0.22225 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 165 |  TrainLoss: 0.16303 | TestLoss: 0.24391 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 166 |  TrainLoss: 0.16031 | TestLoss: 0.21821 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 167 |  TrainLoss: 0.15722 | TestLoss: 0.22560 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 168 |  TrainLoss: 0.15680 | TestLoss: 0.21858 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 169 |  TrainLoss: 0.15111 | TestLoss: 0.22414 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 170 |  TrainLoss: 0.16156 | TestLoss: 0.25641 | TestAcc: 0.88710 | TestF1: 0.87\n",
            "Epoch: 171 |  TrainLoss: 0.15688 | TestLoss: 0.21622 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 172 |  TrainLoss: 0.15197 | TestLoss: 0.21468 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 173 |  TrainLoss: 0.14218 | TestLoss: 0.23395 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 174 |  TrainLoss: 0.14585 | TestLoss: 0.22088 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 175 |  TrainLoss: 0.15085 | TestLoss: 0.23694 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 176 |  TrainLoss: 0.14931 | TestLoss: 0.21866 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 177 |  TrainLoss: 0.14768 | TestLoss: 0.23701 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 178 |  TrainLoss: 0.15158 | TestLoss: 0.21687 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 179 |  TrainLoss: 0.15746 | TestLoss: 0.22885 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 180 |  TrainLoss: 0.14275 | TestLoss: 0.21540 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 181 |  TrainLoss: 0.13577 | TestLoss: 0.21583 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 182 |  TrainLoss: 0.14750 | TestLoss: 0.24768 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 183 |  TrainLoss: 0.15289 | TestLoss: 0.22613 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 184 |  TrainLoss: 0.14767 | TestLoss: 0.22264 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 185 |  TrainLoss: 0.12700 | TestLoss: 0.21941 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 186 |  TrainLoss: 0.13142 | TestLoss: 0.21518 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 187 |  TrainLoss: 0.14157 | TestLoss: 0.22548 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 188 |  TrainLoss: 0.12593 | TestLoss: 0.21523 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 189 |  TrainLoss: 0.13431 | TestLoss: 0.22455 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 190 |  TrainLoss: 0.12328 | TestLoss: 0.21479 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 191 |  TrainLoss: 0.12306 | TestLoss: 0.21436 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 192 |  TrainLoss: 0.12441 | TestLoss: 0.24652 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 193 |  TrainLoss: 0.14448 | TestLoss: 0.24646 | TestAcc: 0.91935 | TestF1: 0.90\n",
            "Epoch: 194 |  TrainLoss: 0.18118 | TestLoss: 0.37601 | TestAcc: 0.83871 | TestF1: 0.83\n",
            "Epoch: 195 |  TrainLoss: 0.25431 | TestLoss: 0.33951 | TestAcc: 0.88710 | TestF1: 0.85\n",
            "Epoch: 196 |  TrainLoss: 0.24894 | TestLoss: 0.31542 | TestAcc: 0.88710 | TestF1: 0.88\n",
            "Epoch: 197 |  TrainLoss: 0.18434 | TestLoss: 0.23316 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 198 |  TrainLoss: 0.11844 | TestLoss: 0.29620 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 199 |  TrainLoss: 0.21696 | TestLoss: 0.28189 | TestAcc: 0.88710 | TestF1: 0.87\n",
            "Epoch: 200 |  TrainLoss: 0.15288 | TestLoss: 0.25250 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 201 |  TrainLoss: 0.13603 | TestLoss: 0.32031 | TestAcc: 0.88710 | TestF1: 0.85\n",
            "Epoch: 202 |  TrainLoss: 0.24262 | TestLoss: 0.27248 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 203 |  TrainLoss: 0.15569 | TestLoss: 0.26705 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 204 |  TrainLoss: 0.14838 | TestLoss: 0.26293 | TestAcc: 0.91935 | TestF1: 0.90\n",
            "Epoch: 205 |  TrainLoss: 0.17584 | TestLoss: 0.21528 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 206 |  TrainLoss: 0.12106 | TestLoss: 0.32447 | TestAcc: 0.88710 | TestF1: 0.88\n",
            "Epoch: 207 |  TrainLoss: 0.19534 | TestLoss: 0.22637 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 208 |  TrainLoss: 0.13571 | TestLoss: 0.24448 | TestAcc: 0.91935 | TestF1: 0.90\n",
            "Epoch: 209 |  TrainLoss: 0.16383 | TestLoss: 0.32629 | TestAcc: 0.88710 | TestF1: 0.88\n",
            "Epoch: 210 |  TrainLoss: 0.18399 | TestLoss: 0.23344 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 211 |  TrainLoss: 0.11591 | TestLoss: 0.27303 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 212 |  TrainLoss: 0.19059 | TestLoss: 0.22385 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 213 |  TrainLoss: 0.11603 | TestLoss: 0.28362 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 214 |  TrainLoss: 0.16235 | TestLoss: 0.22426 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 215 |  TrainLoss: 0.12460 | TestLoss: 0.22274 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 216 |  TrainLoss: 0.11845 | TestLoss: 0.26249 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 217 |  TrainLoss: 0.13375 | TestLoss: 0.22999 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 218 |  TrainLoss: 0.12451 | TestLoss: 0.24581 | TestAcc: 0.91935 | TestF1: 0.90\n",
            "Epoch: 219 |  TrainLoss: 0.14961 | TestLoss: 0.21429 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 220 |  TrainLoss: 0.10867 | TestLoss: 0.24763 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 221 |  TrainLoss: 0.13083 | TestLoss: 0.21602 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 222 |  TrainLoss: 0.10488 | TestLoss: 0.22197 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 223 |  TrainLoss: 0.10296 | TestLoss: 0.21959 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 224 |  TrainLoss: 0.09430 | TestLoss: 0.23705 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 225 |  TrainLoss: 0.09967 | TestLoss: 0.21486 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 226 |  TrainLoss: 0.10301 | TestLoss: 0.21921 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 227 |  TrainLoss: 0.12179 | TestLoss: 0.23890 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 228 |  TrainLoss: 0.11362 | TestLoss: 0.22020 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 229 |  TrainLoss: 0.10511 | TestLoss: 0.21763 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 230 |  TrainLoss: 0.09536 | TestLoss: 0.21871 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 231 |  TrainLoss: 0.09341 | TestLoss: 0.22240 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 232 |  TrainLoss: 0.09142 | TestLoss: 0.21692 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 233 |  TrainLoss: 0.09101 | TestLoss: 0.21696 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 234 |  TrainLoss: 0.09206 | TestLoss: 0.22507 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 235 |  TrainLoss: 0.10577 | TestLoss: 0.22037 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 236 |  TrainLoss: 0.10067 | TestLoss: 0.21860 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 237 |  TrainLoss: 0.09740 | TestLoss: 0.22114 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 238 |  TrainLoss: 0.08541 | TestLoss: 0.22874 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 239 |  TrainLoss: 0.09357 | TestLoss: 0.21983 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 240 |  TrainLoss: 0.08728 | TestLoss: 0.22048 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 241 |  TrainLoss: 0.08381 | TestLoss: 0.23194 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 242 |  TrainLoss: 0.08424 | TestLoss: 0.22156 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 243 |  TrainLoss: 0.08110 | TestLoss: 0.22198 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 244 |  TrainLoss: 0.08071 | TestLoss: 0.22873 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 245 |  TrainLoss: 0.09115 | TestLoss: 0.24253 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 246 |  TrainLoss: 0.09073 | TestLoss: 0.22770 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 247 |  TrainLoss: 0.09766 | TestLoss: 0.22494 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 248 |  TrainLoss: 0.08542 | TestLoss: 0.25132 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 249 |  TrainLoss: 0.10916 | TestLoss: 0.22746 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 250 |  TrainLoss: 0.09936 | TestLoss: 0.22576 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 251 |  TrainLoss: 0.07557 | TestLoss: 0.23989 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 252 |  TrainLoss: 0.07956 | TestLoss: 0.22655 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 253 |  TrainLoss: 0.07277 | TestLoss: 0.22598 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 254 |  TrainLoss: 0.08993 | TestLoss: 0.22857 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 255 |  TrainLoss: 0.07490 | TestLoss: 0.24251 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 256 |  TrainLoss: 0.08315 | TestLoss: 0.22898 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 257 |  TrainLoss: 0.07754 | TestLoss: 0.22823 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 258 |  TrainLoss: 0.07651 | TestLoss: 0.25333 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 259 |  TrainLoss: 0.08525 | TestLoss: 0.22953 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 260 |  TrainLoss: 0.07692 | TestLoss: 0.22965 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 261 |  TrainLoss: 0.06606 | TestLoss: 0.24639 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 262 |  TrainLoss: 0.08292 | TestLoss: 0.23174 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 263 |  TrainLoss: 0.06805 | TestLoss: 0.23084 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 264 |  TrainLoss: 0.07772 | TestLoss: 0.23517 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 265 |  TrainLoss: 0.07274 | TestLoss: 0.23487 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 266 |  TrainLoss: 0.06578 | TestLoss: 0.23167 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 267 |  TrainLoss: 0.06482 | TestLoss: 0.24186 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 268 |  TrainLoss: 0.06360 | TestLoss: 0.23478 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 269 |  TrainLoss: 0.06515 | TestLoss: 0.23335 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 270 |  TrainLoss: 0.07491 | TestLoss: 0.24814 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 271 |  TrainLoss: 0.07429 | TestLoss: 0.23513 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 272 |  TrainLoss: 0.05790 | TestLoss: 0.23654 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 273 |  TrainLoss: 0.06297 | TestLoss: 0.25749 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 274 |  TrainLoss: 0.06749 | TestLoss: 0.23697 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 275 |  TrainLoss: 0.06988 | TestLoss: 0.24071 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 276 |  TrainLoss: 0.06252 | TestLoss: 0.25145 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 277 |  TrainLoss: 0.06917 | TestLoss: 0.23839 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 278 |  TrainLoss: 0.06117 | TestLoss: 0.23786 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 279 |  TrainLoss: 0.05616 | TestLoss: 0.24836 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 280 |  TrainLoss: 0.05985 | TestLoss: 0.24559 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 281 |  TrainLoss: 0.06335 | TestLoss: 0.23847 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 282 |  TrainLoss: 0.05995 | TestLoss: 0.25038 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 283 |  TrainLoss: 0.05800 | TestLoss: 0.24209 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 284 |  TrainLoss: 0.06690 | TestLoss: 0.24110 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 285 |  TrainLoss: 0.05143 | TestLoss: 0.24933 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 286 |  TrainLoss: 0.05291 | TestLoss: 0.24564 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 287 |  TrainLoss: 0.05623 | TestLoss: 0.25641 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 288 |  TrainLoss: 0.06175 | TestLoss: 0.24694 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 289 |  TrainLoss: 0.07401 | TestLoss: 0.26457 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 290 |  TrainLoss: 0.06394 | TestLoss: 0.24716 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 291 |  TrainLoss: 0.04945 | TestLoss: 0.24496 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 292 |  TrainLoss: 0.06206 | TestLoss: 0.27061 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 293 |  TrainLoss: 0.06751 | TestLoss: 0.24715 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 294 |  TrainLoss: 0.05282 | TestLoss: 0.24664 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 295 |  TrainLoss: 0.06308 | TestLoss: 0.29385 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 296 |  TrainLoss: 0.07707 | TestLoss: 0.24725 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 297 |  TrainLoss: 0.05528 | TestLoss: 0.24780 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 298 |  TrainLoss: 0.05962 | TestLoss: 0.30520 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 299 |  TrainLoss: 0.09426 | TestLoss: 0.25998 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 300 |  TrainLoss: 0.08316 | TestLoss: 0.26012 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 301 |  TrainLoss: 0.05658 | TestLoss: 0.27250 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 302 |  TrainLoss: 0.05527 | TestLoss: 0.25092 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 303 |  TrainLoss: 0.06405 | TestLoss: 0.26184 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 304 |  TrainLoss: 0.04351 | TestLoss: 0.26719 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 305 |  TrainLoss: 0.05118 | TestLoss: 0.25266 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 306 |  TrainLoss: 0.06142 | TestLoss: 0.26520 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 307 |  TrainLoss: 0.05117 | TestLoss: 0.26334 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 308 |  TrainLoss: 0.05076 | TestLoss: 0.25089 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 309 |  TrainLoss: 0.05127 | TestLoss: 0.25949 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 310 |  TrainLoss: 0.03791 | TestLoss: 0.27311 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 311 |  TrainLoss: 0.04466 | TestLoss: 0.25122 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 312 |  TrainLoss: 0.05010 | TestLoss: 0.25484 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 313 |  TrainLoss: 0.04329 | TestLoss: 0.26490 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 314 |  TrainLoss: 0.04001 | TestLoss: 0.25414 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 315 |  TrainLoss: 0.04040 | TestLoss: 0.25136 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 316 |  TrainLoss: 0.04514 | TestLoss: 0.28319 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 317 |  TrainLoss: 0.06120 | TestLoss: 0.25171 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 318 |  TrainLoss: 0.04606 | TestLoss: 0.25178 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 319 |  TrainLoss: 0.04939 | TestLoss: 0.29451 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 320 |  TrainLoss: 0.06020 | TestLoss: 0.25334 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 321 |  TrainLoss: 0.04318 | TestLoss: 0.25196 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 322 |  TrainLoss: 0.04541 | TestLoss: 0.29698 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 323 |  TrainLoss: 0.06237 | TestLoss: 0.25255 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 324 |  TrainLoss: 0.04054 | TestLoss: 0.25349 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 325 |  TrainLoss: 0.03819 | TestLoss: 0.27907 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 326 |  TrainLoss: 0.04960 | TestLoss: 0.25677 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 327 |  TrainLoss: 0.03149 | TestLoss: 0.25254 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 328 |  TrainLoss: 0.04566 | TestLoss: 0.29466 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 329 |  TrainLoss: 0.05088 | TestLoss: 0.26477 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 330 |  TrainLoss: 0.03990 | TestLoss: 0.26318 | TestAcc: 0.91935 | TestF1: 0.90\n",
            "Epoch: 331 |  TrainLoss: 0.06814 | TestLoss: 0.29592 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 332 |  TrainLoss: 0.04749 | TestLoss: 0.28002 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 333 |  TrainLoss: 0.04047 | TestLoss: 0.28013 | TestAcc: 0.91935 | TestF1: 0.90\n",
            "Epoch: 334 |  TrainLoss: 0.08968 | TestLoss: 0.32928 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 335 |  TrainLoss: 0.09362 | TestLoss: 0.25465 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 336 |  TrainLoss: 0.04172 | TestLoss: 0.26158 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 337 |  TrainLoss: 0.05605 | TestLoss: 0.35389 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 338 |  TrainLoss: 0.10900 | TestLoss: 0.26773 | TestAcc: 0.91935 | TestF1: 0.90\n",
            "Epoch: 339 |  TrainLoss: 0.05608 | TestLoss: 0.26174 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 340 |  TrainLoss: 0.05366 | TestLoss: 0.37275 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 341 |  TrainLoss: 0.13725 | TestLoss: 0.32302 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 342 |  TrainLoss: 0.13918 | TestLoss: 0.33221 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 343 |  TrainLoss: 0.08161 | TestLoss: 0.29219 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 344 |  TrainLoss: 0.04277 | TestLoss: 0.28461 | TestAcc: 0.91935 | TestF1: 0.90\n",
            "Epoch: 345 |  TrainLoss: 0.07543 | TestLoss: 0.28526 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 346 |  TrainLoss: 0.03723 | TestLoss: 0.32873 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 347 |  TrainLoss: 0.09392 | TestLoss: 0.29570 | TestAcc: 0.91935 | TestF1: 0.90\n",
            "Epoch: 348 |  TrainLoss: 0.09141 | TestLoss: 0.27434 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 349 |  TrainLoss: 0.03577 | TestLoss: 0.31681 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 350 |  TrainLoss: 0.07034 | TestLoss: 0.25548 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 351 |  TrainLoss: 0.04039 | TestLoss: 0.26598 | TestAcc: 0.91935 | TestF1: 0.90\n",
            "Epoch: 352 |  TrainLoss: 0.06165 | TestLoss: 0.30842 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 353 |  TrainLoss: 0.05854 | TestLoss: 0.28857 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 354 |  TrainLoss: 0.03910 | TestLoss: 0.25764 | TestAcc: 0.90323 | TestF1: 0.88\n",
            "Epoch: 355 |  TrainLoss: 0.05682 | TestLoss: 0.26536 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 356 |  TrainLoss: 0.03635 | TestLoss: 0.28318 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 357 |  TrainLoss: 0.03432 | TestLoss: 0.26373 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 358 |  TrainLoss: 0.02323 | TestLoss: 0.25408 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 359 |  TrainLoss: 0.03447 | TestLoss: 0.25899 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 360 |  TrainLoss: 0.02281 | TestLoss: 0.28736 | TestAcc: 0.90323 | TestF1: 0.89\n",
            "Epoch: 361 |  TrainLoss: 0.03265 | TestLoss: 0.27338 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 362 |  TrainLoss: 0.02435 | TestLoss: 0.25475 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 363 |  TrainLoss: 0.02903 | TestLoss: 0.25847 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 364 |  TrainLoss: 0.02476 | TestLoss: 0.27459 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 365 |  TrainLoss: 0.02502 | TestLoss: 0.27512 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 366 |  TrainLoss: 0.02405 | TestLoss: 0.25936 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 367 |  TrainLoss: 0.02405 | TestLoss: 0.25874 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 368 |  TrainLoss: 0.02405 | TestLoss: 0.27540 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 369 |  TrainLoss: 0.02270 | TestLoss: 0.28081 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 370 |  TrainLoss: 0.03189 | TestLoss: 0.25550 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 371 |  TrainLoss: 0.02683 | TestLoss: 0.25774 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 372 |  TrainLoss: 0.02330 | TestLoss: 0.27927 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 373 |  TrainLoss: 0.02002 | TestLoss: 0.28207 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 374 |  TrainLoss: 0.02056 | TestLoss: 0.26215 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 375 |  TrainLoss: 0.02389 | TestLoss: 0.26460 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 376 |  TrainLoss: 0.01803 | TestLoss: 0.27724 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 377 |  TrainLoss: 0.02240 | TestLoss: 0.27016 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 378 |  TrainLoss: 0.01856 | TestLoss: 0.26301 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 379 |  TrainLoss: 0.01862 | TestLoss: 0.26129 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 380 |  TrainLoss: 0.01841 | TestLoss: 0.27105 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 381 |  TrainLoss: 0.02326 | TestLoss: 0.27051 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 382 |  TrainLoss: 0.02215 | TestLoss: 0.25777 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 383 |  TrainLoss: 0.01816 | TestLoss: 0.26294 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 384 |  TrainLoss: 0.02082 | TestLoss: 0.28588 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 385 |  TrainLoss: 0.02081 | TestLoss: 0.27929 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 386 |  TrainLoss: 0.01933 | TestLoss: 0.26093 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 387 |  TrainLoss: 0.01536 | TestLoss: 0.26327 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 388 |  TrainLoss: 0.01904 | TestLoss: 0.26182 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 389 |  TrainLoss: 0.01831 | TestLoss: 0.26650 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 390 |  TrainLoss: 0.01797 | TestLoss: 0.27702 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 391 |  TrainLoss: 0.01695 | TestLoss: 0.27286 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 392 |  TrainLoss: 0.01461 | TestLoss: 0.26405 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 393 |  TrainLoss: 0.01739 | TestLoss: 0.26180 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 394 |  TrainLoss: 0.01944 | TestLoss: 0.29597 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 395 |  TrainLoss: 0.02387 | TestLoss: 0.28151 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 396 |  TrainLoss: 0.01323 | TestLoss: 0.26375 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 397 |  TrainLoss: 0.01667 | TestLoss: 0.26878 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 398 |  TrainLoss: 0.01785 | TestLoss: 0.28949 | TestAcc: 0.91935 | TestF1: 0.91\n",
            "Epoch: 399 |  TrainLoss: 0.01348 | TestLoss: 0.29149 | TestAcc: 0.91935 | TestF1: 0.91\n"
          ]
        }
      ],
      "source": [
        "wloss = []\n",
        "weighted_loss = 0\n",
        "exp_param = 0.8\n",
        "\n",
        "for epoch in range(400):\n",
        "  train_loss = train(epoch)\n",
        "  test_loss, test_acc, test_f1 = test(epoch)\n",
        "  # weighted_loss = exp_param*(weighted_loss) + (1-exp_param)*(test_loss/ len(test_loader.dataset))\n",
        "\n",
        "  # wloss.append(weighted_loss/(1-exp_param**(epoch+1)))\n",
        "\n",
        "  # if(epoch-20>=0 and wloss[epoch-6]-weighted_loss<0.01):\n",
        "  #     print(\"Stopped Early at Epoch {} \".format(epoch))\n",
        "  #     break\n",
        "\n",
        "  print(f'Epoch: {epoch:02d} |  TrainLoss: {train_loss:.5f} | '\n",
        "          f'TestLoss: {test_loss:.5f} | TestAcc: {test_acc:.5f} | TestF1: {test_f1:.2f}')\n",
        "  # print(f'Epoch: {epoch:02d} |  TrainLoss: {train_loss:.7f} |')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Best Metrics found after training \n",
        "**Epoch: 168 |  TrainLoss: 0.15680 | TestLoss: 0.21858 | TestAcc: 0.91935 | TestF1: 0.91**\n",
        "\n",
        "*Note : We choose the best epoch based on lowest Test Loss.*\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.12 ('torch-gpu')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "e1cb4ba5f411cfa4a68a7ea6c2f9ba3655e2604bd37447d058a856eda531fd15"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
